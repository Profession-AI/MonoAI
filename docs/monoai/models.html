<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.4"/>
    <title>monoai.models API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../monoai.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;monoai</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#Model">Model</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Model.__init__">Model</a>
                        </li>
                        <li>
                                <a class="variable" href="#Model.provider">provider</a>
                        </li>
                        <li>
                                <a class="variable" href="#Model.model">model</a>
                        </li>
                        <li>
                                <a class="function" href="#Model.ask_stream">ask_stream</a>
                        </li>
                        <li>
                                <a class="function" href="#Model.ask">ask</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#HostedModel">HostedModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#HostedModel.__init__">HostedModel</a>
                        </li>
                        <li>
                                <a class="variable" href="#HostedModel.url">url</a>
                        </li>
                        <li>
                                <a class="variable" href="#HostedModel.version">version</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#MultiModel">MultiModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#MultiModel.__init__">MultiModel</a>
                        </li>
                        <li>
                                <a class="function" href="#MultiModel.ask">ask</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#CollaborativeModel">CollaborativeModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#CollaborativeModel.__init__">CollaborativeModel</a>
                        </li>
                        <li>
                                <a class="function" href="#CollaborativeModel.ask">ask</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ImageModel">ImageModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ImageModel.__init__">ImageModel</a>
                        </li>
                        <li>
                                <a class="variable" href="#ImageModel.provider">provider</a>
                        </li>
                        <li>
                                <a class="variable" href="#ImageModel.model">model</a>
                        </li>
                        <li>
                                <a class="function" href="#ImageModel.generate">generate</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#VoiceModel">VoiceModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#VoiceModel.__init__">VoiceModel</a>
                        </li>
                        <li>
                                <a class="function" href="#VoiceModel.speak">speak</a>
                        </li>
                        <li>
                                <a class="function" href="#VoiceModel.stream">stream</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../monoai.html">monoai</a><wbr>.models    </h1>

                        <div class="docstring"><p>Models are the core of MonoAI. They are responsible for executing prompts and returning responses.</p>

<p>This package uses lazy loading to avoid importing heavy optional dependencies
at module import time. Classes are imported only when accessed.</p>
</div>

                        <input id="mod-models-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-models-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos"> 1</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos"> 2</span></a><span class="sd">Models are the core of MonoAI. They are responsible for executing prompts and returning responses.</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos"> 3</span></a>
</span><span id="L-4"><a href="#L-4"><span class="linenos"> 4</span></a><span class="sd">This package uses lazy loading to avoid importing heavy optional dependencies</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos"> 5</span></a><span class="sd">at module import time. Classes are imported only when accessed.</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos"> 6</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos"> 7</span></a>
</span><span id="L-8"><a href="#L-8"><span class="linenos"> 8</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos"> 9</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.hosted_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">HostedModel</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">10</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.multi_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultiModel</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">11</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.collaborative_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">CollaborativeModel</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">12</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.image_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">ImageModel</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">13</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.voice_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">VoiceModel</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">14</span></a>
</span><span id="L-15"><a href="#L-15"><span class="linenos">15</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s2">&quot;HostedModel&quot;</span><span class="p">,</span> <span class="s1">&#39;MultiModel&#39;</span><span class="p">,</span> <span class="s1">&#39;CollaborativeModel&#39;</span><span class="p">,</span> <span class="s1">&#39;ImageModel&#39;</span><span class="p">,</span> <span class="s1">&#39;VoiceModel&#39;</span><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="Model">
                            <input id="Model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">Model</span><wbr>(<span class="base">monoai.models._base_model.BaseModel</span>, <span class="base">monoai.models._response_processor.ResponseProcessorMixin</span>, <span class="base">monoai.models._prompt_executor.PromptExecutorMixin</span>):

                <label class="view-source-button" for="Model-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Model"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Model-13"><a href="#Model-13"><span class="linenos"> 13</span></a><span class="k">class</span><span class="w"> </span><span class="nc">Model</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">,</span> <span class="n">ResponseProcessorMixin</span><span class="p">,</span> <span class="n">PromptExecutorMixin</span><span class="p">):</span>
</span><span id="Model-14"><a href="#Model-14"><span class="linenos"> 14</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Model-15"><a href="#Model-15"><span class="linenos"> 15</span></a><span class="sd">    Model class for interacting with AI language models.</span>
</span><span id="Model-16"><a href="#Model-16"><span class="linenos"> 16</span></a>
</span><span id="Model-17"><a href="#Model-17"><span class="linenos"> 17</span></a><span class="sd">    This module provides the Model class which serves as the primary interface for interacting</span>
</span><span id="Model-18"><a href="#Model-18"><span class="linenos"> 18</span></a><span class="sd">    with various AI language models (like GPT-4, Claude-3, etc.).</span>
</span><span id="Model-19"><a href="#Model-19"><span class="linenos"> 19</span></a>
</span><span id="Model-20"><a href="#Model-20"><span class="linenos"> 20</span></a><span class="sd">    Examples</span>
</span><span id="Model-21"><a href="#Model-21"><span class="linenos"> 21</span></a><span class="sd">    --------</span>
</span><span id="Model-22"><a href="#Model-22"><span class="linenos"> 22</span></a><span class="sd">    Basic usage:</span>
</span><span id="Model-23"><a href="#Model-23"><span class="linenos"> 23</span></a><span class="sd">    ```</span>
</span><span id="Model-24"><a href="#Model-24"><span class="linenos"> 24</span></a><span class="sd">    model = Model(provider=&quot;openai&quot;, model=&quot;gpt-4&quot;)</span>
</span><span id="Model-25"><a href="#Model-25"><span class="linenos"> 25</span></a><span class="sd">    response = model.ask(&quot;What is the capital of France?&quot;)</span>
</span><span id="Model-26"><a href="#Model-26"><span class="linenos"> 26</span></a><span class="sd">    ```</span>
</span><span id="Model-27"><a href="#Model-27"><span class="linenos"> 27</span></a>
</span><span id="Model-28"><a href="#Model-28"><span class="linenos"> 28</span></a><span class="sd">    With prompt:</span>
</span><span id="Model-29"><a href="#Model-29"><span class="linenos"> 29</span></a><span class="sd">    ```</span>
</span><span id="Model-30"><a href="#Model-30"><span class="linenos"> 30</span></a><span class="sd">    model = Model(</span>
</span><span id="Model-31"><a href="#Model-31"><span class="linenos"> 31</span></a><span class="sd">        provider=&quot;anthropic&quot;,</span>
</span><span id="Model-32"><a href="#Model-32"><span class="linenos"> 32</span></a><span class="sd">        model=&quot;claude-3&quot;,</span>
</span><span id="Model-33"><a href="#Model-33"><span class="linenos"> 33</span></a><span class="sd">    )</span>
</span><span id="Model-34"><a href="#Model-34"><span class="linenos"> 34</span></a><span class="sd">    prompt = Prompt(</span>
</span><span id="Model-35"><a href="#Model-35"><span class="linenos"> 35</span></a><span class="sd">        prompt=&quot;What is the capital of {country}?&quot;,</span>
</span><span id="Model-36"><a href="#Model-36"><span class="linenos"> 36</span></a><span class="sd">        prompt_data={&quot;country&quot;: &quot;France&quot;},</span>
</span><span id="Model-37"><a href="#Model-37"><span class="linenos"> 37</span></a><span class="sd">        response_type=str</span>
</span><span id="Model-38"><a href="#Model-38"><span class="linenos"> 38</span></a><span class="sd">    )</span>
</span><span id="Model-39"><a href="#Model-39"><span class="linenos"> 39</span></a><span class="sd">    response = model.ask(prompt)</span>
</span><span id="Model-40"><a href="#Model-40"><span class="linenos"> 40</span></a><span class="sd">    ```</span>
</span><span id="Model-41"><a href="#Model-41"><span class="linenos"> 41</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="Model-42"><a href="#Model-42"><span class="linenos"> 42</span></a>
</span><span id="Model-43"><a href="#Model-43"><span class="linenos"> 43</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="Model-44"><a href="#Model-44"><span class="linenos"> 44</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="Model-45"><a href="#Model-45"><span class="linenos"> 45</span></a>        <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
</span><span id="Model-46"><a href="#Model-46"><span class="linenos"> 46</span></a>        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
</span><span id="Model-47"><a href="#Model-47"><span class="linenos"> 47</span></a>        <span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
</span><span id="Model-48"><a href="#Model-48"><span class="linenos"> 48</span></a>        <span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Model-49"><a href="#Model-49"><span class="linenos"> 49</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="Model-50"><a href="#Model-50"><span class="linenos"> 50</span></a>    <span class="p">):</span>
</span><span id="Model-51"><a href="#Model-51"><span class="linenos"> 51</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Model-52"><a href="#Model-52"><span class="linenos"> 52</span></a><span class="sd">        Initialize a new Model instance.</span>
</span><span id="Model-53"><a href="#Model-53"><span class="linenos"> 53</span></a>
</span><span id="Model-54"><a href="#Model-54"><span class="linenos"> 54</span></a><span class="sd">        Parameters</span>
</span><span id="Model-55"><a href="#Model-55"><span class="linenos"> 55</span></a><span class="sd">        ----------</span>
</span><span id="Model-56"><a href="#Model-56"><span class="linenos"> 56</span></a><span class="sd">        provider : str</span>
</span><span id="Model-57"><a href="#Model-57"><span class="linenos"> 57</span></a><span class="sd">            Name of the provider (e.g., &#39;openai&#39;, &#39;anthropic&#39;)</span>
</span><span id="Model-58"><a href="#Model-58"><span class="linenos"> 58</span></a><span class="sd">        model : str</span>
</span><span id="Model-59"><a href="#Model-59"><span class="linenos"> 59</span></a><span class="sd">            Name of the model (e.g., &#39;gpt-4&#39;, &#39;claude-3&#39;)</span>
</span><span id="Model-60"><a href="#Model-60"><span class="linenos"> 60</span></a><span class="sd">        count_tokens : bool, optional</span>
</span><span id="Model-61"><a href="#Model-61"><span class="linenos"> 61</span></a><span class="sd">            Whether to count tokens for each request</span>
</span><span id="Model-62"><a href="#Model-62"><span class="linenos"> 62</span></a><span class="sd">        count_cost : bool, optional</span>
</span><span id="Model-63"><a href="#Model-63"><span class="linenos"> 63</span></a><span class="sd">            Whether to calculate costs for each request</span>
</span><span id="Model-64"><a href="#Model-64"><span class="linenos"> 64</span></a><span class="sd">        max_tokens : int, optional</span>
</span><span id="Model-65"><a href="#Model-65"><span class="linenos"> 65</span></a><span class="sd">            Maximum number of tokens for each request</span>
</span><span id="Model-66"><a href="#Model-66"><span class="linenos"> 66</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Model-67"><a href="#Model-67"><span class="linenos"> 67</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">count_tokens</span><span class="p">,</span> <span class="n">count_cost</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">)</span>
</span><span id="Model-68"><a href="#Model-68"><span class="linenos"> 68</span></a>        
</span><span id="Model-69"><a href="#Model-69"><span class="linenos"> 69</span></a>        <span class="k">if</span> <span class="n">provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Model-70"><a href="#Model-70"><span class="linenos"> 70</span></a>            <span class="n">provider</span> <span class="o">=</span> <span class="n">Conf</span><span class="p">()[</span><span class="s2">&quot;base_model&quot;</span><span class="p">][</span><span class="s2">&quot;provider&quot;</span><span class="p">]</span>
</span><span id="Model-71"><a href="#Model-71"><span class="linenos"> 71</span></a>        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Model-72"><a href="#Model-72"><span class="linenos"> 72</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">Conf</span><span class="p">()[</span><span class="s2">&quot;base_model&quot;</span><span class="p">][</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
</span><span id="Model-73"><a href="#Model-73"><span class="linenos"> 73</span></a>
</span><span id="Model-74"><a href="#Model-74"><span class="linenos"> 74</span></a>        <span class="n">load_key</span><span class="p">(</span><span class="n">provider</span><span class="p">)</span>
</span><span id="Model-75"><a href="#Model-75"><span class="linenos"> 75</span></a>
</span><span id="Model-76"><a href="#Model-76"><span class="linenos"> 76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">provider</span> <span class="o">=</span> <span class="n">provider</span>
</span><span id="Model-77"><a href="#Model-77"><span class="linenos"> 77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="Model-78"><a href="#Model-78"><span class="linenos"> 78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_web_search</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="Model-79"><a href="#Model-79"><span class="linenos"> 79</span></a>
</span><span id="Model-80"><a href="#Model-80"><span class="linenos"> 80</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_ask_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">],</span> <span class="n">metadata</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{})</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
</span><span id="Model-81"><a href="#Model-81"><span class="linenos"> 81</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Model-82"><a href="#Model-82"><span class="linenos"> 82</span></a><span class="sd">        Ask the model asynchronously.</span>
</span><span id="Model-83"><a href="#Model-83"><span class="linenos"> 83</span></a>
</span><span id="Model-84"><a href="#Model-84"><span class="linenos"> 84</span></a><span class="sd">        Parameters</span>
</span><span id="Model-85"><a href="#Model-85"><span class="linenos"> 85</span></a><span class="sd">        ----------</span>
</span><span id="Model-86"><a href="#Model-86"><span class="linenos"> 86</span></a><span class="sd">        prompt : Union[str, Prompt]</span>
</span><span id="Model-87"><a href="#Model-87"><span class="linenos"> 87</span></a><span class="sd">            The prompt to process</span>
</span><span id="Model-88"><a href="#Model-88"><span class="linenos"> 88</span></a><span class="sd">        metadata : Dict, optional</span>
</span><span id="Model-89"><a href="#Model-89"><span class="linenos"> 89</span></a><span class="sd">            Metadata to pass to the completion call</span>
</span><span id="Model-90"><a href="#Model-90"><span class="linenos"> 90</span></a>
</span><span id="Model-91"><a href="#Model-91"><span class="linenos"> 91</span></a><span class="sd">        Returns</span>
</span><span id="Model-92"><a href="#Model-92"><span class="linenos"> 92</span></a><span class="sd">        -------</span>
</span><span id="Model-93"><a href="#Model-93"><span class="linenos"> 93</span></a><span class="sd">        Dict</span>
</span><span id="Model-94"><a href="#Model-94"><span class="linenos"> 94</span></a><span class="sd">            Dictionary containing:</span>
</span><span id="Model-95"><a href="#Model-95"><span class="linenos"> 95</span></a><span class="sd">            - response: The model&#39;s response</span>
</span><span id="Model-96"><a href="#Model-96"><span class="linenos"> 96</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="Model-97"><a href="#Model-97"><span class="linenos"> 97</span></a><span class="sd">            - model: Dictionary with provider and model name</span>
</span><span id="Model-98"><a href="#Model-98"><span class="linenos"> 98</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="Model-99"><a href="#Model-99"><span class="linenos"> 99</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="Model-100"><a href="#Model-100"><span class="linenos">100</span></a>
</span><span id="Model-101"><a href="#Model-101"><span class="linenos">101</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Model-102"><a href="#Model-102"><span class="linenos">102</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_async</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
</span><span id="Model-103"><a href="#Model-103"><span class="linenos">103</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_response</span><span class="p">(</span>
</span><span id="Model-104"><a href="#Model-104"><span class="linenos">104</span></a>            <span class="n">prompt</span><span class="p">,</span>
</span><span id="Model-105"><a href="#Model-105"><span class="linenos">105</span></a>            <span class="n">response</span><span class="p">,</span>
</span><span id="Model-106"><a href="#Model-106"><span class="linenos">106</span></a>        <span class="p">)</span>
</span><span id="Model-107"><a href="#Model-107"><span class="linenos">107</span></a>
</span><span id="Model-108"><a href="#Model-108"><span class="linenos">108</span></a>    
</span><span id="Model-109"><a href="#Model-109"><span class="linenos">109</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">ask_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">],</span> <span class="n">metadata</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{})</span> <span class="o">-&gt;</span> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
</span><span id="Model-110"><a href="#Model-110"><span class="linenos">110</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Model-111"><a href="#Model-111"><span class="linenos">111</span></a><span class="sd">        Ask the model with streaming response.</span>
</span><span id="Model-112"><a href="#Model-112"><span class="linenos">112</span></a>
</span><span id="Model-113"><a href="#Model-113"><span class="linenos">113</span></a><span class="sd">        Parameters</span>
</span><span id="Model-114"><a href="#Model-114"><span class="linenos">114</span></a><span class="sd">        ----------</span>
</span><span id="Model-115"><a href="#Model-115"><span class="linenos">115</span></a><span class="sd">        prompt : Union[str, Prompt, PromptChain]</span>
</span><span id="Model-116"><a href="#Model-116"><span class="linenos">116</span></a><span class="sd">            The prompt to process</span>
</span><span id="Model-117"><a href="#Model-117"><span class="linenos">117</span></a><span class="sd">        metadata : Dict, optional</span>
</span><span id="Model-118"><a href="#Model-118"><span class="linenos">118</span></a><span class="sd">            Metadata to pass to the completion call</span>
</span><span id="Model-119"><a href="#Model-119"><span class="linenos">119</span></a>
</span><span id="Model-120"><a href="#Model-120"><span class="linenos">120</span></a><span class="sd">        Yields</span>
</span><span id="Model-121"><a href="#Model-121"><span class="linenos">121</span></a><span class="sd">        ------</span>
</span><span id="Model-122"><a href="#Model-122"><span class="linenos">122</span></a><span class="sd">        Dict</span>
</span><span id="Model-123"><a href="#Model-123"><span class="linenos">123</span></a><span class="sd">            Streaming response chunks</span>
</span><span id="Model-124"><a href="#Model-124"><span class="linenos">124</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Model-125"><a href="#Model-125"><span class="linenos">125</span></a>        <span class="k">yield</span> <span class="p">{</span><span class="s2">&quot;provider&quot;</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">provider</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">}</span>
</span><span id="Model-126"><a href="#Model-126"><span class="linenos">126</span></a>        <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_stream</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
</span><span id="Model-127"><a href="#Model-127"><span class="linenos">127</span></a>            <span class="n">processed_chunk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span><span id="Model-128"><a href="#Model-128"><span class="linenos">128</span></a>            <span class="k">if</span> <span class="n">processed_chunk</span><span class="p">[</span><span class="s2">&quot;delta&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Model-129"><a href="#Model-129"><span class="linenos">129</span></a>                <span class="k">yield</span> <span class="n">processed_chunk</span>
</span><span id="Model-130"><a href="#Model-130"><span class="linenos">130</span></a>
</span><span id="Model-131"><a href="#Model-131"><span class="linenos">131</span></a>
</span><span id="Model-132"><a href="#Model-132"><span class="linenos">132</span></a>
</span><span id="Model-133"><a href="#Model-133"><span class="linenos">133</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">ask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">],</span> <span class="n">metadata</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{})</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
</span><span id="Model-134"><a href="#Model-134"><span class="linenos">134</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Model-135"><a href="#Model-135"><span class="linenos">135</span></a><span class="sd">        Ask the model.</span>
</span><span id="Model-136"><a href="#Model-136"><span class="linenos">136</span></a>
</span><span id="Model-137"><a href="#Model-137"><span class="linenos">137</span></a><span class="sd">        Parameters</span>
</span><span id="Model-138"><a href="#Model-138"><span class="linenos">138</span></a><span class="sd">        ----------</span>
</span><span id="Model-139"><a href="#Model-139"><span class="linenos">139</span></a><span class="sd">        prompt : Union[str, Prompt]</span>
</span><span id="Model-140"><a href="#Model-140"><span class="linenos">140</span></a><span class="sd">            The prompt to process</span>
</span><span id="Model-141"><a href="#Model-141"><span class="linenos">141</span></a><span class="sd">        metadata : Dict, optional</span>
</span><span id="Model-142"><a href="#Model-142"><span class="linenos">142</span></a><span class="sd">            Metadata to pass to the completion call</span>
</span><span id="Model-143"><a href="#Model-143"><span class="linenos">143</span></a>
</span><span id="Model-144"><a href="#Model-144"><span class="linenos">144</span></a><span class="sd">        Returns</span>
</span><span id="Model-145"><a href="#Model-145"><span class="linenos">145</span></a><span class="sd">        -------</span>
</span><span id="Model-146"><a href="#Model-146"><span class="linenos">146</span></a><span class="sd">        Dict</span>
</span><span id="Model-147"><a href="#Model-147"><span class="linenos">147</span></a><span class="sd">            Dictionary containing:</span>
</span><span id="Model-148"><a href="#Model-148"><span class="linenos">148</span></a><span class="sd">            - response: The model&#39;s response</span>
</span><span id="Model-149"><a href="#Model-149"><span class="linenos">149</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="Model-150"><a href="#Model-150"><span class="linenos">150</span></a><span class="sd">            - model: Dictionary with provider and model name</span>
</span><span id="Model-151"><a href="#Model-151"><span class="linenos">151</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="Model-152"><a href="#Model-152"><span class="linenos">152</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="Model-153"><a href="#Model-153"><span class="linenos">153</span></a>
</span><span id="Model-154"><a href="#Model-154"><span class="linenos">154</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Model-155"><a href="#Model-155"><span class="linenos">155</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="Model-156"><a href="#Model-156"><span class="linenos">156</span></a>            <span class="n">prompt</span> <span class="o">=</span> <span class="n">Prompt</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
</span><span id="Model-157"><a href="#Model-157"><span class="linenos">157</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
</span><span id="Model-158"><a href="#Model-158"><span class="linenos">158</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_response</span><span class="p">(</span>
</span><span id="Model-159"><a href="#Model-159"><span class="linenos">159</span></a>            <span class="n">prompt</span><span class="p">,</span>
</span><span id="Model-160"><a href="#Model-160"><span class="linenos">160</span></a>            <span class="n">response</span>
</span><span id="Model-161"><a href="#Model-161"><span class="linenos">161</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Model class for interacting with AI language models.</p>

<p>This module provides the Model class which serves as the primary interface for interacting
with various AI language models (like GPT-4, Claude-3, etc.).</p>

<h6 id="examples">Examples</h6>

<p>Basic usage:</p>

<pre><code>model = Model(provider="openai", model="gpt-4")
response = model.ask("What is the capital of France?")
</code></pre>

<p>With prompt:</p>

<pre><code>model = Model(
    provider="anthropic",
    model="claude-3",
)
prompt = Prompt(
    prompt="What is the capital of {country}?",
    prompt_data={"country": "France"},
    response_type=str
)
response = model.ask(prompt)
</code></pre>
</div>


                            <div id="Model.__init__" class="classattr">
                                        <input id="Model.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">Model</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">provider</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="Model.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Model.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Model.__init__-43"><a href="#Model.__init__-43"><span class="linenos">43</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="Model.__init__-44"><a href="#Model.__init__-44"><span class="linenos">44</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="Model.__init__-45"><a href="#Model.__init__-45"><span class="linenos">45</span></a>        <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
</span><span id="Model.__init__-46"><a href="#Model.__init__-46"><span class="linenos">46</span></a>        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
</span><span id="Model.__init__-47"><a href="#Model.__init__-47"><span class="linenos">47</span></a>        <span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
</span><span id="Model.__init__-48"><a href="#Model.__init__-48"><span class="linenos">48</span></a>        <span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Model.__init__-49"><a href="#Model.__init__-49"><span class="linenos">49</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="Model.__init__-50"><a href="#Model.__init__-50"><span class="linenos">50</span></a>    <span class="p">):</span>
</span><span id="Model.__init__-51"><a href="#Model.__init__-51"><span class="linenos">51</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Model.__init__-52"><a href="#Model.__init__-52"><span class="linenos">52</span></a><span class="sd">        Initialize a new Model instance.</span>
</span><span id="Model.__init__-53"><a href="#Model.__init__-53"><span class="linenos">53</span></a>
</span><span id="Model.__init__-54"><a href="#Model.__init__-54"><span class="linenos">54</span></a><span class="sd">        Parameters</span>
</span><span id="Model.__init__-55"><a href="#Model.__init__-55"><span class="linenos">55</span></a><span class="sd">        ----------</span>
</span><span id="Model.__init__-56"><a href="#Model.__init__-56"><span class="linenos">56</span></a><span class="sd">        provider : str</span>
</span><span id="Model.__init__-57"><a href="#Model.__init__-57"><span class="linenos">57</span></a><span class="sd">            Name of the provider (e.g., &#39;openai&#39;, &#39;anthropic&#39;)</span>
</span><span id="Model.__init__-58"><a href="#Model.__init__-58"><span class="linenos">58</span></a><span class="sd">        model : str</span>
</span><span id="Model.__init__-59"><a href="#Model.__init__-59"><span class="linenos">59</span></a><span class="sd">            Name of the model (e.g., &#39;gpt-4&#39;, &#39;claude-3&#39;)</span>
</span><span id="Model.__init__-60"><a href="#Model.__init__-60"><span class="linenos">60</span></a><span class="sd">        count_tokens : bool, optional</span>
</span><span id="Model.__init__-61"><a href="#Model.__init__-61"><span class="linenos">61</span></a><span class="sd">            Whether to count tokens for each request</span>
</span><span id="Model.__init__-62"><a href="#Model.__init__-62"><span class="linenos">62</span></a><span class="sd">        count_cost : bool, optional</span>
</span><span id="Model.__init__-63"><a href="#Model.__init__-63"><span class="linenos">63</span></a><span class="sd">            Whether to calculate costs for each request</span>
</span><span id="Model.__init__-64"><a href="#Model.__init__-64"><span class="linenos">64</span></a><span class="sd">        max_tokens : int, optional</span>
</span><span id="Model.__init__-65"><a href="#Model.__init__-65"><span class="linenos">65</span></a><span class="sd">            Maximum number of tokens for each request</span>
</span><span id="Model.__init__-66"><a href="#Model.__init__-66"><span class="linenos">66</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Model.__init__-67"><a href="#Model.__init__-67"><span class="linenos">67</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">count_tokens</span><span class="p">,</span> <span class="n">count_cost</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">)</span>
</span><span id="Model.__init__-68"><a href="#Model.__init__-68"><span class="linenos">68</span></a>        
</span><span id="Model.__init__-69"><a href="#Model.__init__-69"><span class="linenos">69</span></a>        <span class="k">if</span> <span class="n">provider</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Model.__init__-70"><a href="#Model.__init__-70"><span class="linenos">70</span></a>            <span class="n">provider</span> <span class="o">=</span> <span class="n">Conf</span><span class="p">()[</span><span class="s2">&quot;base_model&quot;</span><span class="p">][</span><span class="s2">&quot;provider&quot;</span><span class="p">]</span>
</span><span id="Model.__init__-71"><a href="#Model.__init__-71"><span class="linenos">71</span></a>        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Model.__init__-72"><a href="#Model.__init__-72"><span class="linenos">72</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">Conf</span><span class="p">()[</span><span class="s2">&quot;base_model&quot;</span><span class="p">][</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
</span><span id="Model.__init__-73"><a href="#Model.__init__-73"><span class="linenos">73</span></a>
</span><span id="Model.__init__-74"><a href="#Model.__init__-74"><span class="linenos">74</span></a>        <span class="n">load_key</span><span class="p">(</span><span class="n">provider</span><span class="p">)</span>
</span><span id="Model.__init__-75"><a href="#Model.__init__-75"><span class="linenos">75</span></a>
</span><span id="Model.__init__-76"><a href="#Model.__init__-76"><span class="linenos">76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">provider</span> <span class="o">=</span> <span class="n">provider</span>
</span><span id="Model.__init__-77"><a href="#Model.__init__-77"><span class="linenos">77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="Model.__init__-78"><a href="#Model.__init__-78"><span class="linenos">78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_web_search</span> <span class="o">=</span> <span class="kc">False</span>
</span></pre></div>


            <div class="docstring"><p>Initialize a new Model instance.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>provider</strong> (str):
Name of the provider (e.g., 'openai', 'anthropic')</li>
<li><strong>model</strong> (str):
Name of the model (e.g., 'gpt-4', 'claude-3')</li>
<li><strong>count_tokens</strong> (bool, optional):
Whether to count tokens for each request</li>
<li><strong>count_cost</strong> (bool, optional):
Whether to calculate costs for each request</li>
<li><strong>max_tokens</strong> (int, optional):
Maximum number of tokens for each request</li>
</ul>
</div>


                            </div>
                            <div id="Model.provider" class="classattr">
                                <div class="attr variable">
            <span class="name">provider</span>

        
    </div>
    <a class="headerlink" href="#Model.provider"></a>
    
    

                            </div>
                            <div id="Model.model" class="classattr">
                                <div class="attr variable">
            <span class="name">model</span>

        
    </div>
    <a class="headerlink" href="#Model.model"></a>
    
    

                            </div>
                            <div id="Model.ask_stream" class="classattr">
                                        <input id="Model.ask_stream-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">ask_stream</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n"><a href="prompts.html#Prompt">monoai.prompts.Prompt</a></span><span class="p">,</span> <span class="n"><a href="prompts.html#PromptChain">monoai.prompts.PromptChain</a></span><span class="p">]</span>,</span><span class="param">	<span class="n">metadata</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{}</span></span><span class="return-annotation">) -> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="Model.ask_stream-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Model.ask_stream"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Model.ask_stream-109"><a href="#Model.ask_stream-109"><span class="linenos">109</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">ask_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">],</span> <span class="n">metadata</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{})</span> <span class="o">-&gt;</span> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
</span><span id="Model.ask_stream-110"><a href="#Model.ask_stream-110"><span class="linenos">110</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Model.ask_stream-111"><a href="#Model.ask_stream-111"><span class="linenos">111</span></a><span class="sd">        Ask the model with streaming response.</span>
</span><span id="Model.ask_stream-112"><a href="#Model.ask_stream-112"><span class="linenos">112</span></a>
</span><span id="Model.ask_stream-113"><a href="#Model.ask_stream-113"><span class="linenos">113</span></a><span class="sd">        Parameters</span>
</span><span id="Model.ask_stream-114"><a href="#Model.ask_stream-114"><span class="linenos">114</span></a><span class="sd">        ----------</span>
</span><span id="Model.ask_stream-115"><a href="#Model.ask_stream-115"><span class="linenos">115</span></a><span class="sd">        prompt : Union[str, Prompt, PromptChain]</span>
</span><span id="Model.ask_stream-116"><a href="#Model.ask_stream-116"><span class="linenos">116</span></a><span class="sd">            The prompt to process</span>
</span><span id="Model.ask_stream-117"><a href="#Model.ask_stream-117"><span class="linenos">117</span></a><span class="sd">        metadata : Dict, optional</span>
</span><span id="Model.ask_stream-118"><a href="#Model.ask_stream-118"><span class="linenos">118</span></a><span class="sd">            Metadata to pass to the completion call</span>
</span><span id="Model.ask_stream-119"><a href="#Model.ask_stream-119"><span class="linenos">119</span></a>
</span><span id="Model.ask_stream-120"><a href="#Model.ask_stream-120"><span class="linenos">120</span></a><span class="sd">        Yields</span>
</span><span id="Model.ask_stream-121"><a href="#Model.ask_stream-121"><span class="linenos">121</span></a><span class="sd">        ------</span>
</span><span id="Model.ask_stream-122"><a href="#Model.ask_stream-122"><span class="linenos">122</span></a><span class="sd">        Dict</span>
</span><span id="Model.ask_stream-123"><a href="#Model.ask_stream-123"><span class="linenos">123</span></a><span class="sd">            Streaming response chunks</span>
</span><span id="Model.ask_stream-124"><a href="#Model.ask_stream-124"><span class="linenos">124</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Model.ask_stream-125"><a href="#Model.ask_stream-125"><span class="linenos">125</span></a>        <span class="k">yield</span> <span class="p">{</span><span class="s2">&quot;provider&quot;</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">provider</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">}</span>
</span><span id="Model.ask_stream-126"><a href="#Model.ask_stream-126"><span class="linenos">126</span></a>        <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_stream</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
</span><span id="Model.ask_stream-127"><a href="#Model.ask_stream-127"><span class="linenos">127</span></a>            <span class="n">processed_chunk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span><span id="Model.ask_stream-128"><a href="#Model.ask_stream-128"><span class="linenos">128</span></a>            <span class="k">if</span> <span class="n">processed_chunk</span><span class="p">[</span><span class="s2">&quot;delta&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Model.ask_stream-129"><a href="#Model.ask_stream-129"><span class="linenos">129</span></a>                <span class="k">yield</span> <span class="n">processed_chunk</span>
</span></pre></div>


            <div class="docstring"><p>Ask the model with streaming response.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>prompt</strong> (Union[str, Prompt, PromptChain]):
The prompt to process</li>
<li><strong>metadata</strong> (Dict, optional):
Metadata to pass to the completion call</li>
</ul>

<h6 id="yields">Yields</h6>

<ul>
<li><strong>Dict</strong>: Streaming response chunks</li>
</ul>
</div>


                            </div>
                            <div id="Model.ask" class="classattr">
                                        <input id="Model.ask-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">ask</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n"><a href="prompts.html#Prompt">monoai.prompts.Prompt</a></span><span class="p">,</span> <span class="n"><a href="prompts.html#PromptChain">monoai.prompts.PromptChain</a></span><span class="p">]</span>,</span><span class="param">	<span class="n">metadata</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{}</span></span><span class="return-annotation">) -> <span class="n">Dict</span>:</span></span>

                <label class="view-source-button" for="Model.ask-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Model.ask"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Model.ask-133"><a href="#Model.ask-133"><span class="linenos">133</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">ask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">],</span> <span class="n">metadata</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{})</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
</span><span id="Model.ask-134"><a href="#Model.ask-134"><span class="linenos">134</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Model.ask-135"><a href="#Model.ask-135"><span class="linenos">135</span></a><span class="sd">        Ask the model.</span>
</span><span id="Model.ask-136"><a href="#Model.ask-136"><span class="linenos">136</span></a>
</span><span id="Model.ask-137"><a href="#Model.ask-137"><span class="linenos">137</span></a><span class="sd">        Parameters</span>
</span><span id="Model.ask-138"><a href="#Model.ask-138"><span class="linenos">138</span></a><span class="sd">        ----------</span>
</span><span id="Model.ask-139"><a href="#Model.ask-139"><span class="linenos">139</span></a><span class="sd">        prompt : Union[str, Prompt]</span>
</span><span id="Model.ask-140"><a href="#Model.ask-140"><span class="linenos">140</span></a><span class="sd">            The prompt to process</span>
</span><span id="Model.ask-141"><a href="#Model.ask-141"><span class="linenos">141</span></a><span class="sd">        metadata : Dict, optional</span>
</span><span id="Model.ask-142"><a href="#Model.ask-142"><span class="linenos">142</span></a><span class="sd">            Metadata to pass to the completion call</span>
</span><span id="Model.ask-143"><a href="#Model.ask-143"><span class="linenos">143</span></a>
</span><span id="Model.ask-144"><a href="#Model.ask-144"><span class="linenos">144</span></a><span class="sd">        Returns</span>
</span><span id="Model.ask-145"><a href="#Model.ask-145"><span class="linenos">145</span></a><span class="sd">        -------</span>
</span><span id="Model.ask-146"><a href="#Model.ask-146"><span class="linenos">146</span></a><span class="sd">        Dict</span>
</span><span id="Model.ask-147"><a href="#Model.ask-147"><span class="linenos">147</span></a><span class="sd">            Dictionary containing:</span>
</span><span id="Model.ask-148"><a href="#Model.ask-148"><span class="linenos">148</span></a><span class="sd">            - response: The model&#39;s response</span>
</span><span id="Model.ask-149"><a href="#Model.ask-149"><span class="linenos">149</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="Model.ask-150"><a href="#Model.ask-150"><span class="linenos">150</span></a><span class="sd">            - model: Dictionary with provider and model name</span>
</span><span id="Model.ask-151"><a href="#Model.ask-151"><span class="linenos">151</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="Model.ask-152"><a href="#Model.ask-152"><span class="linenos">152</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="Model.ask-153"><a href="#Model.ask-153"><span class="linenos">153</span></a>
</span><span id="Model.ask-154"><a href="#Model.ask-154"><span class="linenos">154</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Model.ask-155"><a href="#Model.ask-155"><span class="linenos">155</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="Model.ask-156"><a href="#Model.ask-156"><span class="linenos">156</span></a>            <span class="n">prompt</span> <span class="o">=</span> <span class="n">Prompt</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
</span><span id="Model.ask-157"><a href="#Model.ask-157"><span class="linenos">157</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
</span><span id="Model.ask-158"><a href="#Model.ask-158"><span class="linenos">158</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_response</span><span class="p">(</span>
</span><span id="Model.ask-159"><a href="#Model.ask-159"><span class="linenos">159</span></a>            <span class="n">prompt</span><span class="p">,</span>
</span><span id="Model.ask-160"><a href="#Model.ask-160"><span class="linenos">160</span></a>            <span class="n">response</span>
</span><span id="Model.ask-161"><a href="#Model.ask-161"><span class="linenos">161</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Ask the model.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>prompt</strong> (Union[str, Prompt]):
The prompt to process</li>
<li><strong>metadata</strong> (Dict, optional):
Metadata to pass to the completion call</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>Dict</strong>: Dictionary containing:
<ul>
<li>response: The model's response</li>
<li>prompt: The original prompt</li>
<li>model: Dictionary with provider and model name</li>
<li>tokens: Token counts (if enabled)</li>
<li>cost: Cost calculation (if enabled)</li>
</ul></li>
</ul>
</div>


                            </div>
                </section>
                <section id="HostedModel">
                            <input id="HostedModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">HostedModel</span><wbr>(<span class="base"><a href="#Model">monoai.models.Model</a></span>, <span class="base">monoai.models._response_processor.ResponseProcessorMixin</span>, <span class="base">monoai.models._prompt_executor.PromptExecutorMixin</span>):

                <label class="view-source-button" for="HostedModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#HostedModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="HostedModel-9"><a href="#HostedModel-9"><span class="linenos"> 9</span></a><span class="k">class</span><span class="w"> </span><span class="nc">HostedModel</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="n">ResponseProcessorMixin</span><span class="p">,</span> <span class="n">PromptExecutorMixin</span><span class="p">):</span>
</span><span id="HostedModel-10"><a href="#HostedModel-10"><span class="linenos">10</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="HostedModel-11"><a href="#HostedModel-11"><span class="linenos">11</span></a><span class="sd">    HostedModel is a class for interacting with self-hosted AI language models.</span>
</span><span id="HostedModel-12"><a href="#HostedModel-12"><span class="linenos">12</span></a><span class="sd">    Currently support models deployed with VLLM.</span>
</span><span id="HostedModel-13"><a href="#HostedModel-13"><span class="linenos">13</span></a><span class="sd">    </span>
</span><span id="HostedModel-14"><a href="#HostedModel-14"><span class="linenos">14</span></a><span class="sd">    Examples</span>
</span><span id="HostedModel-15"><a href="#HostedModel-15"><span class="linenos">15</span></a><span class="sd">    --------</span>
</span><span id="HostedModel-16"><a href="#HostedModel-16"><span class="linenos">16</span></a><span class="sd">    Basic usage:</span>
</span><span id="HostedModel-17"><a href="#HostedModel-17"><span class="linenos">17</span></a><span class="sd">    ```</span>
</span><span id="HostedModel-18"><a href="#HostedModel-18"><span class="linenos">18</span></a><span class="sd">    model = HostedModel(url=&quot;http://localhost:8000&quot;, version=1, provider=&quot;openai&quot;, model=&quot;gpt-4&quot;)</span>
</span><span id="HostedModel-19"><a href="#HostedModel-19"><span class="linenos">19</span></a><span class="sd">    response = model.ask(&quot;What is the capital of France?&quot;)</span>
</span><span id="HostedModel-20"><a href="#HostedModel-20"><span class="linenos">20</span></a><span class="sd">    ```</span>
</span><span id="HostedModel-21"><a href="#HostedModel-21"><span class="linenos">21</span></a>
</span><span id="HostedModel-22"><a href="#HostedModel-22"><span class="linenos">22</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="HostedModel-23"><a href="#HostedModel-23"><span class="linenos">23</span></a>
</span><span id="HostedModel-24"><a href="#HostedModel-24"><span class="linenos">24</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="HostedModel-25"><a href="#HostedModel-25"><span class="linenos">25</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="HostedModel-26"><a href="#HostedModel-26"><span class="linenos">26</span></a>        <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="HostedModel-27"><a href="#HostedModel-27"><span class="linenos">27</span></a>        <span class="n">version</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="HostedModel-28"><a href="#HostedModel-28"><span class="linenos">28</span></a>        <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
</span><span id="HostedModel-29"><a href="#HostedModel-29"><span class="linenos">29</span></a>        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
</span><span id="HostedModel-30"><a href="#HostedModel-30"><span class="linenos">30</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">(),</span>
</span><span id="HostedModel-31"><a href="#HostedModel-31"><span class="linenos">31</span></a>        <span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
</span><span id="HostedModel-32"><a href="#HostedModel-32"><span class="linenos">32</span></a>        <span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="HostedModel-33"><a href="#HostedModel-33"><span class="linenos">33</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="HostedModel-34"><a href="#HostedModel-34"><span class="linenos">34</span></a>    <span class="p">):</span>
</span><span id="HostedModel-35"><a href="#HostedModel-35"><span class="linenos">35</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="HostedModel-36"><a href="#HostedModel-36"><span class="linenos">36</span></a><span class="sd">        Initialize a new Model instance.</span>
</span><span id="HostedModel-37"><a href="#HostedModel-37"><span class="linenos">37</span></a>
</span><span id="HostedModel-38"><a href="#HostedModel-38"><span class="linenos">38</span></a><span class="sd">        Parameters</span>
</span><span id="HostedModel-39"><a href="#HostedModel-39"><span class="linenos">39</span></a><span class="sd">        ----------</span>
</span><span id="HostedModel-40"><a href="#HostedModel-40"><span class="linenos">40</span></a><span class="sd">        provider : str</span>
</span><span id="HostedModel-41"><a href="#HostedModel-41"><span class="linenos">41</span></a><span class="sd">            Name of the provider (e.g., &#39;openai&#39;, &#39;anthropic&#39;)</span>
</span><span id="HostedModel-42"><a href="#HostedModel-42"><span class="linenos">42</span></a><span class="sd">        model : str</span>
</span><span id="HostedModel-43"><a href="#HostedModel-43"><span class="linenos">43</span></a><span class="sd">            Name of the model (e.g., &#39;gpt-4&#39;, &#39;claude-3&#39;)</span>
</span><span id="HostedModel-44"><a href="#HostedModel-44"><span class="linenos">44</span></a><span class="sd">        system_prompt : str | Sequence[str], optional</span>
</span><span id="HostedModel-45"><a href="#HostedModel-45"><span class="linenos">45</span></a><span class="sd">            System prompt or sequence of prompts</span>
</span><span id="HostedModel-46"><a href="#HostedModel-46"><span class="linenos">46</span></a><span class="sd">        count_tokens : bool, optional</span>
</span><span id="HostedModel-47"><a href="#HostedModel-47"><span class="linenos">47</span></a><span class="sd">            Whether to count tokens for each request</span>
</span><span id="HostedModel-48"><a href="#HostedModel-48"><span class="linenos">48</span></a><span class="sd">        count_cost : bool, optional</span>
</span><span id="HostedModel-49"><a href="#HostedModel-49"><span class="linenos">49</span></a><span class="sd">            Whether to calculate costs for each request</span>
</span><span id="HostedModel-50"><a href="#HostedModel-50"><span class="linenos">50</span></a><span class="sd">        max_tokens : int, optional</span>
</span><span id="HostedModel-51"><a href="#HostedModel-51"><span class="linenos">51</span></a><span class="sd">            Maximum number of tokens for each request</span>
</span><span id="HostedModel-52"><a href="#HostedModel-52"><span class="linenos">52</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="HostedModel-53"><a href="#HostedModel-53"><span class="linenos">53</span></a>
</span><span id="HostedModel-54"><a href="#HostedModel-54"><span class="linenos">54</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="HostedModel-55"><a href="#HostedModel-55"><span class="linenos">55</span></a>            <span class="n">provider</span><span class="o">=</span><span class="n">provider</span><span class="p">,</span>
</span><span id="HostedModel-56"><a href="#HostedModel-56"><span class="linenos">56</span></a>            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="HostedModel-57"><a href="#HostedModel-57"><span class="linenos">57</span></a>            <span class="n">count_tokens</span><span class="o">=</span><span class="n">count_tokens</span><span class="p">,</span> 
</span><span id="HostedModel-58"><a href="#HostedModel-58"><span class="linenos">58</span></a>            <span class="n">count_cost</span><span class="o">=</span><span class="n">count_cost</span><span class="p">,</span> 
</span><span id="HostedModel-59"><a href="#HostedModel-59"><span class="linenos">59</span></a>            <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span>
</span><span id="HostedModel-60"><a href="#HostedModel-60"><span class="linenos">60</span></a>        <span class="p">)</span>
</span><span id="HostedModel-61"><a href="#HostedModel-61"><span class="linenos">61</span></a>        
</span><span id="HostedModel-62"><a href="#HostedModel-62"><span class="linenos">62</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">url</span> <span class="o">=</span> <span class="n">url</span>
</span><span id="HostedModel-63"><a href="#HostedModel-63"><span class="linenos">63</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">version</span> <span class="o">=</span> <span class="n">version</span>
</span></pre></div>


            <div class="docstring"><p>HostedModel is a class for interacting with self-hosted AI language models.
Currently support models deployed with VLLM.</p>

<h6 id="examples">Examples</h6>

<p>Basic usage:</p>

<pre><code>model = HostedModel(url="http://localhost:8000", version=1, provider="openai", model="gpt-4")
response = model.ask("What is the capital of France?")
</code></pre>
</div>


                            <div id="HostedModel.__init__" class="classattr">
                                        <input id="HostedModel.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">HostedModel</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">url</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">version</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>,</span><span class="param">	<span class="n">provider</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">system_prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">()</span>,</span><span class="param">	<span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="HostedModel.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#HostedModel.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="HostedModel.__init__-24"><a href="#HostedModel.__init__-24"><span class="linenos">24</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="HostedModel.__init__-25"><a href="#HostedModel.__init__-25"><span class="linenos">25</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="HostedModel.__init__-26"><a href="#HostedModel.__init__-26"><span class="linenos">26</span></a>        <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="HostedModel.__init__-27"><a href="#HostedModel.__init__-27"><span class="linenos">27</span></a>        <span class="n">version</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="HostedModel.__init__-28"><a href="#HostedModel.__init__-28"><span class="linenos">28</span></a>        <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
</span><span id="HostedModel.__init__-29"><a href="#HostedModel.__init__-29"><span class="linenos">29</span></a>        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
</span><span id="HostedModel.__init__-30"><a href="#HostedModel.__init__-30"><span class="linenos">30</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">(),</span>
</span><span id="HostedModel.__init__-31"><a href="#HostedModel.__init__-31"><span class="linenos">31</span></a>        <span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
</span><span id="HostedModel.__init__-32"><a href="#HostedModel.__init__-32"><span class="linenos">32</span></a>        <span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="HostedModel.__init__-33"><a href="#HostedModel.__init__-33"><span class="linenos">33</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="HostedModel.__init__-34"><a href="#HostedModel.__init__-34"><span class="linenos">34</span></a>    <span class="p">):</span>
</span><span id="HostedModel.__init__-35"><a href="#HostedModel.__init__-35"><span class="linenos">35</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="HostedModel.__init__-36"><a href="#HostedModel.__init__-36"><span class="linenos">36</span></a><span class="sd">        Initialize a new Model instance.</span>
</span><span id="HostedModel.__init__-37"><a href="#HostedModel.__init__-37"><span class="linenos">37</span></a>
</span><span id="HostedModel.__init__-38"><a href="#HostedModel.__init__-38"><span class="linenos">38</span></a><span class="sd">        Parameters</span>
</span><span id="HostedModel.__init__-39"><a href="#HostedModel.__init__-39"><span class="linenos">39</span></a><span class="sd">        ----------</span>
</span><span id="HostedModel.__init__-40"><a href="#HostedModel.__init__-40"><span class="linenos">40</span></a><span class="sd">        provider : str</span>
</span><span id="HostedModel.__init__-41"><a href="#HostedModel.__init__-41"><span class="linenos">41</span></a><span class="sd">            Name of the provider (e.g., &#39;openai&#39;, &#39;anthropic&#39;)</span>
</span><span id="HostedModel.__init__-42"><a href="#HostedModel.__init__-42"><span class="linenos">42</span></a><span class="sd">        model : str</span>
</span><span id="HostedModel.__init__-43"><a href="#HostedModel.__init__-43"><span class="linenos">43</span></a><span class="sd">            Name of the model (e.g., &#39;gpt-4&#39;, &#39;claude-3&#39;)</span>
</span><span id="HostedModel.__init__-44"><a href="#HostedModel.__init__-44"><span class="linenos">44</span></a><span class="sd">        system_prompt : str | Sequence[str], optional</span>
</span><span id="HostedModel.__init__-45"><a href="#HostedModel.__init__-45"><span class="linenos">45</span></a><span class="sd">            System prompt or sequence of prompts</span>
</span><span id="HostedModel.__init__-46"><a href="#HostedModel.__init__-46"><span class="linenos">46</span></a><span class="sd">        count_tokens : bool, optional</span>
</span><span id="HostedModel.__init__-47"><a href="#HostedModel.__init__-47"><span class="linenos">47</span></a><span class="sd">            Whether to count tokens for each request</span>
</span><span id="HostedModel.__init__-48"><a href="#HostedModel.__init__-48"><span class="linenos">48</span></a><span class="sd">        count_cost : bool, optional</span>
</span><span id="HostedModel.__init__-49"><a href="#HostedModel.__init__-49"><span class="linenos">49</span></a><span class="sd">            Whether to calculate costs for each request</span>
</span><span id="HostedModel.__init__-50"><a href="#HostedModel.__init__-50"><span class="linenos">50</span></a><span class="sd">        max_tokens : int, optional</span>
</span><span id="HostedModel.__init__-51"><a href="#HostedModel.__init__-51"><span class="linenos">51</span></a><span class="sd">            Maximum number of tokens for each request</span>
</span><span id="HostedModel.__init__-52"><a href="#HostedModel.__init__-52"><span class="linenos">52</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="HostedModel.__init__-53"><a href="#HostedModel.__init__-53"><span class="linenos">53</span></a>
</span><span id="HostedModel.__init__-54"><a href="#HostedModel.__init__-54"><span class="linenos">54</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="HostedModel.__init__-55"><a href="#HostedModel.__init__-55"><span class="linenos">55</span></a>            <span class="n">provider</span><span class="o">=</span><span class="n">provider</span><span class="p">,</span>
</span><span id="HostedModel.__init__-56"><a href="#HostedModel.__init__-56"><span class="linenos">56</span></a>            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="HostedModel.__init__-57"><a href="#HostedModel.__init__-57"><span class="linenos">57</span></a>            <span class="n">count_tokens</span><span class="o">=</span><span class="n">count_tokens</span><span class="p">,</span> 
</span><span id="HostedModel.__init__-58"><a href="#HostedModel.__init__-58"><span class="linenos">58</span></a>            <span class="n">count_cost</span><span class="o">=</span><span class="n">count_cost</span><span class="p">,</span> 
</span><span id="HostedModel.__init__-59"><a href="#HostedModel.__init__-59"><span class="linenos">59</span></a>            <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span>
</span><span id="HostedModel.__init__-60"><a href="#HostedModel.__init__-60"><span class="linenos">60</span></a>        <span class="p">)</span>
</span><span id="HostedModel.__init__-61"><a href="#HostedModel.__init__-61"><span class="linenos">61</span></a>        
</span><span id="HostedModel.__init__-62"><a href="#HostedModel.__init__-62"><span class="linenos">62</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">url</span> <span class="o">=</span> <span class="n">url</span>
</span><span id="HostedModel.__init__-63"><a href="#HostedModel.__init__-63"><span class="linenos">63</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">version</span> <span class="o">=</span> <span class="n">version</span>
</span></pre></div>


            <div class="docstring"><p>Initialize a new Model instance.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>provider</strong> (str):
Name of the provider (e.g., 'openai', 'anthropic')</li>
<li><strong>model</strong> (str):
Name of the model (e.g., 'gpt-4', 'claude-3')</li>
<li><strong>system_prompt</strong> (str | Sequence[str], optional):
System prompt or sequence of prompts</li>
<li><strong>count_tokens</strong> (bool, optional):
Whether to count tokens for each request</li>
<li><strong>count_cost</strong> (bool, optional):
Whether to calculate costs for each request</li>
<li><strong>max_tokens</strong> (int, optional):
Maximum number of tokens for each request</li>
</ul>
</div>


                            </div>
                            <div id="HostedModel.url" class="classattr">
                                <div class="attr variable">
            <span class="name">url</span>

        
    </div>
    <a class="headerlink" href="#HostedModel.url"></a>
    
    

                            </div>
                            <div id="HostedModel.version" class="classattr">
                                <div class="attr variable">
            <span class="name">version</span>

        
    </div>
    <a class="headerlink" href="#HostedModel.version"></a>
    
    

                            </div>
                </section>
                <section id="MultiModel">
                            <input id="MultiModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">MultiModel</span><wbr>(<span class="base">monoai.models._base_model.BaseModel</span>, <span class="base">monoai.models._prompt_executor.PromptExecutorMixin</span>, <span class="base">monoai.models._response_processor.ResponseProcessorMixin</span>):

                <label class="view-source-button" for="MultiModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MultiModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MultiModel-11"><a href="#MultiModel-11"><span class="linenos"> 11</span></a><span class="k">class</span><span class="w"> </span><span class="nc">MultiModel</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">,</span> <span class="n">PromptExecutorMixin</span><span class="p">,</span> <span class="n">ResponseProcessorMixin</span><span class="p">):</span>
</span><span id="MultiModel-12"><a href="#MultiModel-12"><span class="linenos"> 12</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MultiModel-13"><a href="#MultiModel-13"><span class="linenos"> 13</span></a><span class="sd">    A class to execute prompts across multiple AI models in parallel.</span>
</span><span id="MultiModel-14"><a href="#MultiModel-14"><span class="linenos"> 14</span></a><span class="sd">    </span>
</span><span id="MultiModel-15"><a href="#MultiModel-15"><span class="linenos"> 15</span></a><span class="sd">    MultiModel manages a collection of AI models and enables parallel execution of prompts</span>
</span><span id="MultiModel-16"><a href="#MultiModel-16"><span class="linenos"> 16</span></a><span class="sd">    across all models. It&#39;s particularly useful for comparing model responses or</span>
</span><span id="MultiModel-17"><a href="#MultiModel-17"><span class="linenos"> 17</span></a><span class="sd">    implementing ensemble approaches.</span>
</span><span id="MultiModel-18"><a href="#MultiModel-18"><span class="linenos"> 18</span></a>
</span><span id="MultiModel-19"><a href="#MultiModel-19"><span class="linenos"> 19</span></a><span class="sd">    Examples</span>
</span><span id="MultiModel-20"><a href="#MultiModel-20"><span class="linenos"> 20</span></a><span class="sd">    --------</span>
</span><span id="MultiModel-21"><a href="#MultiModel-21"><span class="linenos"> 21</span></a><span class="sd">    Basic comparison of models:</span>
</span><span id="MultiModel-22"><a href="#MultiModel-22"><span class="linenos"> 22</span></a><span class="sd">    ```</span>
</span><span id="MultiModel-23"><a href="#MultiModel-23"><span class="linenos"> 23</span></a><span class="sd">    models = [</span>
</span><span id="MultiModel-24"><a href="#MultiModel-24"><span class="linenos"> 24</span></a><span class="sd">        {&quot;provider&quot;: &quot;openai&quot;, &quot;model&quot;: &quot;gpt-4&quot;},</span>
</span><span id="MultiModel-25"><a href="#MultiModel-25"><span class="linenos"> 25</span></a><span class="sd">        {&quot;provider&quot;: &quot;anthropic&quot;, &quot;model&quot;: &quot;claude-3&quot;}</span>
</span><span id="MultiModel-26"><a href="#MultiModel-26"><span class="linenos"> 26</span></a><span class="sd">    ]</span>
</span><span id="MultiModel-27"><a href="#MultiModel-27"><span class="linenos"> 27</span></a><span class="sd">    multi_model = MultiModel(models=models)</span>
</span><span id="MultiModel-28"><a href="#MultiModel-28"><span class="linenos"> 28</span></a><span class="sd">    prompt = Prompt(</span>
</span><span id="MultiModel-29"><a href="#MultiModel-29"><span class="linenos"> 29</span></a><span class="sd">        prompt=&quot;What is 2+2?&quot;,</span>
</span><span id="MultiModel-30"><a href="#MultiModel-30"><span class="linenos"> 30</span></a><span class="sd">        response_type=int</span>
</span><span id="MultiModel-31"><a href="#MultiModel-31"><span class="linenos"> 31</span></a><span class="sd">    )</span>
</span><span id="MultiModel-32"><a href="#MultiModel-32"><span class="linenos"> 32</span></a><span class="sd">    responses = multi_model.ask(prompt)</span>
</span><span id="MultiModel-33"><a href="#MultiModel-33"><span class="linenos"> 33</span></a><span class="sd">    for resp in responses:</span>
</span><span id="MultiModel-34"><a href="#MultiModel-34"><span class="linenos"> 34</span></a><span class="sd">        print(f&quot;{resp[&#39;model&#39;][&#39;name&#39;]}: {resp[&#39;response&#39;]}&quot;)</span>
</span><span id="MultiModel-35"><a href="#MultiModel-35"><span class="linenos"> 35</span></a><span class="sd">    ```</span>
</span><span id="MultiModel-36"><a href="#MultiModel-36"><span class="linenos"> 36</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="MultiModel-37"><a href="#MultiModel-37"><span class="linenos"> 37</span></a>
</span><span id="MultiModel-38"><a href="#MultiModel-38"><span class="linenos"> 38</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="MultiModel-39"><a href="#MultiModel-39"><span class="linenos"> 39</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="MultiModel-40"><a href="#MultiModel-40"><span class="linenos"> 40</span></a>        <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> 
</span><span id="MultiModel-41"><a href="#MultiModel-41"><span class="linenos"> 41</span></a>        <span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
</span><span id="MultiModel-42"><a href="#MultiModel-42"><span class="linenos"> 42</span></a>        <span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="MultiModel-43"><a href="#MultiModel-43"><span class="linenos"> 43</span></a>    <span class="p">):</span>
</span><span id="MultiModel-44"><a href="#MultiModel-44"><span class="linenos"> 44</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MultiModel-45"><a href="#MultiModel-45"><span class="linenos"> 45</span></a><span class="sd">        Initialize a new MultiModel instance.</span>
</span><span id="MultiModel-46"><a href="#MultiModel-46"><span class="linenos"> 46</span></a>
</span><span id="MultiModel-47"><a href="#MultiModel-47"><span class="linenos"> 47</span></a><span class="sd">        Parameters</span>
</span><span id="MultiModel-48"><a href="#MultiModel-48"><span class="linenos"> 48</span></a><span class="sd">        ----------</span>
</span><span id="MultiModel-49"><a href="#MultiModel-49"><span class="linenos"> 49</span></a><span class="sd">        models : List[Dict[str, str]]</span>
</span><span id="MultiModel-50"><a href="#MultiModel-50"><span class="linenos"> 50</span></a><span class="sd">            List of dictionaries with provider and model information</span>
</span><span id="MultiModel-51"><a href="#MultiModel-51"><span class="linenos"> 51</span></a><span class="sd">        count_tokens : bool, optional</span>
</span><span id="MultiModel-52"><a href="#MultiModel-52"><span class="linenos"> 52</span></a><span class="sd">            Whether to count tokens for each request</span>
</span><span id="MultiModel-53"><a href="#MultiModel-53"><span class="linenos"> 53</span></a><span class="sd">        count_cost : bool, optional</span>
</span><span id="MultiModel-54"><a href="#MultiModel-54"><span class="linenos"> 54</span></a><span class="sd">            Whether to calculate costs for each request</span>
</span><span id="MultiModel-55"><a href="#MultiModel-55"><span class="linenos"> 55</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultiModel-56"><a href="#MultiModel-56"><span class="linenos"> 56</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">count_tokens</span><span class="p">,</span> <span class="n">count_cost</span><span class="p">)</span>
</span><span id="MultiModel-57"><a href="#MultiModel-57"><span class="linenos"> 57</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_models</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="MultiModel-58"><a href="#MultiModel-58"><span class="linenos"> 58</span></a>            <span class="n">Model</span><span class="p">(</span>
</span><span id="MultiModel-59"><a href="#MultiModel-59"><span class="linenos"> 59</span></a>                <span class="n">provider</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;provider&#39;</span><span class="p">],</span>
</span><span id="MultiModel-60"><a href="#MultiModel-60"><span class="linenos"> 60</span></a>                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">],</span>
</span><span id="MultiModel-61"><a href="#MultiModel-61"><span class="linenos"> 61</span></a>                <span class="n">count_tokens</span><span class="o">=</span><span class="n">count_tokens</span><span class="p">,</span>
</span><span id="MultiModel-62"><a href="#MultiModel-62"><span class="linenos"> 62</span></a>                <span class="n">count_cost</span><span class="o">=</span><span class="n">count_cost</span>
</span><span id="MultiModel-63"><a href="#MultiModel-63"><span class="linenos"> 63</span></a>            <span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span>
</span><span id="MultiModel-64"><a href="#MultiModel-64"><span class="linenos"> 64</span></a>        <span class="p">]</span>
</span><span id="MultiModel-65"><a href="#MultiModel-65"><span class="linenos"> 65</span></a>
</span><span id="MultiModel-66"><a href="#MultiModel-66"><span class="linenos"> 66</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_task</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
</span><span id="MultiModel-67"><a href="#MultiModel-67"><span class="linenos"> 67</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MultiModel-68"><a href="#MultiModel-68"><span class="linenos"> 68</span></a><span class="sd">        Execute a single model task asynchronously.</span>
</span><span id="MultiModel-69"><a href="#MultiModel-69"><span class="linenos"> 69</span></a>
</span><span id="MultiModel-70"><a href="#MultiModel-70"><span class="linenos"> 70</span></a><span class="sd">        Parameters</span>
</span><span id="MultiModel-71"><a href="#MultiModel-71"><span class="linenos"> 71</span></a><span class="sd">        ----------</span>
</span><span id="MultiModel-72"><a href="#MultiModel-72"><span class="linenos"> 72</span></a><span class="sd">        model : Model</span>
</span><span id="MultiModel-73"><a href="#MultiModel-73"><span class="linenos"> 73</span></a><span class="sd">            The model instance to use</span>
</span><span id="MultiModel-74"><a href="#MultiModel-74"><span class="linenos"> 74</span></a><span class="sd">        prompt : Union[str, Prompt, PromptChain]</span>
</span><span id="MultiModel-75"><a href="#MultiModel-75"><span class="linenos"> 75</span></a><span class="sd">            The prompt to process</span>
</span><span id="MultiModel-76"><a href="#MultiModel-76"><span class="linenos"> 76</span></a>
</span><span id="MultiModel-77"><a href="#MultiModel-77"><span class="linenos"> 77</span></a><span class="sd">        Returns</span>
</span><span id="MultiModel-78"><a href="#MultiModel-78"><span class="linenos"> 78</span></a><span class="sd">        -------</span>
</span><span id="MultiModel-79"><a href="#MultiModel-79"><span class="linenos"> 79</span></a><span class="sd">        Dict</span>
</span><span id="MultiModel-80"><a href="#MultiModel-80"><span class="linenos"> 80</span></a><span class="sd">            Dictionary containing:</span>
</span><span id="MultiModel-81"><a href="#MultiModel-81"><span class="linenos"> 81</span></a><span class="sd">            - response: The model&#39;s response</span>
</span><span id="MultiModel-82"><a href="#MultiModel-82"><span class="linenos"> 82</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="MultiModel-83"><a href="#MultiModel-83"><span class="linenos"> 83</span></a><span class="sd">            - model: Dictionary with provider and model name</span>
</span><span id="MultiModel-84"><a href="#MultiModel-84"><span class="linenos"> 84</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="MultiModel-85"><a href="#MultiModel-85"><span class="linenos"> 85</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="MultiModel-86"><a href="#MultiModel-86"><span class="linenos"> 86</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultiModel-87"><a href="#MultiModel-87"><span class="linenos"> 87</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_async</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">_agent</span><span class="p">)</span>
</span><span id="MultiModel-88"><a href="#MultiModel-88"><span class="linenos"> 88</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_response</span><span class="p">(</span>
</span><span id="MultiModel-89"><a href="#MultiModel-89"><span class="linenos"> 89</span></a>            <span class="n">prompt</span><span class="p">,</span>
</span><span id="MultiModel-90"><a href="#MultiModel-90"><span class="linenos"> 90</span></a>            <span class="n">response</span><span class="p">,</span>
</span><span id="MultiModel-91"><a href="#MultiModel-91"><span class="linenos"> 91</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">provider</span><span class="p">,</span>
</span><span id="MultiModel-92"><a href="#MultiModel-92"><span class="linenos"> 92</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="MultiModel-93"><a href="#MultiModel-93"><span class="linenos"> 93</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_count_tokens</span><span class="p">,</span>
</span><span id="MultiModel-94"><a href="#MultiModel-94"><span class="linenos"> 94</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_count_cost</span>
</span><span id="MultiModel-95"><a href="#MultiModel-95"><span class="linenos"> 95</span></a>        <span class="p">)</span>
</span><span id="MultiModel-96"><a href="#MultiModel-96"><span class="linenos"> 96</span></a>
</span><span id="MultiModel-97"><a href="#MultiModel-97"><span class="linenos"> 97</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_ask_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
</span><span id="MultiModel-98"><a href="#MultiModel-98"><span class="linenos"> 98</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MultiModel-99"><a href="#MultiModel-99"><span class="linenos"> 99</span></a><span class="sd">        Ask all models asynchronously.</span>
</span><span id="MultiModel-100"><a href="#MultiModel-100"><span class="linenos">100</span></a>
</span><span id="MultiModel-101"><a href="#MultiModel-101"><span class="linenos">101</span></a><span class="sd">        Parameters</span>
</span><span id="MultiModel-102"><a href="#MultiModel-102"><span class="linenos">102</span></a><span class="sd">        ----------</span>
</span><span id="MultiModel-103"><a href="#MultiModel-103"><span class="linenos">103</span></a><span class="sd">        prompt : Union[str, Prompt, PromptChain]</span>
</span><span id="MultiModel-104"><a href="#MultiModel-104"><span class="linenos">104</span></a><span class="sd">            The prompt to process across all models</span>
</span><span id="MultiModel-105"><a href="#MultiModel-105"><span class="linenos">105</span></a>
</span><span id="MultiModel-106"><a href="#MultiModel-106"><span class="linenos">106</span></a><span class="sd">        Returns</span>
</span><span id="MultiModel-107"><a href="#MultiModel-107"><span class="linenos">107</span></a><span class="sd">        -------</span>
</span><span id="MultiModel-108"><a href="#MultiModel-108"><span class="linenos">108</span></a><span class="sd">        List[Dict]</span>
</span><span id="MultiModel-109"><a href="#MultiModel-109"><span class="linenos">109</span></a><span class="sd">            List of response dictionaries, one per model, each containing:</span>
</span><span id="MultiModel-110"><a href="#MultiModel-110"><span class="linenos">110</span></a><span class="sd">            - response: The model&#39;s response</span>
</span><span id="MultiModel-111"><a href="#MultiModel-111"><span class="linenos">111</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="MultiModel-112"><a href="#MultiModel-112"><span class="linenos">112</span></a><span class="sd">            - model: Dictionary with provider and model name</span>
</span><span id="MultiModel-113"><a href="#MultiModel-113"><span class="linenos">113</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="MultiModel-114"><a href="#MultiModel-114"><span class="linenos">114</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="MultiModel-115"><a href="#MultiModel-115"><span class="linenos">115</span></a>
</span><span id="MultiModel-116"><a href="#MultiModel-116"><span class="linenos">116</span></a><span class="sd">        Examples</span>
</span><span id="MultiModel-117"><a href="#MultiModel-117"><span class="linenos">117</span></a><span class="sd">        --------</span>
</span><span id="MultiModel-118"><a href="#MultiModel-118"><span class="linenos">118</span></a><span class="sd">        Using async/await:</span>
</span><span id="MultiModel-119"><a href="#MultiModel-119"><span class="linenos">119</span></a><span class="sd">            &gt;&gt;&gt; responses = await multi_model.ask_async(&quot;What is 2+2?&quot;)</span>
</span><span id="MultiModel-120"><a href="#MultiModel-120"><span class="linenos">120</span></a><span class="sd">            &gt;&gt;&gt; for resp in responses:</span>
</span><span id="MultiModel-121"><a href="#MultiModel-121"><span class="linenos">121</span></a><span class="sd">            ...     print(f&quot;{resp[&#39;model&#39;][&#39;name&#39;]}: {resp[&#39;response&#39;]}&quot;)</span>
</span><span id="MultiModel-122"><a href="#MultiModel-122"><span class="linenos">122</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultiModel-123"><a href="#MultiModel-123"><span class="linenos">123</span></a>        <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_task</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_models</span><span class="p">]</span>
</span><span id="MultiModel-124"><a href="#MultiModel-124"><span class="linenos">124</span></a>        <span class="k">return</span> <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">*</span><span class="n">tasks</span><span class="p">)</span>
</span><span id="MultiModel-125"><a href="#MultiModel-125"><span class="linenos">125</span></a>
</span><span id="MultiModel-126"><a href="#MultiModel-126"><span class="linenos">126</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">ask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
</span><span id="MultiModel-127"><a href="#MultiModel-127"><span class="linenos">127</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MultiModel-128"><a href="#MultiModel-128"><span class="linenos">128</span></a><span class="sd">        Ask all models.</span>
</span><span id="MultiModel-129"><a href="#MultiModel-129"><span class="linenos">129</span></a>
</span><span id="MultiModel-130"><a href="#MultiModel-130"><span class="linenos">130</span></a><span class="sd">        Parameters</span>
</span><span id="MultiModel-131"><a href="#MultiModel-131"><span class="linenos">131</span></a><span class="sd">        ----------</span>
</span><span id="MultiModel-132"><a href="#MultiModel-132"><span class="linenos">132</span></a><span class="sd">        prompt : Union[str, Prompt]</span>
</span><span id="MultiModel-133"><a href="#MultiModel-133"><span class="linenos">133</span></a><span class="sd">            The prompt to process across all models</span>
</span><span id="MultiModel-134"><a href="#MultiModel-134"><span class="linenos">134</span></a>
</span><span id="MultiModel-135"><a href="#MultiModel-135"><span class="linenos">135</span></a><span class="sd">        Returns</span>
</span><span id="MultiModel-136"><a href="#MultiModel-136"><span class="linenos">136</span></a><span class="sd">        -------</span>
</span><span id="MultiModel-137"><a href="#MultiModel-137"><span class="linenos">137</span></a><span class="sd">        List[Dict]</span>
</span><span id="MultiModel-138"><a href="#MultiModel-138"><span class="linenos">138</span></a><span class="sd">            List of response dictionaries, one per model, each containing:</span>
</span><span id="MultiModel-139"><a href="#MultiModel-139"><span class="linenos">139</span></a><span class="sd">            - response: The model&#39;s response</span>
</span><span id="MultiModel-140"><a href="#MultiModel-140"><span class="linenos">140</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="MultiModel-141"><a href="#MultiModel-141"><span class="linenos">141</span></a><span class="sd">            - model: Dictionary with provider and model name</span>
</span><span id="MultiModel-142"><a href="#MultiModel-142"><span class="linenos">142</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="MultiModel-143"><a href="#MultiModel-143"><span class="linenos">143</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="MultiModel-144"><a href="#MultiModel-144"><span class="linenos">144</span></a>
</span><span id="MultiModel-145"><a href="#MultiModel-145"><span class="linenos">145</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultiModel-146"><a href="#MultiModel-146"><span class="linenos">146</span></a>        <span class="k">return</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ask_async</span><span class="p">(</span><span class="n">prompt</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>A class to execute prompts across multiple AI models in parallel.</p>

<p>MultiModel manages a collection of AI models and enables parallel execution of prompts
across all models. It's particularly useful for comparing model responses or
implementing ensemble approaches.</p>

<h6 id="examples">Examples</h6>

<p>Basic comparison of models:</p>

<pre><code>models = [
    {"provider": "openai", "model": "gpt-4"},
    {"provider": "anthropic", "model": "claude-3"}
]
multi_model = MultiModel(models=models)
prompt = Prompt(
    prompt="What is 2+2?",
    response_type=int
)
responses = multi_model.ask(prompt)
for resp in responses:
    print(f"{resp['model']['name']}: {resp['response']}")
</code></pre>
</div>


                            <div id="MultiModel.__init__" class="classattr">
                                        <input id="MultiModel.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">MultiModel</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span>,</span><span class="param">	<span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span>)</span>

                <label class="view-source-button" for="MultiModel.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MultiModel.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MultiModel.__init__-38"><a href="#MultiModel.__init__-38"><span class="linenos">38</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="MultiModel.__init__-39"><a href="#MultiModel.__init__-39"><span class="linenos">39</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="MultiModel.__init__-40"><a href="#MultiModel.__init__-40"><span class="linenos">40</span></a>        <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> 
</span><span id="MultiModel.__init__-41"><a href="#MultiModel.__init__-41"><span class="linenos">41</span></a>        <span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
</span><span id="MultiModel.__init__-42"><a href="#MultiModel.__init__-42"><span class="linenos">42</span></a>        <span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="MultiModel.__init__-43"><a href="#MultiModel.__init__-43"><span class="linenos">43</span></a>    <span class="p">):</span>
</span><span id="MultiModel.__init__-44"><a href="#MultiModel.__init__-44"><span class="linenos">44</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MultiModel.__init__-45"><a href="#MultiModel.__init__-45"><span class="linenos">45</span></a><span class="sd">        Initialize a new MultiModel instance.</span>
</span><span id="MultiModel.__init__-46"><a href="#MultiModel.__init__-46"><span class="linenos">46</span></a>
</span><span id="MultiModel.__init__-47"><a href="#MultiModel.__init__-47"><span class="linenos">47</span></a><span class="sd">        Parameters</span>
</span><span id="MultiModel.__init__-48"><a href="#MultiModel.__init__-48"><span class="linenos">48</span></a><span class="sd">        ----------</span>
</span><span id="MultiModel.__init__-49"><a href="#MultiModel.__init__-49"><span class="linenos">49</span></a><span class="sd">        models : List[Dict[str, str]]</span>
</span><span id="MultiModel.__init__-50"><a href="#MultiModel.__init__-50"><span class="linenos">50</span></a><span class="sd">            List of dictionaries with provider and model information</span>
</span><span id="MultiModel.__init__-51"><a href="#MultiModel.__init__-51"><span class="linenos">51</span></a><span class="sd">        count_tokens : bool, optional</span>
</span><span id="MultiModel.__init__-52"><a href="#MultiModel.__init__-52"><span class="linenos">52</span></a><span class="sd">            Whether to count tokens for each request</span>
</span><span id="MultiModel.__init__-53"><a href="#MultiModel.__init__-53"><span class="linenos">53</span></a><span class="sd">        count_cost : bool, optional</span>
</span><span id="MultiModel.__init__-54"><a href="#MultiModel.__init__-54"><span class="linenos">54</span></a><span class="sd">            Whether to calculate costs for each request</span>
</span><span id="MultiModel.__init__-55"><a href="#MultiModel.__init__-55"><span class="linenos">55</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultiModel.__init__-56"><a href="#MultiModel.__init__-56"><span class="linenos">56</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">count_tokens</span><span class="p">,</span> <span class="n">count_cost</span><span class="p">)</span>
</span><span id="MultiModel.__init__-57"><a href="#MultiModel.__init__-57"><span class="linenos">57</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_models</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="MultiModel.__init__-58"><a href="#MultiModel.__init__-58"><span class="linenos">58</span></a>            <span class="n">Model</span><span class="p">(</span>
</span><span id="MultiModel.__init__-59"><a href="#MultiModel.__init__-59"><span class="linenos">59</span></a>                <span class="n">provider</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;provider&#39;</span><span class="p">],</span>
</span><span id="MultiModel.__init__-60"><a href="#MultiModel.__init__-60"><span class="linenos">60</span></a>                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">],</span>
</span><span id="MultiModel.__init__-61"><a href="#MultiModel.__init__-61"><span class="linenos">61</span></a>                <span class="n">count_tokens</span><span class="o">=</span><span class="n">count_tokens</span><span class="p">,</span>
</span><span id="MultiModel.__init__-62"><a href="#MultiModel.__init__-62"><span class="linenos">62</span></a>                <span class="n">count_cost</span><span class="o">=</span><span class="n">count_cost</span>
</span><span id="MultiModel.__init__-63"><a href="#MultiModel.__init__-63"><span class="linenos">63</span></a>            <span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span>
</span><span id="MultiModel.__init__-64"><a href="#MultiModel.__init__-64"><span class="linenos">64</span></a>        <span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Initialize a new MultiModel instance.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>models</strong> (List[Dict[str, str]]):
List of dictionaries with provider and model information</li>
<li><strong>count_tokens</strong> (bool, optional):
Whether to count tokens for each request</li>
<li><strong>count_cost</strong> (bool, optional):
Whether to calculate costs for each request</li>
</ul>
</div>


                            </div>
                            <div id="MultiModel.ask" class="classattr">
                                        <input id="MultiModel.ask-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">ask</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n"><a href="prompts.html#Prompt">monoai.prompts.Prompt</a></span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="MultiModel.ask-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MultiModel.ask"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MultiModel.ask-126"><a href="#MultiModel.ask-126"><span class="linenos">126</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">ask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
</span><span id="MultiModel.ask-127"><a href="#MultiModel.ask-127"><span class="linenos">127</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MultiModel.ask-128"><a href="#MultiModel.ask-128"><span class="linenos">128</span></a><span class="sd">        Ask all models.</span>
</span><span id="MultiModel.ask-129"><a href="#MultiModel.ask-129"><span class="linenos">129</span></a>
</span><span id="MultiModel.ask-130"><a href="#MultiModel.ask-130"><span class="linenos">130</span></a><span class="sd">        Parameters</span>
</span><span id="MultiModel.ask-131"><a href="#MultiModel.ask-131"><span class="linenos">131</span></a><span class="sd">        ----------</span>
</span><span id="MultiModel.ask-132"><a href="#MultiModel.ask-132"><span class="linenos">132</span></a><span class="sd">        prompt : Union[str, Prompt]</span>
</span><span id="MultiModel.ask-133"><a href="#MultiModel.ask-133"><span class="linenos">133</span></a><span class="sd">            The prompt to process across all models</span>
</span><span id="MultiModel.ask-134"><a href="#MultiModel.ask-134"><span class="linenos">134</span></a>
</span><span id="MultiModel.ask-135"><a href="#MultiModel.ask-135"><span class="linenos">135</span></a><span class="sd">        Returns</span>
</span><span id="MultiModel.ask-136"><a href="#MultiModel.ask-136"><span class="linenos">136</span></a><span class="sd">        -------</span>
</span><span id="MultiModel.ask-137"><a href="#MultiModel.ask-137"><span class="linenos">137</span></a><span class="sd">        List[Dict]</span>
</span><span id="MultiModel.ask-138"><a href="#MultiModel.ask-138"><span class="linenos">138</span></a><span class="sd">            List of response dictionaries, one per model, each containing:</span>
</span><span id="MultiModel.ask-139"><a href="#MultiModel.ask-139"><span class="linenos">139</span></a><span class="sd">            - response: The model&#39;s response</span>
</span><span id="MultiModel.ask-140"><a href="#MultiModel.ask-140"><span class="linenos">140</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="MultiModel.ask-141"><a href="#MultiModel.ask-141"><span class="linenos">141</span></a><span class="sd">            - model: Dictionary with provider and model name</span>
</span><span id="MultiModel.ask-142"><a href="#MultiModel.ask-142"><span class="linenos">142</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="MultiModel.ask-143"><a href="#MultiModel.ask-143"><span class="linenos">143</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="MultiModel.ask-144"><a href="#MultiModel.ask-144"><span class="linenos">144</span></a>
</span><span id="MultiModel.ask-145"><a href="#MultiModel.ask-145"><span class="linenos">145</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultiModel.ask-146"><a href="#MultiModel.ask-146"><span class="linenos">146</span></a>        <span class="k">return</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ask_async</span><span class="p">(</span><span class="n">prompt</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Ask all models.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>prompt</strong> (Union[str, Prompt]):
The prompt to process across all models</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>List[Dict]</strong>: List of response dictionaries, one per model, each containing:
<ul>
<li>response: The model's response</li>
<li>prompt: The original prompt</li>
<li>model: Dictionary with provider and model name</li>
<li>tokens: Token counts (if enabled)</li>
<li>cost: Cost calculation (if enabled)</li>
</ul></li>
</ul>
</div>


                            </div>
                </section>
                <section id="CollaborativeModel">
                            <input id="CollaborativeModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">CollaborativeModel</span><wbr>(<span class="base">monoai.models._base_model.BaseModel</span>, <span class="base">monoai.models._prompt_executor.PromptExecutorMixin</span>, <span class="base">monoai.models._response_processor.ResponseProcessorMixin</span>):

                <label class="view-source-button" for="CollaborativeModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CollaborativeModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CollaborativeModel-12"><a href="#CollaborativeModel-12"><span class="linenos"> 12</span></a><span class="k">class</span><span class="w"> </span><span class="nc">CollaborativeModel</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">,</span> <span class="n">PromptExecutorMixin</span><span class="p">,</span> <span class="n">ResponseProcessorMixin</span><span class="p">):</span>
</span><span id="CollaborativeModel-13"><a href="#CollaborativeModel-13"><span class="linenos"> 13</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-14"><a href="#CollaborativeModel-14"><span class="linenos"> 14</span></a><span class="sd">    A class to implement collaborative decision making across multiple AI models.</span>
</span><span id="CollaborativeModel-15"><a href="#CollaborativeModel-15"><span class="linenos"> 15</span></a><span class="sd">    </span>
</span><span id="CollaborativeModel-16"><a href="#CollaborativeModel-16"><span class="linenos"> 16</span></a><span class="sd">    CollaborativeModel manages a collection of AI models and an aggregator model.</span>
</span><span id="CollaborativeModel-17"><a href="#CollaborativeModel-17"><span class="linenos"> 17</span></a><span class="sd">    It executes prompts across all models in parallel and then uses the aggregator</span>
</span><span id="CollaborativeModel-18"><a href="#CollaborativeModel-18"><span class="linenos"> 18</span></a><span class="sd">    to synthesize a final response based on all individual responses.</span>
</span><span id="CollaborativeModel-19"><a href="#CollaborativeModel-19"><span class="linenos"> 19</span></a>
</span><span id="CollaborativeModel-20"><a href="#CollaborativeModel-20"><span class="linenos"> 20</span></a><span class="sd">    Examples</span>
</span><span id="CollaborativeModel-21"><a href="#CollaborativeModel-21"><span class="linenos"> 21</span></a><span class="sd">    --------</span>
</span><span id="CollaborativeModel-22"><a href="#CollaborativeModel-22"><span class="linenos"> 22</span></a><span class="sd">    Basic collaborative analysis:</span>
</span><span id="CollaborativeModel-23"><a href="#CollaborativeModel-23"><span class="linenos"> 23</span></a><span class="sd">    ```</span>
</span><span id="CollaborativeModel-24"><a href="#CollaborativeModel-24"><span class="linenos"> 24</span></a><span class="sd">    models = [</span>
</span><span id="CollaborativeModel-25"><a href="#CollaborativeModel-25"><span class="linenos"> 25</span></a><span class="sd">        {&quot;provider&quot;: &quot;openai&quot;, &quot;model&quot;: &quot;gpt-4&quot;},</span>
</span><span id="CollaborativeModel-26"><a href="#CollaborativeModel-26"><span class="linenos"> 26</span></a><span class="sd">        {&quot;provider&quot;: &quot;anthropic&quot;, &quot;model&quot;: &quot;claude-3&quot;}</span>
</span><span id="CollaborativeModel-27"><a href="#CollaborativeModel-27"><span class="linenos"> 27</span></a><span class="sd">    ]</span>
</span><span id="CollaborativeModel-28"><a href="#CollaborativeModel-28"><span class="linenos"> 28</span></a><span class="sd">    aggregator = {&quot;provider&quot;: &quot;openai&quot;, &quot;model&quot;: &quot;gpt-4&quot;}</span>
</span><span id="CollaborativeModel-29"><a href="#CollaborativeModel-29"><span class="linenos"> 29</span></a><span class="sd">    collab = CollaborativeModel(models=models, aggregator=aggregator)</span>
</span><span id="CollaborativeModel-30"><a href="#CollaborativeModel-30"><span class="linenos"> 30</span></a><span class="sd">    response = collab.ask(&quot;Explain quantum computing&quot;)</span>
</span><span id="CollaborativeModel-31"><a href="#CollaborativeModel-31"><span class="linenos"> 31</span></a><span class="sd">    print(response[&quot;response&quot;])  # Aggregated response</span>
</span><span id="CollaborativeModel-32"><a href="#CollaborativeModel-32"><span class="linenos"> 32</span></a><span class="sd">    for ind_resp in response[&quot;individual_responses&quot;]:</span>
</span><span id="CollaborativeModel-33"><a href="#CollaborativeModel-33"><span class="linenos"> 33</span></a><span class="sd">        print(f&quot;{ind_resp[&#39;model&#39;][&#39;name&#39;]}: {ind_resp[&#39;response&#39;]}&quot;)</span>
</span><span id="CollaborativeModel-34"><a href="#CollaborativeModel-34"><span class="linenos"> 34</span></a><span class="sd">    ```</span>
</span><span id="CollaborativeModel-35"><a href="#CollaborativeModel-35"><span class="linenos"> 35</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-36"><a href="#CollaborativeModel-36"><span class="linenos"> 36</span></a>
</span><span id="CollaborativeModel-37"><a href="#CollaborativeModel-37"><span class="linenos"> 37</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="CollaborativeModel-38"><a href="#CollaborativeModel-38"><span class="linenos"> 38</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="CollaborativeModel-39"><a href="#CollaborativeModel-39"><span class="linenos"> 39</span></a>        <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
</span><span id="CollaborativeModel-40"><a href="#CollaborativeModel-40"><span class="linenos"> 40</span></a>        <span class="n">aggregator</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
</span><span id="CollaborativeModel-41"><a href="#CollaborativeModel-41"><span class="linenos"> 41</span></a>        <span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="CollaborativeModel-42"><a href="#CollaborativeModel-42"><span class="linenos"> 42</span></a>        <span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="CollaborativeModel-43"><a href="#CollaborativeModel-43"><span class="linenos"> 43</span></a>    <span class="p">):</span>
</span><span id="CollaborativeModel-44"><a href="#CollaborativeModel-44"><span class="linenos"> 44</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-45"><a href="#CollaborativeModel-45"><span class="linenos"> 45</span></a><span class="sd">        Initialize a new CollaborativeModel instance.</span>
</span><span id="CollaborativeModel-46"><a href="#CollaborativeModel-46"><span class="linenos"> 46</span></a>
</span><span id="CollaborativeModel-47"><a href="#CollaborativeModel-47"><span class="linenos"> 47</span></a><span class="sd">        Parameters</span>
</span><span id="CollaborativeModel-48"><a href="#CollaborativeModel-48"><span class="linenos"> 48</span></a><span class="sd">        ----------</span>
</span><span id="CollaborativeModel-49"><a href="#CollaborativeModel-49"><span class="linenos"> 49</span></a><span class="sd">        models : List[Dict[str, str]]</span>
</span><span id="CollaborativeModel-50"><a href="#CollaborativeModel-50"><span class="linenos"> 50</span></a><span class="sd">            List of dictionaries with provider and model information</span>
</span><span id="CollaborativeModel-51"><a href="#CollaborativeModel-51"><span class="linenos"> 51</span></a><span class="sd">        aggregator : Dict[str, str]</span>
</span><span id="CollaborativeModel-52"><a href="#CollaborativeModel-52"><span class="linenos"> 52</span></a><span class="sd">            Dictionary with provider and model information for the aggregator</span>
</span><span id="CollaborativeModel-53"><a href="#CollaborativeModel-53"><span class="linenos"> 53</span></a><span class="sd">        count_tokens : bool, optional</span>
</span><span id="CollaborativeModel-54"><a href="#CollaborativeModel-54"><span class="linenos"> 54</span></a><span class="sd">            Whether to count tokens for each request</span>
</span><span id="CollaborativeModel-55"><a href="#CollaborativeModel-55"><span class="linenos"> 55</span></a><span class="sd">        count_cost : bool, optional</span>
</span><span id="CollaborativeModel-56"><a href="#CollaborativeModel-56"><span class="linenos"> 56</span></a><span class="sd">            Whether to calculate costs for each request</span>
</span><span id="CollaborativeModel-57"><a href="#CollaborativeModel-57"><span class="linenos"> 57</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-58"><a href="#CollaborativeModel-58"><span class="linenos"> 58</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">count_tokens</span><span class="p">,</span> <span class="n">count_cost</span><span class="p">)</span>
</span><span id="CollaborativeModel-59"><a href="#CollaborativeModel-59"><span class="linenos"> 59</span></a>
</span><span id="CollaborativeModel-60"><a href="#CollaborativeModel-60"><span class="linenos"> 60</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_multi_model</span> <span class="o">=</span> <span class="n">MultiModel</span><span class="p">(</span>
</span><span id="CollaborativeModel-61"><a href="#CollaborativeModel-61"><span class="linenos"> 61</span></a>            <span class="n">models</span><span class="o">=</span><span class="n">models</span><span class="p">,</span>
</span><span id="CollaborativeModel-62"><a href="#CollaborativeModel-62"><span class="linenos"> 62</span></a>            <span class="n">count_tokens</span><span class="o">=</span><span class="n">count_tokens</span><span class="p">,</span>
</span><span id="CollaborativeModel-63"><a href="#CollaborativeModel-63"><span class="linenos"> 63</span></a>            <span class="n">count_cost</span><span class="o">=</span><span class="n">count_cost</span>
</span><span id="CollaborativeModel-64"><a href="#CollaborativeModel-64"><span class="linenos"> 64</span></a>        <span class="p">)</span>
</span><span id="CollaborativeModel-65"><a href="#CollaborativeModel-65"><span class="linenos"> 65</span></a>
</span><span id="CollaborativeModel-66"><a href="#CollaborativeModel-66"><span class="linenos"> 66</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
</span><span id="CollaborativeModel-67"><a href="#CollaborativeModel-67"><span class="linenos"> 67</span></a>            <span class="n">provider</span><span class="o">=</span><span class="n">aggregator</span><span class="p">[</span><span class="s1">&#39;provider&#39;</span><span class="p">],</span>
</span><span id="CollaborativeModel-68"><a href="#CollaborativeModel-68"><span class="linenos"> 68</span></a>            <span class="n">model</span><span class="o">=</span><span class="n">aggregator</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">],</span>
</span><span id="CollaborativeModel-69"><a href="#CollaborativeModel-69"><span class="linenos"> 69</span></a>            <span class="n">count_tokens</span><span class="o">=</span><span class="n">count_tokens</span><span class="p">,</span>
</span><span id="CollaborativeModel-70"><a href="#CollaborativeModel-70"><span class="linenos"> 70</span></a>            <span class="n">count_cost</span><span class="o">=</span><span class="n">count_cost</span>
</span><span id="CollaborativeModel-71"><a href="#CollaborativeModel-71"><span class="linenos"> 71</span></a>        <span class="p">)</span>
</span><span id="CollaborativeModel-72"><a href="#CollaborativeModel-72"><span class="linenos"> 72</span></a>
</span><span id="CollaborativeModel-73"><a href="#CollaborativeModel-73"><span class="linenos"> 73</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_format_aggregator_prompt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">],</span> <span class="n">responses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="CollaborativeModel-74"><a href="#CollaborativeModel-74"><span class="linenos"> 74</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-75"><a href="#CollaborativeModel-75"><span class="linenos"> 75</span></a><span class="sd">        Format the prompt for the aggregator model.</span>
</span><span id="CollaborativeModel-76"><a href="#CollaborativeModel-76"><span class="linenos"> 76</span></a>
</span><span id="CollaborativeModel-77"><a href="#CollaborativeModel-77"><span class="linenos"> 77</span></a><span class="sd">        Parameters</span>
</span><span id="CollaborativeModel-78"><a href="#CollaborativeModel-78"><span class="linenos"> 78</span></a><span class="sd">        ----------</span>
</span><span id="CollaborativeModel-79"><a href="#CollaborativeModel-79"><span class="linenos"> 79</span></a><span class="sd">        prompt : Union[str, Prompt, PromptChain]</span>
</span><span id="CollaborativeModel-80"><a href="#CollaborativeModel-80"><span class="linenos"> 80</span></a><span class="sd">            The original prompt</span>
</span><span id="CollaborativeModel-81"><a href="#CollaborativeModel-81"><span class="linenos"> 81</span></a><span class="sd">        responses : List[Dict]</span>
</span><span id="CollaborativeModel-82"><a href="#CollaborativeModel-82"><span class="linenos"> 82</span></a><span class="sd">            List of responses from individual models</span>
</span><span id="CollaborativeModel-83"><a href="#CollaborativeModel-83"><span class="linenos"> 83</span></a>
</span><span id="CollaborativeModel-84"><a href="#CollaborativeModel-84"><span class="linenos"> 84</span></a><span class="sd">        Returns</span>
</span><span id="CollaborativeModel-85"><a href="#CollaborativeModel-85"><span class="linenos"> 85</span></a><span class="sd">        -------</span>
</span><span id="CollaborativeModel-86"><a href="#CollaborativeModel-86"><span class="linenos"> 86</span></a><span class="sd">        str</span>
</span><span id="CollaborativeModel-87"><a href="#CollaborativeModel-87"><span class="linenos"> 87</span></a><span class="sd">            Formatted prompt for the aggregator including original question</span>
</span><span id="CollaborativeModel-88"><a href="#CollaborativeModel-88"><span class="linenos"> 88</span></a><span class="sd">            and all model responses</span>
</span><span id="CollaborativeModel-89"><a href="#CollaborativeModel-89"><span class="linenos"> 89</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-90"><a href="#CollaborativeModel-90"><span class="linenos"> 90</span></a>        <span class="n">prompt_text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</span><span id="CollaborativeModel-91"><a href="#CollaborativeModel-91"><span class="linenos"> 91</span></a>        <span class="n">model_responses</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span>
</span><span id="CollaborativeModel-92"><a href="#CollaborativeModel-92"><span class="linenos"> 92</span></a>            <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">][</span><span class="s1">&#39;provider&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">][</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">):</span><span class="se">\n</span><span class="si">{</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;response&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="CollaborativeModel-93"><a href="#CollaborativeModel-93"><span class="linenos"> 93</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">response</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
</span><span id="CollaborativeModel-94"><a href="#CollaborativeModel-94"><span class="linenos"> 94</span></a>        <span class="p">])</span>
</span><span id="CollaborativeModel-95"><a href="#CollaborativeModel-95"><span class="linenos"> 95</span></a>        
</span><span id="CollaborativeModel-96"><a href="#CollaborativeModel-96"><span class="linenos"> 96</span></a>        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Please analyze the following responses from different models and provide a comprehensive answer:</span>
</span><span id="CollaborativeModel-97"><a href="#CollaborativeModel-97"><span class="linenos"> 97</span></a><span class="s2">                    Original Question: </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span>
</span><span id="CollaborativeModel-98"><a href="#CollaborativeModel-98"><span class="linenos"> 98</span></a><span class="s2">                    Model Responses:</span>
</span><span id="CollaborativeModel-99"><a href="#CollaborativeModel-99"><span class="linenos"> 99</span></a><span class="s2">                    </span><span class="si">{</span><span class="n">model_responses</span><span class="si">}</span>
</span><span id="CollaborativeModel-100"><a href="#CollaborativeModel-100"><span class="linenos">100</span></a><span class="s2">                    Please provide a well-reasoned response that takes into account all the information above.&quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-101"><a href="#CollaborativeModel-101"><span class="linenos">101</span></a>
</span><span id="CollaborativeModel-102"><a href="#CollaborativeModel-102"><span class="linenos">102</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_ask_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
</span><span id="CollaborativeModel-103"><a href="#CollaborativeModel-103"><span class="linenos">103</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-104"><a href="#CollaborativeModel-104"><span class="linenos">104</span></a><span class="sd">        Ask all models and aggregate their responses asynchronously.</span>
</span><span id="CollaborativeModel-105"><a href="#CollaborativeModel-105"><span class="linenos">105</span></a>
</span><span id="CollaborativeModel-106"><a href="#CollaborativeModel-106"><span class="linenos">106</span></a><span class="sd">        Parameters</span>
</span><span id="CollaborativeModel-107"><a href="#CollaborativeModel-107"><span class="linenos">107</span></a><span class="sd">        ----------</span>
</span><span id="CollaborativeModel-108"><a href="#CollaborativeModel-108"><span class="linenos">108</span></a><span class="sd">        prompt : Union[str, Prompt, PromptChain]</span>
</span><span id="CollaborativeModel-109"><a href="#CollaborativeModel-109"><span class="linenos">109</span></a><span class="sd">            The prompt to process across all models</span>
</span><span id="CollaborativeModel-110"><a href="#CollaborativeModel-110"><span class="linenos">110</span></a>
</span><span id="CollaborativeModel-111"><a href="#CollaborativeModel-111"><span class="linenos">111</span></a><span class="sd">        Returns</span>
</span><span id="CollaborativeModel-112"><a href="#CollaborativeModel-112"><span class="linenos">112</span></a><span class="sd">        -------</span>
</span><span id="CollaborativeModel-113"><a href="#CollaborativeModel-113"><span class="linenos">113</span></a><span class="sd">        Dict</span>
</span><span id="CollaborativeModel-114"><a href="#CollaborativeModel-114"><span class="linenos">114</span></a><span class="sd">            Dictionary containing:</span>
</span><span id="CollaborativeModel-115"><a href="#CollaborativeModel-115"><span class="linenos">115</span></a><span class="sd">            - response: The aggregated response</span>
</span><span id="CollaborativeModel-116"><a href="#CollaborativeModel-116"><span class="linenos">116</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="CollaborativeModel-117"><a href="#CollaborativeModel-117"><span class="linenos">117</span></a><span class="sd">            - model: Dictionary with aggregator&#39;s provider and model name</span>
</span><span id="CollaborativeModel-118"><a href="#CollaborativeModel-118"><span class="linenos">118</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="CollaborativeModel-119"><a href="#CollaborativeModel-119"><span class="linenos">119</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="CollaborativeModel-120"><a href="#CollaborativeModel-120"><span class="linenos">120</span></a><span class="sd">            - individual_responses: List of responses from individual models</span>
</span><span id="CollaborativeModel-121"><a href="#CollaborativeModel-121"><span class="linenos">121</span></a>
</span><span id="CollaborativeModel-122"><a href="#CollaborativeModel-122"><span class="linenos">122</span></a><span class="sd">        Examples</span>
</span><span id="CollaborativeModel-123"><a href="#CollaborativeModel-123"><span class="linenos">123</span></a><span class="sd">        --------</span>
</span><span id="CollaborativeModel-124"><a href="#CollaborativeModel-124"><span class="linenos">124</span></a><span class="sd">        Using async/await:</span>
</span><span id="CollaborativeModel-125"><a href="#CollaborativeModel-125"><span class="linenos">125</span></a><span class="sd">            &gt;&gt;&gt; response = await collab.ask_async(&quot;What is consciousness?&quot;)</span>
</span><span id="CollaborativeModel-126"><a href="#CollaborativeModel-126"><span class="linenos">126</span></a><span class="sd">            &gt;&gt;&gt; print(response[&quot;response&quot;])  # Aggregated response</span>
</span><span id="CollaborativeModel-127"><a href="#CollaborativeModel-127"><span class="linenos">127</span></a><span class="sd">            &gt;&gt;&gt; for resp in response[&quot;individual_responses&quot;]:</span>
</span><span id="CollaborativeModel-128"><a href="#CollaborativeModel-128"><span class="linenos">128</span></a><span class="sd">            ...     print(f&quot;{resp[&#39;model&#39;][&#39;name&#39;]}: {resp[&#39;response&#39;]}&quot;)</span>
</span><span id="CollaborativeModel-129"><a href="#CollaborativeModel-129"><span class="linenos">129</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-130"><a href="#CollaborativeModel-130"><span class="linenos">130</span></a>        <span class="c1"># Get responses from all models</span>
</span><span id="CollaborativeModel-131"><a href="#CollaborativeModel-131"><span class="linenos">131</span></a>        <span class="n">model_responses</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_multi_model</span><span class="o">.</span><span class="n">ask_async</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</span><span id="CollaborativeModel-132"><a href="#CollaborativeModel-132"><span class="linenos">132</span></a>        
</span><span id="CollaborativeModel-133"><a href="#CollaborativeModel-133"><span class="linenos">133</span></a>        <span class="c1"># Get aggregator response</span>
</span><span id="CollaborativeModel-134"><a href="#CollaborativeModel-134"><span class="linenos">134</span></a>        <span class="n">aggregator_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_aggregator_prompt</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">model_responses</span><span class="p">)</span>
</span><span id="CollaborativeModel-135"><a href="#CollaborativeModel-135"><span class="linenos">135</span></a>        <span class="n">aggregator_response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_async</span><span class="p">(</span><span class="n">aggregator_prompt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator</span><span class="o">.</span><span class="n">_agent</span><span class="p">)</span>
</span><span id="CollaborativeModel-136"><a href="#CollaborativeModel-136"><span class="linenos">136</span></a>        
</span><span id="CollaborativeModel-137"><a href="#CollaborativeModel-137"><span class="linenos">137</span></a>        <span class="c1"># Process aggregator response</span>
</span><span id="CollaborativeModel-138"><a href="#CollaborativeModel-138"><span class="linenos">138</span></a>        <span class="n">processed_aggregator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_response</span><span class="p">(</span>
</span><span id="CollaborativeModel-139"><a href="#CollaborativeModel-139"><span class="linenos">139</span></a>            <span class="n">aggregator_prompt</span><span class="p">,</span>
</span><span id="CollaborativeModel-140"><a href="#CollaborativeModel-140"><span class="linenos">140</span></a>            <span class="n">aggregator_response</span><span class="p">,</span>
</span><span id="CollaborativeModel-141"><a href="#CollaborativeModel-141"><span class="linenos">141</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator</span><span class="o">.</span><span class="n">provider</span><span class="p">,</span>
</span><span id="CollaborativeModel-142"><a href="#CollaborativeModel-142"><span class="linenos">142</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="CollaborativeModel-143"><a href="#CollaborativeModel-143"><span class="linenos">143</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_count_tokens</span><span class="p">,</span>
</span><span id="CollaborativeModel-144"><a href="#CollaborativeModel-144"><span class="linenos">144</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_count_cost</span>
</span><span id="CollaborativeModel-145"><a href="#CollaborativeModel-145"><span class="linenos">145</span></a>        <span class="p">)</span>
</span><span id="CollaborativeModel-146"><a href="#CollaborativeModel-146"><span class="linenos">146</span></a>
</span><span id="CollaborativeModel-147"><a href="#CollaborativeModel-147"><span class="linenos">147</span></a>        <span class="n">processed_aggregator</span><span class="p">[</span><span class="s2">&quot;individual_responses&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_responses</span>
</span><span id="CollaborativeModel-148"><a href="#CollaborativeModel-148"><span class="linenos">148</span></a>        <span class="k">return</span> <span class="n">processed_aggregator</span>
</span><span id="CollaborativeModel-149"><a href="#CollaborativeModel-149"><span class="linenos">149</span></a>
</span><span id="CollaborativeModel-150"><a href="#CollaborativeModel-150"><span class="linenos">150</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">ask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
</span><span id="CollaborativeModel-151"><a href="#CollaborativeModel-151"><span class="linenos">151</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-152"><a href="#CollaborativeModel-152"><span class="linenos">152</span></a><span class="sd">        Ask all models and aggregate their responses synchronously.</span>
</span><span id="CollaborativeModel-153"><a href="#CollaborativeModel-153"><span class="linenos">153</span></a>
</span><span id="CollaborativeModel-154"><a href="#CollaborativeModel-154"><span class="linenos">154</span></a><span class="sd">        Parameters</span>
</span><span id="CollaborativeModel-155"><a href="#CollaborativeModel-155"><span class="linenos">155</span></a><span class="sd">        ----------</span>
</span><span id="CollaborativeModel-156"><a href="#CollaborativeModel-156"><span class="linenos">156</span></a><span class="sd">        prompt : Union[str, Prompt, PromptChain]</span>
</span><span id="CollaborativeModel-157"><a href="#CollaborativeModel-157"><span class="linenos">157</span></a><span class="sd">            The prompt to process across all models</span>
</span><span id="CollaborativeModel-158"><a href="#CollaborativeModel-158"><span class="linenos">158</span></a>
</span><span id="CollaborativeModel-159"><a href="#CollaborativeModel-159"><span class="linenos">159</span></a><span class="sd">        Returns</span>
</span><span id="CollaborativeModel-160"><a href="#CollaborativeModel-160"><span class="linenos">160</span></a><span class="sd">        -------</span>
</span><span id="CollaborativeModel-161"><a href="#CollaborativeModel-161"><span class="linenos">161</span></a><span class="sd">        Dict</span>
</span><span id="CollaborativeModel-162"><a href="#CollaborativeModel-162"><span class="linenos">162</span></a><span class="sd">            Dictionary containing:</span>
</span><span id="CollaborativeModel-163"><a href="#CollaborativeModel-163"><span class="linenos">163</span></a><span class="sd">            - response: The aggregated response</span>
</span><span id="CollaborativeModel-164"><a href="#CollaborativeModel-164"><span class="linenos">164</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="CollaborativeModel-165"><a href="#CollaborativeModel-165"><span class="linenos">165</span></a><span class="sd">            - model: Dictionary with aggregator&#39;s provider and model name</span>
</span><span id="CollaborativeModel-166"><a href="#CollaborativeModel-166"><span class="linenos">166</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="CollaborativeModel-167"><a href="#CollaborativeModel-167"><span class="linenos">167</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="CollaborativeModel-168"><a href="#CollaborativeModel-168"><span class="linenos">168</span></a><span class="sd">            - individual_responses: List of responses from individual models</span>
</span><span id="CollaborativeModel-169"><a href="#CollaborativeModel-169"><span class="linenos">169</span></a>
</span><span id="CollaborativeModel-170"><a href="#CollaborativeModel-170"><span class="linenos">170</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CollaborativeModel-171"><a href="#CollaborativeModel-171"><span class="linenos">171</span></a>        <span class="k">return</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ask_async</span><span class="p">(</span><span class="n">prompt</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>A class to implement collaborative decision making across multiple AI models.</p>

<p>CollaborativeModel manages a collection of AI models and an aggregator model.
It executes prompts across all models in parallel and then uses the aggregator
to synthesize a final response based on all individual responses.</p>

<h6 id="examples">Examples</h6>

<p>Basic collaborative analysis:</p>

<pre><code>models = [
    {"provider": "openai", "model": "gpt-4"},
    {"provider": "anthropic", "model": "claude-3"}
]
aggregator = {"provider": "openai", "model": "gpt-4"}
collab = CollaborativeModel(models=models, aggregator=aggregator)
response = collab.ask("Explain quantum computing")
print(response["response"])  # Aggregated response
for ind_resp in response["individual_responses"]:
    print(f"{ind_resp['model']['name']}: {ind_resp['response']}")
</code></pre>
</div>


                            <div id="CollaborativeModel.__init__" class="classattr">
                                        <input id="CollaborativeModel.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">CollaborativeModel</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span>,</span><span class="param">	<span class="n">aggregator</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span>)</span>

                <label class="view-source-button" for="CollaborativeModel.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CollaborativeModel.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CollaborativeModel.__init__-37"><a href="#CollaborativeModel.__init__-37"><span class="linenos">37</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="CollaborativeModel.__init__-38"><a href="#CollaborativeModel.__init__-38"><span class="linenos">38</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="CollaborativeModel.__init__-39"><a href="#CollaborativeModel.__init__-39"><span class="linenos">39</span></a>        <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
</span><span id="CollaborativeModel.__init__-40"><a href="#CollaborativeModel.__init__-40"><span class="linenos">40</span></a>        <span class="n">aggregator</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
</span><span id="CollaborativeModel.__init__-41"><a href="#CollaborativeModel.__init__-41"><span class="linenos">41</span></a>        <span class="n">count_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="CollaborativeModel.__init__-42"><a href="#CollaborativeModel.__init__-42"><span class="linenos">42</span></a>        <span class="n">count_cost</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="CollaborativeModel.__init__-43"><a href="#CollaborativeModel.__init__-43"><span class="linenos">43</span></a>    <span class="p">):</span>
</span><span id="CollaborativeModel.__init__-44"><a href="#CollaborativeModel.__init__-44"><span class="linenos">44</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="CollaborativeModel.__init__-45"><a href="#CollaborativeModel.__init__-45"><span class="linenos">45</span></a><span class="sd">        Initialize a new CollaborativeModel instance.</span>
</span><span id="CollaborativeModel.__init__-46"><a href="#CollaborativeModel.__init__-46"><span class="linenos">46</span></a>
</span><span id="CollaborativeModel.__init__-47"><a href="#CollaborativeModel.__init__-47"><span class="linenos">47</span></a><span class="sd">        Parameters</span>
</span><span id="CollaborativeModel.__init__-48"><a href="#CollaborativeModel.__init__-48"><span class="linenos">48</span></a><span class="sd">        ----------</span>
</span><span id="CollaborativeModel.__init__-49"><a href="#CollaborativeModel.__init__-49"><span class="linenos">49</span></a><span class="sd">        models : List[Dict[str, str]]</span>
</span><span id="CollaborativeModel.__init__-50"><a href="#CollaborativeModel.__init__-50"><span class="linenos">50</span></a><span class="sd">            List of dictionaries with provider and model information</span>
</span><span id="CollaborativeModel.__init__-51"><a href="#CollaborativeModel.__init__-51"><span class="linenos">51</span></a><span class="sd">        aggregator : Dict[str, str]</span>
</span><span id="CollaborativeModel.__init__-52"><a href="#CollaborativeModel.__init__-52"><span class="linenos">52</span></a><span class="sd">            Dictionary with provider and model information for the aggregator</span>
</span><span id="CollaborativeModel.__init__-53"><a href="#CollaborativeModel.__init__-53"><span class="linenos">53</span></a><span class="sd">        count_tokens : bool, optional</span>
</span><span id="CollaborativeModel.__init__-54"><a href="#CollaborativeModel.__init__-54"><span class="linenos">54</span></a><span class="sd">            Whether to count tokens for each request</span>
</span><span id="CollaborativeModel.__init__-55"><a href="#CollaborativeModel.__init__-55"><span class="linenos">55</span></a><span class="sd">        count_cost : bool, optional</span>
</span><span id="CollaborativeModel.__init__-56"><a href="#CollaborativeModel.__init__-56"><span class="linenos">56</span></a><span class="sd">            Whether to calculate costs for each request</span>
</span><span id="CollaborativeModel.__init__-57"><a href="#CollaborativeModel.__init__-57"><span class="linenos">57</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CollaborativeModel.__init__-58"><a href="#CollaborativeModel.__init__-58"><span class="linenos">58</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">count_tokens</span><span class="p">,</span> <span class="n">count_cost</span><span class="p">)</span>
</span><span id="CollaborativeModel.__init__-59"><a href="#CollaborativeModel.__init__-59"><span class="linenos">59</span></a>
</span><span id="CollaborativeModel.__init__-60"><a href="#CollaborativeModel.__init__-60"><span class="linenos">60</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_multi_model</span> <span class="o">=</span> <span class="n">MultiModel</span><span class="p">(</span>
</span><span id="CollaborativeModel.__init__-61"><a href="#CollaborativeModel.__init__-61"><span class="linenos">61</span></a>            <span class="n">models</span><span class="o">=</span><span class="n">models</span><span class="p">,</span>
</span><span id="CollaborativeModel.__init__-62"><a href="#CollaborativeModel.__init__-62"><span class="linenos">62</span></a>            <span class="n">count_tokens</span><span class="o">=</span><span class="n">count_tokens</span><span class="p">,</span>
</span><span id="CollaborativeModel.__init__-63"><a href="#CollaborativeModel.__init__-63"><span class="linenos">63</span></a>            <span class="n">count_cost</span><span class="o">=</span><span class="n">count_cost</span>
</span><span id="CollaborativeModel.__init__-64"><a href="#CollaborativeModel.__init__-64"><span class="linenos">64</span></a>        <span class="p">)</span>
</span><span id="CollaborativeModel.__init__-65"><a href="#CollaborativeModel.__init__-65"><span class="linenos">65</span></a>
</span><span id="CollaborativeModel.__init__-66"><a href="#CollaborativeModel.__init__-66"><span class="linenos">66</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
</span><span id="CollaborativeModel.__init__-67"><a href="#CollaborativeModel.__init__-67"><span class="linenos">67</span></a>            <span class="n">provider</span><span class="o">=</span><span class="n">aggregator</span><span class="p">[</span><span class="s1">&#39;provider&#39;</span><span class="p">],</span>
</span><span id="CollaborativeModel.__init__-68"><a href="#CollaborativeModel.__init__-68"><span class="linenos">68</span></a>            <span class="n">model</span><span class="o">=</span><span class="n">aggregator</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">],</span>
</span><span id="CollaborativeModel.__init__-69"><a href="#CollaborativeModel.__init__-69"><span class="linenos">69</span></a>            <span class="n">count_tokens</span><span class="o">=</span><span class="n">count_tokens</span><span class="p">,</span>
</span><span id="CollaborativeModel.__init__-70"><a href="#CollaborativeModel.__init__-70"><span class="linenos">70</span></a>            <span class="n">count_cost</span><span class="o">=</span><span class="n">count_cost</span>
</span><span id="CollaborativeModel.__init__-71"><a href="#CollaborativeModel.__init__-71"><span class="linenos">71</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initialize a new CollaborativeModel instance.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>models</strong> (List[Dict[str, str]]):
List of dictionaries with provider and model information</li>
<li><strong>aggregator</strong> (Dict[str, str]):
Dictionary with provider and model information for the aggregator</li>
<li><strong>count_tokens</strong> (bool, optional):
Whether to count tokens for each request</li>
<li><strong>count_cost</strong> (bool, optional):
Whether to calculate costs for each request</li>
</ul>
</div>


                            </div>
                            <div id="CollaborativeModel.ask" class="classattr">
                                        <input id="CollaborativeModel.ask-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">ask</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n"><a href="prompts.html#Prompt">monoai.prompts.Prompt</a></span><span class="p">,</span> <span class="n"><a href="prompts.html#PromptChain">monoai.prompts.PromptChain</a></span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">Dict</span>:</span></span>

                <label class="view-source-button" for="CollaborativeModel.ask-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CollaborativeModel.ask"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CollaborativeModel.ask-150"><a href="#CollaborativeModel.ask-150"><span class="linenos">150</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">ask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Prompt</span><span class="p">,</span> <span class="n">PromptChain</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
</span><span id="CollaborativeModel.ask-151"><a href="#CollaborativeModel.ask-151"><span class="linenos">151</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="CollaborativeModel.ask-152"><a href="#CollaborativeModel.ask-152"><span class="linenos">152</span></a><span class="sd">        Ask all models and aggregate their responses synchronously.</span>
</span><span id="CollaborativeModel.ask-153"><a href="#CollaborativeModel.ask-153"><span class="linenos">153</span></a>
</span><span id="CollaborativeModel.ask-154"><a href="#CollaborativeModel.ask-154"><span class="linenos">154</span></a><span class="sd">        Parameters</span>
</span><span id="CollaborativeModel.ask-155"><a href="#CollaborativeModel.ask-155"><span class="linenos">155</span></a><span class="sd">        ----------</span>
</span><span id="CollaborativeModel.ask-156"><a href="#CollaborativeModel.ask-156"><span class="linenos">156</span></a><span class="sd">        prompt : Union[str, Prompt, PromptChain]</span>
</span><span id="CollaborativeModel.ask-157"><a href="#CollaborativeModel.ask-157"><span class="linenos">157</span></a><span class="sd">            The prompt to process across all models</span>
</span><span id="CollaborativeModel.ask-158"><a href="#CollaborativeModel.ask-158"><span class="linenos">158</span></a>
</span><span id="CollaborativeModel.ask-159"><a href="#CollaborativeModel.ask-159"><span class="linenos">159</span></a><span class="sd">        Returns</span>
</span><span id="CollaborativeModel.ask-160"><a href="#CollaborativeModel.ask-160"><span class="linenos">160</span></a><span class="sd">        -------</span>
</span><span id="CollaborativeModel.ask-161"><a href="#CollaborativeModel.ask-161"><span class="linenos">161</span></a><span class="sd">        Dict</span>
</span><span id="CollaborativeModel.ask-162"><a href="#CollaborativeModel.ask-162"><span class="linenos">162</span></a><span class="sd">            Dictionary containing:</span>
</span><span id="CollaborativeModel.ask-163"><a href="#CollaborativeModel.ask-163"><span class="linenos">163</span></a><span class="sd">            - response: The aggregated response</span>
</span><span id="CollaborativeModel.ask-164"><a href="#CollaborativeModel.ask-164"><span class="linenos">164</span></a><span class="sd">            - prompt: The original prompt</span>
</span><span id="CollaborativeModel.ask-165"><a href="#CollaborativeModel.ask-165"><span class="linenos">165</span></a><span class="sd">            - model: Dictionary with aggregator&#39;s provider and model name</span>
</span><span id="CollaborativeModel.ask-166"><a href="#CollaborativeModel.ask-166"><span class="linenos">166</span></a><span class="sd">            - tokens: Token counts (if enabled)</span>
</span><span id="CollaborativeModel.ask-167"><a href="#CollaborativeModel.ask-167"><span class="linenos">167</span></a><span class="sd">            - cost: Cost calculation (if enabled)</span>
</span><span id="CollaborativeModel.ask-168"><a href="#CollaborativeModel.ask-168"><span class="linenos">168</span></a><span class="sd">            - individual_responses: List of responses from individual models</span>
</span><span id="CollaborativeModel.ask-169"><a href="#CollaborativeModel.ask-169"><span class="linenos">169</span></a>
</span><span id="CollaborativeModel.ask-170"><a href="#CollaborativeModel.ask-170"><span class="linenos">170</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CollaborativeModel.ask-171"><a href="#CollaborativeModel.ask-171"><span class="linenos">171</span></a>        <span class="k">return</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ask_async</span><span class="p">(</span><span class="n">prompt</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Ask all models and aggregate their responses synchronously.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>prompt</strong> (Union[str, Prompt, PromptChain]):
The prompt to process across all models</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>Dict</strong>: Dictionary containing:
<ul>
<li>response: The aggregated response</li>
<li>prompt: The original prompt</li>
<li>model: Dictionary with aggregator's provider and model name</li>
<li>tokens: Token counts (if enabled)</li>
<li>cost: Cost calculation (if enabled)</li>
<li>individual_responses: List of responses from individual models</li>
</ul></li>
</ul>
</div>


                            </div>
                </section>
                <section id="ImageModel">
                            <input id="ImageModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ImageModel</span>:

                <label class="view-source-button" for="ImageModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ImageModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ImageModel-5"><a href="#ImageModel-5"><span class="linenos"> 5</span></a><span class="k">class</span><span class="w"> </span><span class="nc">ImageModel</span><span class="p">:</span>
</span><span id="ImageModel-6"><a href="#ImageModel-6"><span class="linenos"> 6</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ImageModel-7"><a href="#ImageModel-7"><span class="linenos"> 7</span></a><span class="sd">    A class to interact with AI image generation models.</span>
</span><span id="ImageModel-8"><a href="#ImageModel-8"><span class="linenos"> 8</span></a><span class="sd">    </span>
</span><span id="ImageModel-9"><a href="#ImageModel-9"><span class="linenos"> 9</span></a><span class="sd">    ImageModel provides an interface for generating images from text prompts using</span>
</span><span id="ImageModel-10"><a href="#ImageModel-10"><span class="linenos">10</span></a><span class="sd">    AI models. Currently supports OpenAI&#39;s DALL-E 3, with potential for expansion</span>
</span><span id="ImageModel-11"><a href="#ImageModel-11"><span class="linenos">11</span></a><span class="sd">    to other providers and models in the future.</span>
</span><span id="ImageModel-12"><a href="#ImageModel-12"><span class="linenos">12</span></a>
</span><span id="ImageModel-13"><a href="#ImageModel-13"><span class="linenos">13</span></a><span class="sd">    Examples</span>
</span><span id="ImageModel-14"><a href="#ImageModel-14"><span class="linenos">14</span></a><span class="sd">    --------</span>
</span><span id="ImageModel-15"><a href="#ImageModel-15"><span class="linenos">15</span></a><span class="sd">    Basic image generation:</span>
</span><span id="ImageModel-16"><a href="#ImageModel-16"><span class="linenos">16</span></a><span class="sd">    ```</span>
</span><span id="ImageModel-17"><a href="#ImageModel-17"><span class="linenos">17</span></a><span class="sd">    model = ImageModel(provider=&quot;openai&quot;, model=&quot;dall-e-3&quot;)</span>
</span><span id="ImageModel-18"><a href="#ImageModel-18"><span class="linenos">18</span></a><span class="sd">    response = model.generate(&quot;A beautiful garden with flowers&quot;)</span>
</span><span id="ImageModel-19"><a href="#ImageModel-19"><span class="linenos">19</span></a><span class="sd">    ```</span>
</span><span id="ImageModel-20"><a href="#ImageModel-20"><span class="linenos">20</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ImageModel-21"><a href="#ImageModel-21"><span class="linenos">21</span></a>
</span><span id="ImageModel-22"><a href="#ImageModel-22"><span class="linenos">22</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="ImageModel-23"><a href="#ImageModel-23"><span class="linenos">23</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ImageModel-24"><a href="#ImageModel-24"><span class="linenos">24</span></a><span class="sd">        Initialize a new ImageModel instance.</span>
</span><span id="ImageModel-25"><a href="#ImageModel-25"><span class="linenos">25</span></a>
</span><span id="ImageModel-26"><a href="#ImageModel-26"><span class="linenos">26</span></a><span class="sd">        Parameters</span>
</span><span id="ImageModel-27"><a href="#ImageModel-27"><span class="linenos">27</span></a><span class="sd">        ----------</span>
</span><span id="ImageModel-28"><a href="#ImageModel-28"><span class="linenos">28</span></a><span class="sd">        provider : str</span>
</span><span id="ImageModel-29"><a href="#ImageModel-29"><span class="linenos">29</span></a><span class="sd">            Name of the provider (currently only &quot;openai&quot; is supported)</span>
</span><span id="ImageModel-30"><a href="#ImageModel-30"><span class="linenos">30</span></a><span class="sd">        model : str</span>
</span><span id="ImageModel-31"><a href="#ImageModel-31"><span class="linenos">31</span></a><span class="sd">            Name of the model (currently only &quot;dall-e-3&quot; is supported)</span>
</span><span id="ImageModel-32"><a href="#ImageModel-32"><span class="linenos">32</span></a>
</span><span id="ImageModel-33"><a href="#ImageModel-33"><span class="linenos">33</span></a><span class="sd">        Raises</span>
</span><span id="ImageModel-34"><a href="#ImageModel-34"><span class="linenos">34</span></a><span class="sd">        ------</span>
</span><span id="ImageModel-35"><a href="#ImageModel-35"><span class="linenos">35</span></a><span class="sd">        ValueError</span>
</span><span id="ImageModel-36"><a href="#ImageModel-36"><span class="linenos">36</span></a><span class="sd">            If an unsupported provider or model is specified</span>
</span><span id="ImageModel-37"><a href="#ImageModel-37"><span class="linenos">37</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ImageModel-38"><a href="#ImageModel-38"><span class="linenos">38</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">provider</span> <span class="o">=</span> <span class="n">provider</span>
</span><span id="ImageModel-39"><a href="#ImageModel-39"><span class="linenos">39</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="ImageModel-40"><a href="#ImageModel-40"><span class="linenos">40</span></a>
</span><span id="ImageModel-41"><a href="#ImageModel-41"><span class="linenos">41</span></a>        <span class="k">if</span> <span class="n">provider</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">&quot;openai&quot;</span><span class="p">:</span>
</span><span id="ImageModel-42"><a href="#ImageModel-42"><span class="linenos">42</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Provider </span><span class="si">{</span><span class="n">provider</span><span class="si">}</span><span class="s2"> not supported&quot;</span><span class="p">)</span>
</span><span id="ImageModel-43"><a href="#ImageModel-43"><span class="linenos">43</span></a>        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">&quot;dall-e-3&quot;</span><span class="p">:</span>
</span><span id="ImageModel-44"><a href="#ImageModel-44"><span class="linenos">44</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2"> not supported&quot;</span><span class="p">)</span>
</span><span id="ImageModel-45"><a href="#ImageModel-45"><span class="linenos">45</span></a>        
</span><span id="ImageModel-46"><a href="#ImageModel-46"><span class="linenos">46</span></a>        <span class="n">load_key</span><span class="p">(</span><span class="n">provider</span><span class="p">)</span>
</span><span id="ImageModel-47"><a href="#ImageModel-47"><span class="linenos">47</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>
</span><span id="ImageModel-48"><a href="#ImageModel-48"><span class="linenos">48</span></a>
</span><span id="ImageModel-49"><a href="#ImageModel-49"><span class="linenos">49</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
</span><span id="ImageModel-50"><a href="#ImageModel-50"><span class="linenos">50</span></a>                <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
</span><span id="ImageModel-51"><a href="#ImageModel-51"><span class="linenos">51</span></a>                <span class="n">size</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;1024x1024&quot;</span><span class="p">,</span> 
</span><span id="ImageModel-52"><a href="#ImageModel-52"><span class="linenos">52</span></a>                <span class="n">quality</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;standard&quot;</span><span class="p">,</span> 
</span><span id="ImageModel-53"><a href="#ImageModel-53"><span class="linenos">53</span></a>                <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="ImageModel-54"><a href="#ImageModel-54"><span class="linenos">54</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ImageModel-55"><a href="#ImageModel-55"><span class="linenos">55</span></a><span class="sd">        Generate images from a text prompt.</span>
</span><span id="ImageModel-56"><a href="#ImageModel-56"><span class="linenos">56</span></a>
</span><span id="ImageModel-57"><a href="#ImageModel-57"><span class="linenos">57</span></a><span class="sd">        Parameters</span>
</span><span id="ImageModel-58"><a href="#ImageModel-58"><span class="linenos">58</span></a><span class="sd">        ----------</span>
</span><span id="ImageModel-59"><a href="#ImageModel-59"><span class="linenos">59</span></a><span class="sd">        prompt : str</span>
</span><span id="ImageModel-60"><a href="#ImageModel-60"><span class="linenos">60</span></a><span class="sd">            The text description of the image to generate</span>
</span><span id="ImageModel-61"><a href="#ImageModel-61"><span class="linenos">61</span></a><span class="sd">        size : str, optional</span>
</span><span id="ImageModel-62"><a href="#ImageModel-62"><span class="linenos">62</span></a><span class="sd">            The size of the generated image(s). Options:</span>
</span><span id="ImageModel-63"><a href="#ImageModel-63"><span class="linenos">63</span></a><span class="sd">            - &quot;1024x1024&quot; (default)</span>
</span><span id="ImageModel-64"><a href="#ImageModel-64"><span class="linenos">64</span></a><span class="sd">            - &quot;1792x1024&quot;</span>
</span><span id="ImageModel-65"><a href="#ImageModel-65"><span class="linenos">65</span></a><span class="sd">            - &quot;1024x1792&quot;</span>
</span><span id="ImageModel-66"><a href="#ImageModel-66"><span class="linenos">66</span></a><span class="sd">        quality : str, optional</span>
</span><span id="ImageModel-67"><a href="#ImageModel-67"><span class="linenos">67</span></a><span class="sd">            The quality of the generated image(s). Options:</span>
</span><span id="ImageModel-68"><a href="#ImageModel-68"><span class="linenos">68</span></a><span class="sd">            - &quot;standard&quot; (default)</span>
</span><span id="ImageModel-69"><a href="#ImageModel-69"><span class="linenos">69</span></a><span class="sd">            - &quot;hd&quot;</span>
</span><span id="ImageModel-70"><a href="#ImageModel-70"><span class="linenos">70</span></a><span class="sd">        n : int, optional</span>
</span><span id="ImageModel-71"><a href="#ImageModel-71"><span class="linenos">71</span></a><span class="sd">            Number of images to generate (default: 1)</span>
</span><span id="ImageModel-72"><a href="#ImageModel-72"><span class="linenos">72</span></a>
</span><span id="ImageModel-73"><a href="#ImageModel-73"><span class="linenos">73</span></a><span class="sd">        Returns</span>
</span><span id="ImageModel-74"><a href="#ImageModel-74"><span class="linenos">74</span></a><span class="sd">        -------</span>
</span><span id="ImageModel-75"><a href="#ImageModel-75"><span class="linenos">75</span></a><span class="sd">        dict</span>
</span><span id="ImageModel-76"><a href="#ImageModel-76"><span class="linenos">76</span></a><span class="sd">            OpenAI image generation response containing:</span>
</span><span id="ImageModel-77"><a href="#ImageModel-77"><span class="linenos">77</span></a><span class="sd">            - created: timestamp</span>
</span><span id="ImageModel-78"><a href="#ImageModel-78"><span class="linenos">78</span></a><span class="sd">            - data: list of generated images with URLs and other metadata</span>
</span><span id="ImageModel-79"><a href="#ImageModel-79"><span class="linenos">79</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ImageModel-80"><a href="#ImageModel-80"><span class="linenos">80</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
</span><span id="ImageModel-81"><a href="#ImageModel-81"><span class="linenos">81</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="ImageModel-82"><a href="#ImageModel-82"><span class="linenos">82</span></a>            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
</span><span id="ImageModel-83"><a href="#ImageModel-83"><span class="linenos">83</span></a>            <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
</span><span id="ImageModel-84"><a href="#ImageModel-84"><span class="linenos">84</span></a>            <span class="n">quality</span><span class="o">=</span><span class="n">quality</span><span class="p">,</span>
</span><span id="ImageModel-85"><a href="#ImageModel-85"><span class="linenos">85</span></a>            <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
</span><span id="ImageModel-86"><a href="#ImageModel-86"><span class="linenos">86</span></a>        <span class="p">)</span>
</span><span id="ImageModel-87"><a href="#ImageModel-87"><span class="linenos">87</span></a>        <span class="k">return</span> <span class="n">response</span>
</span></pre></div>


            <div class="docstring"><p>A class to interact with AI image generation models.</p>

<p>ImageModel provides an interface for generating images from text prompts using
AI models. Currently supports OpenAI's DALL-E 3, with potential for expansion
to other providers and models in the future.</p>

<h6 id="examples">Examples</h6>

<p>Basic image generation:</p>

<pre><code>model = ImageModel(provider="openai", model="dall-e-3")
response = model.generate("A beautiful garden with flowers")
</code></pre>
</div>


                            <div id="ImageModel.__init__" class="classattr">
                                        <input id="ImageModel.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ImageModel</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">provider</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">model</span><span class="p">:</span> <span class="nb">str</span></span>)</span>

                <label class="view-source-button" for="ImageModel.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ImageModel.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ImageModel.__init__-22"><a href="#ImageModel.__init__-22"><span class="linenos">22</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="ImageModel.__init__-23"><a href="#ImageModel.__init__-23"><span class="linenos">23</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ImageModel.__init__-24"><a href="#ImageModel.__init__-24"><span class="linenos">24</span></a><span class="sd">        Initialize a new ImageModel instance.</span>
</span><span id="ImageModel.__init__-25"><a href="#ImageModel.__init__-25"><span class="linenos">25</span></a>
</span><span id="ImageModel.__init__-26"><a href="#ImageModel.__init__-26"><span class="linenos">26</span></a><span class="sd">        Parameters</span>
</span><span id="ImageModel.__init__-27"><a href="#ImageModel.__init__-27"><span class="linenos">27</span></a><span class="sd">        ----------</span>
</span><span id="ImageModel.__init__-28"><a href="#ImageModel.__init__-28"><span class="linenos">28</span></a><span class="sd">        provider : str</span>
</span><span id="ImageModel.__init__-29"><a href="#ImageModel.__init__-29"><span class="linenos">29</span></a><span class="sd">            Name of the provider (currently only &quot;openai&quot; is supported)</span>
</span><span id="ImageModel.__init__-30"><a href="#ImageModel.__init__-30"><span class="linenos">30</span></a><span class="sd">        model : str</span>
</span><span id="ImageModel.__init__-31"><a href="#ImageModel.__init__-31"><span class="linenos">31</span></a><span class="sd">            Name of the model (currently only &quot;dall-e-3&quot; is supported)</span>
</span><span id="ImageModel.__init__-32"><a href="#ImageModel.__init__-32"><span class="linenos">32</span></a>
</span><span id="ImageModel.__init__-33"><a href="#ImageModel.__init__-33"><span class="linenos">33</span></a><span class="sd">        Raises</span>
</span><span id="ImageModel.__init__-34"><a href="#ImageModel.__init__-34"><span class="linenos">34</span></a><span class="sd">        ------</span>
</span><span id="ImageModel.__init__-35"><a href="#ImageModel.__init__-35"><span class="linenos">35</span></a><span class="sd">        ValueError</span>
</span><span id="ImageModel.__init__-36"><a href="#ImageModel.__init__-36"><span class="linenos">36</span></a><span class="sd">            If an unsupported provider or model is specified</span>
</span><span id="ImageModel.__init__-37"><a href="#ImageModel.__init__-37"><span class="linenos">37</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ImageModel.__init__-38"><a href="#ImageModel.__init__-38"><span class="linenos">38</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">provider</span> <span class="o">=</span> <span class="n">provider</span>
</span><span id="ImageModel.__init__-39"><a href="#ImageModel.__init__-39"><span class="linenos">39</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="ImageModel.__init__-40"><a href="#ImageModel.__init__-40"><span class="linenos">40</span></a>
</span><span id="ImageModel.__init__-41"><a href="#ImageModel.__init__-41"><span class="linenos">41</span></a>        <span class="k">if</span> <span class="n">provider</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">&quot;openai&quot;</span><span class="p">:</span>
</span><span id="ImageModel.__init__-42"><a href="#ImageModel.__init__-42"><span class="linenos">42</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Provider </span><span class="si">{</span><span class="n">provider</span><span class="si">}</span><span class="s2"> not supported&quot;</span><span class="p">)</span>
</span><span id="ImageModel.__init__-43"><a href="#ImageModel.__init__-43"><span class="linenos">43</span></a>        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">&quot;dall-e-3&quot;</span><span class="p">:</span>
</span><span id="ImageModel.__init__-44"><a href="#ImageModel.__init__-44"><span class="linenos">44</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2"> not supported&quot;</span><span class="p">)</span>
</span><span id="ImageModel.__init__-45"><a href="#ImageModel.__init__-45"><span class="linenos">45</span></a>        
</span><span id="ImageModel.__init__-46"><a href="#ImageModel.__init__-46"><span class="linenos">46</span></a>        <span class="n">load_key</span><span class="p">(</span><span class="n">provider</span><span class="p">)</span>
</span><span id="ImageModel.__init__-47"><a href="#ImageModel.__init__-47"><span class="linenos">47</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initialize a new ImageModel instance.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>provider</strong> (str):
Name of the provider (currently only "openai" is supported)</li>
<li><strong>model</strong> (str):
Name of the model (currently only "dall-e-3" is supported)</li>
</ul>

<h6 id="raises">Raises</h6>

<ul>
<li><strong>ValueError</strong>: If an unsupported provider or model is specified</li>
</ul>
</div>


                            </div>
                            <div id="ImageModel.provider" class="classattr">
                                <div class="attr variable">
            <span class="name">provider</span>

        
    </div>
    <a class="headerlink" href="#ImageModel.provider"></a>
    
    

                            </div>
                            <div id="ImageModel.model" class="classattr">
                                <div class="attr variable">
            <span class="name">model</span>

        
    </div>
    <a class="headerlink" href="#ImageModel.model"></a>
    
    

                            </div>
                            <div id="ImageModel.generate" class="classattr">
                                        <input id="ImageModel.generate-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">generate</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">size</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;1024x1024&#39;</span>,</span><span class="param">	<span class="n">quality</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;standard&#39;</span>,</span><span class="param">	<span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></span><span class="return-annotation">) -> <span class="nb">dict</span>:</span></span>

                <label class="view-source-button" for="ImageModel.generate-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ImageModel.generate"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ImageModel.generate-49"><a href="#ImageModel.generate-49"><span class="linenos">49</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
</span><span id="ImageModel.generate-50"><a href="#ImageModel.generate-50"><span class="linenos">50</span></a>                <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
</span><span id="ImageModel.generate-51"><a href="#ImageModel.generate-51"><span class="linenos">51</span></a>                <span class="n">size</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;1024x1024&quot;</span><span class="p">,</span> 
</span><span id="ImageModel.generate-52"><a href="#ImageModel.generate-52"><span class="linenos">52</span></a>                <span class="n">quality</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;standard&quot;</span><span class="p">,</span> 
</span><span id="ImageModel.generate-53"><a href="#ImageModel.generate-53"><span class="linenos">53</span></a>                <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="ImageModel.generate-54"><a href="#ImageModel.generate-54"><span class="linenos">54</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ImageModel.generate-55"><a href="#ImageModel.generate-55"><span class="linenos">55</span></a><span class="sd">        Generate images from a text prompt.</span>
</span><span id="ImageModel.generate-56"><a href="#ImageModel.generate-56"><span class="linenos">56</span></a>
</span><span id="ImageModel.generate-57"><a href="#ImageModel.generate-57"><span class="linenos">57</span></a><span class="sd">        Parameters</span>
</span><span id="ImageModel.generate-58"><a href="#ImageModel.generate-58"><span class="linenos">58</span></a><span class="sd">        ----------</span>
</span><span id="ImageModel.generate-59"><a href="#ImageModel.generate-59"><span class="linenos">59</span></a><span class="sd">        prompt : str</span>
</span><span id="ImageModel.generate-60"><a href="#ImageModel.generate-60"><span class="linenos">60</span></a><span class="sd">            The text description of the image to generate</span>
</span><span id="ImageModel.generate-61"><a href="#ImageModel.generate-61"><span class="linenos">61</span></a><span class="sd">        size : str, optional</span>
</span><span id="ImageModel.generate-62"><a href="#ImageModel.generate-62"><span class="linenos">62</span></a><span class="sd">            The size of the generated image(s). Options:</span>
</span><span id="ImageModel.generate-63"><a href="#ImageModel.generate-63"><span class="linenos">63</span></a><span class="sd">            - &quot;1024x1024&quot; (default)</span>
</span><span id="ImageModel.generate-64"><a href="#ImageModel.generate-64"><span class="linenos">64</span></a><span class="sd">            - &quot;1792x1024&quot;</span>
</span><span id="ImageModel.generate-65"><a href="#ImageModel.generate-65"><span class="linenos">65</span></a><span class="sd">            - &quot;1024x1792&quot;</span>
</span><span id="ImageModel.generate-66"><a href="#ImageModel.generate-66"><span class="linenos">66</span></a><span class="sd">        quality : str, optional</span>
</span><span id="ImageModel.generate-67"><a href="#ImageModel.generate-67"><span class="linenos">67</span></a><span class="sd">            The quality of the generated image(s). Options:</span>
</span><span id="ImageModel.generate-68"><a href="#ImageModel.generate-68"><span class="linenos">68</span></a><span class="sd">            - &quot;standard&quot; (default)</span>
</span><span id="ImageModel.generate-69"><a href="#ImageModel.generate-69"><span class="linenos">69</span></a><span class="sd">            - &quot;hd&quot;</span>
</span><span id="ImageModel.generate-70"><a href="#ImageModel.generate-70"><span class="linenos">70</span></a><span class="sd">        n : int, optional</span>
</span><span id="ImageModel.generate-71"><a href="#ImageModel.generate-71"><span class="linenos">71</span></a><span class="sd">            Number of images to generate (default: 1)</span>
</span><span id="ImageModel.generate-72"><a href="#ImageModel.generate-72"><span class="linenos">72</span></a>
</span><span id="ImageModel.generate-73"><a href="#ImageModel.generate-73"><span class="linenos">73</span></a><span class="sd">        Returns</span>
</span><span id="ImageModel.generate-74"><a href="#ImageModel.generate-74"><span class="linenos">74</span></a><span class="sd">        -------</span>
</span><span id="ImageModel.generate-75"><a href="#ImageModel.generate-75"><span class="linenos">75</span></a><span class="sd">        dict</span>
</span><span id="ImageModel.generate-76"><a href="#ImageModel.generate-76"><span class="linenos">76</span></a><span class="sd">            OpenAI image generation response containing:</span>
</span><span id="ImageModel.generate-77"><a href="#ImageModel.generate-77"><span class="linenos">77</span></a><span class="sd">            - created: timestamp</span>
</span><span id="ImageModel.generate-78"><a href="#ImageModel.generate-78"><span class="linenos">78</span></a><span class="sd">            - data: list of generated images with URLs and other metadata</span>
</span><span id="ImageModel.generate-79"><a href="#ImageModel.generate-79"><span class="linenos">79</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ImageModel.generate-80"><a href="#ImageModel.generate-80"><span class="linenos">80</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
</span><span id="ImageModel.generate-81"><a href="#ImageModel.generate-81"><span class="linenos">81</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="ImageModel.generate-82"><a href="#ImageModel.generate-82"><span class="linenos">82</span></a>            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
</span><span id="ImageModel.generate-83"><a href="#ImageModel.generate-83"><span class="linenos">83</span></a>            <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
</span><span id="ImageModel.generate-84"><a href="#ImageModel.generate-84"><span class="linenos">84</span></a>            <span class="n">quality</span><span class="o">=</span><span class="n">quality</span><span class="p">,</span>
</span><span id="ImageModel.generate-85"><a href="#ImageModel.generate-85"><span class="linenos">85</span></a>            <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
</span><span id="ImageModel.generate-86"><a href="#ImageModel.generate-86"><span class="linenos">86</span></a>        <span class="p">)</span>
</span><span id="ImageModel.generate-87"><a href="#ImageModel.generate-87"><span class="linenos">87</span></a>        <span class="k">return</span> <span class="n">response</span>
</span></pre></div>


            <div class="docstring"><p>Generate images from a text prompt.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>prompt</strong> (str):
The text description of the image to generate</li>
<li><strong>size</strong> (str, optional):
The size of the generated image(s). Options:
<ul>
<li>"1024x1024" (default)</li>
<li>"1792x1024"</li>
<li>"1024x1792"</li>
</ul></li>
<li><strong>quality</strong> (str, optional):
The quality of the generated image(s). Options:
<ul>
<li>"standard" (default)</li>
<li>"hd"</li>
</ul></li>
<li><strong>n</strong> (int, optional):
Number of images to generate (default: 1)</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>dict</strong>: OpenAI image generation response containing:
<ul>
<li>created: timestamp</li>
<li>data: list of generated images with URLs and other metadata</li>
</ul></li>
</ul>
</div>


                            </div>
                </section>
                <section id="VoiceModel">
                            <input id="VoiceModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">VoiceModel</span>:

                <label class="view-source-button" for="VoiceModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#VoiceModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="VoiceModel-7"><a href="#VoiceModel-7"><span class="linenos">  7</span></a><span class="k">class</span><span class="w"> </span><span class="nc">VoiceModel</span><span class="p">:</span>
</span><span id="VoiceModel-8"><a href="#VoiceModel-8"><span class="linenos">  8</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel-9"><a href="#VoiceModel-9"><span class="linenos">  9</span></a><span class="sd">    A class for text-to-speech using various AI voice models.</span>
</span><span id="VoiceModel-10"><a href="#VoiceModel-10"><span class="linenos"> 10</span></a><span class="sd">    </span>
</span><span id="VoiceModel-11"><a href="#VoiceModel-11"><span class="linenos"> 11</span></a><span class="sd">    VoiceModel provides an interface for converting text to speech using different</span>
</span><span id="VoiceModel-12"><a href="#VoiceModel-12"><span class="linenos"> 12</span></a><span class="sd">    AI voice providers. Currently supports ElevenLabs and OpenAI voice models.</span>
</span><span id="VoiceModel-13"><a href="#VoiceModel-13"><span class="linenos"> 13</span></a><span class="sd">            </span>
</span><span id="VoiceModel-14"><a href="#VoiceModel-14"><span class="linenos"> 14</span></a><span class="sd">    Examples</span>
</span><span id="VoiceModel-15"><a href="#VoiceModel-15"><span class="linenos"> 15</span></a><span class="sd">    --------</span>
</span><span id="VoiceModel-16"><a href="#VoiceModel-16"><span class="linenos"> 16</span></a><span class="sd">    Basic usage with ElevenLabs:</span>
</span><span id="VoiceModel-17"><a href="#VoiceModel-17"><span class="linenos"> 17</span></a><span class="sd">    &gt;&gt;&gt; model = VoiceModel(provider=&quot;elevenlabs&quot;, model=&quot;eleven_multilingual_v2&quot;, voice=&quot;21m00Tcm4TlvDq8ikWAM&quot;)</span>
</span><span id="VoiceModel-18"><a href="#VoiceModel-18"><span class="linenos"> 18</span></a><span class="sd">    &gt;&gt;&gt; audio_file = model.speak(&quot;Hello, world!&quot;)</span>
</span><span id="VoiceModel-19"><a href="#VoiceModel-19"><span class="linenos"> 19</span></a><span class="sd">    </span>
</span><span id="VoiceModel-20"><a href="#VoiceModel-20"><span class="linenos"> 20</span></a><span class="sd">    Using different return types:</span>
</span><span id="VoiceModel-21"><a href="#VoiceModel-21"><span class="linenos"> 21</span></a><span class="sd">    &gt;&gt;&gt; # Save as MP3 file</span>
</span><span id="VoiceModel-22"><a href="#VoiceModel-22"><span class="linenos"> 22</span></a><span class="sd">    &gt;&gt;&gt; audio_file = model.speak(&quot;Hello, world!&quot;, return_type=&quot;output.mp3&quot;)</span>
</span><span id="VoiceModel-23"><a href="#VoiceModel-23"><span class="linenos"> 23</span></a><span class="sd">    </span>
</span><span id="VoiceModel-24"><a href="#VoiceModel-24"><span class="linenos"> 24</span></a><span class="sd">    &gt;&gt;&gt; # Get as base64 string</span>
</span><span id="VoiceModel-25"><a href="#VoiceModel-25"><span class="linenos"> 25</span></a><span class="sd">    &gt;&gt;&gt; audio_b64 = model.speak(&quot;Hello, world!&quot;, return_type=&quot;base64&quot;)</span>
</span><span id="VoiceModel-26"><a href="#VoiceModel-26"><span class="linenos"> 26</span></a><span class="sd">    </span>
</span><span id="VoiceModel-27"><a href="#VoiceModel-27"><span class="linenos"> 27</span></a><span class="sd">    &gt;&gt;&gt; # Get as bytes</span>
</span><span id="VoiceModel-28"><a href="#VoiceModel-28"><span class="linenos"> 28</span></a><span class="sd">    &gt;&gt;&gt; audio_bytes = model.speak(&quot;Hello, world!&quot;, return_type=&quot;bytes&quot;)</span>
</span><span id="VoiceModel-29"><a href="#VoiceModel-29"><span class="linenos"> 29</span></a><span class="sd">    </span>
</span><span id="VoiceModel-30"><a href="#VoiceModel-30"><span class="linenos"> 30</span></a><span class="sd">    Streaming audio generation:</span>
</span><span id="VoiceModel-31"><a href="#VoiceModel-31"><span class="linenos"> 31</span></a><span class="sd">    &gt;&gt;&gt; async for audio_chunk in model.stream(&quot;Long text to convert to speech&quot;):</span>
</span><span id="VoiceModel-32"><a href="#VoiceModel-32"><span class="linenos"> 32</span></a><span class="sd">    ...     print(f&quot;Generated audio chunk: {audio_chunk}&quot;)</span>
</span><span id="VoiceModel-33"><a href="#VoiceModel-33"><span class="linenos"> 33</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="VoiceModel-34"><a href="#VoiceModel-34"><span class="linenos"> 34</span></a>    
</span><span id="VoiceModel-35"><a href="#VoiceModel-35"><span class="linenos"> 35</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">voice</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="VoiceModel-36"><a href="#VoiceModel-36"><span class="linenos"> 36</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel-37"><a href="#VoiceModel-37"><span class="linenos"> 37</span></a><span class="sd">        Initialize a new VoiceModel instance.</span>
</span><span id="VoiceModel-38"><a href="#VoiceModel-38"><span class="linenos"> 38</span></a><span class="sd">        </span>
</span><span id="VoiceModel-39"><a href="#VoiceModel-39"><span class="linenos"> 39</span></a><span class="sd">        Parameters</span>
</span><span id="VoiceModel-40"><a href="#VoiceModel-40"><span class="linenos"> 40</span></a><span class="sd">        ----------</span>
</span><span id="VoiceModel-41"><a href="#VoiceModel-41"><span class="linenos"> 41</span></a><span class="sd">        provider : str</span>
</span><span id="VoiceModel-42"><a href="#VoiceModel-42"><span class="linenos"> 42</span></a><span class="sd">            The voice provider to use (e.g., &#39;elevenlabs&#39;, &#39;openai&#39;)</span>
</span><span id="VoiceModel-43"><a href="#VoiceModel-43"><span class="linenos"> 43</span></a><span class="sd">        model : str</span>
</span><span id="VoiceModel-44"><a href="#VoiceModel-44"><span class="linenos"> 44</span></a><span class="sd">            The specific voice model to use</span>
</span><span id="VoiceModel-45"><a href="#VoiceModel-45"><span class="linenos"> 45</span></a><span class="sd">        voice : str</span>
</span><span id="VoiceModel-46"><a href="#VoiceModel-46"><span class="linenos"> 46</span></a><span class="sd">            The voice ID or voice name to use for speech generation</span>
</span><span id="VoiceModel-47"><a href="#VoiceModel-47"><span class="linenos"> 47</span></a><span class="sd">            </span>
</span><span id="VoiceModel-48"><a href="#VoiceModel-48"><span class="linenos"> 48</span></a><span class="sd">        Raises</span>
</span><span id="VoiceModel-49"><a href="#VoiceModel-49"><span class="linenos"> 49</span></a><span class="sd">        ------</span>
</span><span id="VoiceModel-50"><a href="#VoiceModel-50"><span class="linenos"> 50</span></a><span class="sd">        ImportError</span>
</span><span id="VoiceModel-51"><a href="#VoiceModel-51"><span class="linenos"> 51</span></a><span class="sd">            If the required provider library is not installed</span>
</span><span id="VoiceModel-52"><a href="#VoiceModel-52"><span class="linenos"> 52</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="VoiceModel-53"><a href="#VoiceModel-53"><span class="linenos"> 53</span></a>        <span class="n">load_key</span><span class="p">(</span><span class="n">provider</span><span class="p">)</span>
</span><span id="VoiceModel-54"><a href="#VoiceModel-54"><span class="linenos"> 54</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_provider</span> <span class="o">=</span> <span class="n">provider</span>
</span><span id="VoiceModel-55"><a href="#VoiceModel-55"><span class="linenos"> 55</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="VoiceModel-56"><a href="#VoiceModel-56"><span class="linenos"> 56</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_voice</span> <span class="o">=</span> <span class="n">voice</span>
</span><span id="VoiceModel-57"><a href="#VoiceModel-57"><span class="linenos"> 57</span></a>        
</span><span id="VoiceModel-58"><a href="#VoiceModel-58"><span class="linenos"> 58</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_provider</span> <span class="o">==</span> <span class="s2">&quot;elevenlabs&quot;</span><span class="p">:</span>
</span><span id="VoiceModel-59"><a href="#VoiceModel-59"><span class="linenos"> 59</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="VoiceModel-60"><a href="#VoiceModel-60"><span class="linenos"> 60</span></a>                <span class="kn">from</span><span class="w"> </span><span class="nn">elevenlabs.client</span><span class="w"> </span><span class="kn">import</span> <span class="n">ElevenLabs</span>
</span><span id="VoiceModel-61"><a href="#VoiceModel-61"><span class="linenos"> 61</span></a>            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
</span><span id="VoiceModel-62"><a href="#VoiceModel-62"><span class="linenos"> 62</span></a>                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;elevenlabs is not installed. Please install it with &#39;pip install elevenlabs&#39;&quot;</span><span class="p">)</span>
</span><span id="VoiceModel-63"><a href="#VoiceModel-63"><span class="linenos"> 63</span></a>
</span><span id="VoiceModel-64"><a href="#VoiceModel-64"><span class="linenos"> 64</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_client</span> <span class="o">=</span> <span class="n">ElevenLabs</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;ELEVENLABS_API_KEY&quot;</span><span class="p">))</span>
</span><span id="VoiceModel-65"><a href="#VoiceModel-65"><span class="linenos"> 65</span></a>        
</span><span id="VoiceModel-66"><a href="#VoiceModel-66"><span class="linenos"> 66</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">speak</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">min_chars_per_sentence</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;audio.mp3&quot;</span><span class="p">):</span>
</span><span id="VoiceModel-67"><a href="#VoiceModel-67"><span class="linenos"> 67</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel-68"><a href="#VoiceModel-68"><span class="linenos"> 68</span></a><span class="sd">        Convert text to speech and return the audio in the specified format.</span>
</span><span id="VoiceModel-69"><a href="#VoiceModel-69"><span class="linenos"> 69</span></a><span class="sd">        </span>
</span><span id="VoiceModel-70"><a href="#VoiceModel-70"><span class="linenos"> 70</span></a><span class="sd">        The method automatically splits long text into optimal chunks based on</span>
</span><span id="VoiceModel-71"><a href="#VoiceModel-71"><span class="linenos"> 71</span></a><span class="sd">        sentence boundaries to ensure high-quality audio generation.</span>
</span><span id="VoiceModel-72"><a href="#VoiceModel-72"><span class="linenos"> 72</span></a><span class="sd">        </span>
</span><span id="VoiceModel-73"><a href="#VoiceModel-73"><span class="linenos"> 73</span></a><span class="sd">        Parameters</span>
</span><span id="VoiceModel-74"><a href="#VoiceModel-74"><span class="linenos"> 74</span></a><span class="sd">        ----------</span>
</span><span id="VoiceModel-75"><a href="#VoiceModel-75"><span class="linenos"> 75</span></a><span class="sd">        text : str</span>
</span><span id="VoiceModel-76"><a href="#VoiceModel-76"><span class="linenos"> 76</span></a><span class="sd">            The text to convert to speech</span>
</span><span id="VoiceModel-77"><a href="#VoiceModel-77"><span class="linenos"> 77</span></a><span class="sd">        min_chars_per_sentence : int, optional</span>
</span><span id="VoiceModel-78"><a href="#VoiceModel-78"><span class="linenos"> 78</span></a><span class="sd">            Minimum number of characters per sentence group for optimal audio</span>
</span><span id="VoiceModel-79"><a href="#VoiceModel-79"><span class="linenos"> 79</span></a><span class="sd">            generation (default: 100)</span>
</span><span id="VoiceModel-80"><a href="#VoiceModel-80"><span class="linenos"> 80</span></a><span class="sd">        return_type : str, optional</span>
</span><span id="VoiceModel-81"><a href="#VoiceModel-81"><span class="linenos"> 81</span></a><span class="sd">            The format to return the audio in. Options:</span>
</span><span id="VoiceModel-82"><a href="#VoiceModel-82"><span class="linenos"> 82</span></a><span class="sd">            - File path ending with &#39;.mp3&#39; or &#39;.wav&#39; to save to file</span>
</span><span id="VoiceModel-83"><a href="#VoiceModel-83"><span class="linenos"> 83</span></a><span class="sd">            - &#39;base64&#39; to return as base64 encoded string</span>
</span><span id="VoiceModel-84"><a href="#VoiceModel-84"><span class="linenos"> 84</span></a><span class="sd">            - &#39;bytes&#39; to return as raw bytes (default: &quot;audio.mp3&quot;)</span>
</span><span id="VoiceModel-85"><a href="#VoiceModel-85"><span class="linenos"> 85</span></a><span class="sd">            </span>
</span><span id="VoiceModel-86"><a href="#VoiceModel-86"><span class="linenos"> 86</span></a><span class="sd">        Returns</span>
</span><span id="VoiceModel-87"><a href="#VoiceModel-87"><span class="linenos"> 87</span></a><span class="sd">        -------</span>
</span><span id="VoiceModel-88"><a href="#VoiceModel-88"><span class="linenos"> 88</span></a><span class="sd">        str or bytes</span>
</span><span id="VoiceModel-89"><a href="#VoiceModel-89"><span class="linenos"> 89</span></a><span class="sd">            The generated audio in the specified format:</span>
</span><span id="VoiceModel-90"><a href="#VoiceModel-90"><span class="linenos"> 90</span></a><span class="sd">            - If return_type is a file path: returns the file path</span>
</span><span id="VoiceModel-91"><a href="#VoiceModel-91"><span class="linenos"> 91</span></a><span class="sd">            - If return_type is &#39;base64&#39;: returns base64 encoded string</span>
</span><span id="VoiceModel-92"><a href="#VoiceModel-92"><span class="linenos"> 92</span></a><span class="sd">            - If return_type is &#39;bytes&#39;: returns raw audio bytes</span>
</span><span id="VoiceModel-93"><a href="#VoiceModel-93"><span class="linenos"> 93</span></a><span class="sd">            </span>
</span><span id="VoiceModel-94"><a href="#VoiceModel-94"><span class="linenos"> 94</span></a><span class="sd">        Raises</span>
</span><span id="VoiceModel-95"><a href="#VoiceModel-95"><span class="linenos"> 95</span></a><span class="sd">        ------</span>
</span><span id="VoiceModel-96"><a href="#VoiceModel-96"><span class="linenos"> 96</span></a><span class="sd">        ValueError</span>
</span><span id="VoiceModel-97"><a href="#VoiceModel-97"><span class="linenos"> 97</span></a><span class="sd">            If return_type is not a valid option</span>
</span><span id="VoiceModel-98"><a href="#VoiceModel-98"><span class="linenos"> 98</span></a><span class="sd">            </span>
</span><span id="VoiceModel-99"><a href="#VoiceModel-99"><span class="linenos"> 99</span></a><span class="sd">        Examples</span>
</span><span id="VoiceModel-100"><a href="#VoiceModel-100"><span class="linenos">100</span></a><span class="sd">        --------</span>
</span><span id="VoiceModel-101"><a href="#VoiceModel-101"><span class="linenos">101</span></a><span class="sd">        &gt;&gt;&gt; model = VoiceModel(provider=&quot;elevenlabs&quot;, model=&quot;eleven_multilingual_v2&quot;, voice=&quot;21m00Tcm4TlvDq8ikWAM&quot;)</span>
</span><span id="VoiceModel-102"><a href="#VoiceModel-102"><span class="linenos">102</span></a><span class="sd">        &gt;&gt;&gt; # Save to file</span>
</span><span id="VoiceModel-103"><a href="#VoiceModel-103"><span class="linenos">103</span></a><span class="sd">        &gt;&gt;&gt; audio_file = model.speak(&quot;Hello, world!&quot;, return_type=&quot;output.mp3&quot;)</span>
</span><span id="VoiceModel-104"><a href="#VoiceModel-104"><span class="linenos">104</span></a><span class="sd">        &gt;&gt;&gt; # Get as base64</span>
</span><span id="VoiceModel-105"><a href="#VoiceModel-105"><span class="linenos">105</span></a><span class="sd">        &gt;&gt;&gt; audio_b64 = model.speak(&quot;Hello, world!&quot;, return_type=&quot;base64&quot;)</span>
</span><span id="VoiceModel-106"><a href="#VoiceModel-106"><span class="linenos">106</span></a><span class="sd">        &gt;&gt;&gt; # Get as bytes</span>
</span><span id="VoiceModel-107"><a href="#VoiceModel-107"><span class="linenos">107</span></a><span class="sd">        &gt;&gt;&gt; audio_bytes = model.speak(&quot;Hello, world!&quot;, return_type=&quot;bytes&quot;)</span>
</span><span id="VoiceModel-108"><a href="#VoiceModel-108"><span class="linenos">108</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="VoiceModel-109"><a href="#VoiceModel-109"><span class="linenos">109</span></a>        <span class="n">audio_groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_audio_groups</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">min_chars_per_sentence</span><span class="p">)</span>
</span><span id="VoiceModel-110"><a href="#VoiceModel-110"><span class="linenos">110</span></a>        <span class="n">audio_chunks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="VoiceModel-111"><a href="#VoiceModel-111"><span class="linenos">111</span></a>        
</span><span id="VoiceModel-112"><a href="#VoiceModel-112"><span class="linenos">112</span></a>        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">audio_groups</span><span class="p">:</span>
</span><span id="VoiceModel-113"><a href="#VoiceModel-113"><span class="linenos">113</span></a>            
</span><span id="VoiceModel-114"><a href="#VoiceModel-114"><span class="linenos">114</span></a>            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
</span><span id="VoiceModel-115"><a href="#VoiceModel-115"><span class="linenos">115</span></a>            
</span><span id="VoiceModel-116"><a href="#VoiceModel-116"><span class="linenos">116</span></a>            <span class="n">audio_chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span id="VoiceModel-117"><a href="#VoiceModel-117"><span class="linenos">117</span></a>        
</span><span id="VoiceModel-118"><a href="#VoiceModel-118"><span class="linenos">118</span></a>        <span class="k">if</span> <span class="n">return_type</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.mp3&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">return_type</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.wav&quot;</span><span class="p">):</span>
</span><span id="VoiceModel-119"><a href="#VoiceModel-119"><span class="linenos">119</span></a>            <span class="n">combined_audio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_bytes_chunks</span><span class="p">(</span><span class="n">audio_chunks</span><span class="p">)</span>
</span><span id="VoiceModel-120"><a href="#VoiceModel-120"><span class="linenos">120</span></a>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">return_type</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="VoiceModel-121"><a href="#VoiceModel-121"><span class="linenos">121</span></a>                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">combined_audio</span><span class="p">)</span>
</span><span id="VoiceModel-122"><a href="#VoiceModel-122"><span class="linenos">122</span></a>            <span class="k">return</span> <span class="n">return_type</span>
</span><span id="VoiceModel-123"><a href="#VoiceModel-123"><span class="linenos">123</span></a>        <span class="k">elif</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;base64&quot;</span><span class="p">:</span>
</span><span id="VoiceModel-124"><a href="#VoiceModel-124"><span class="linenos">124</span></a>            <span class="n">combined_audio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_bytes_chunks</span><span class="p">(</span><span class="n">audio_chunks</span><span class="p">)</span>
</span><span id="VoiceModel-125"><a href="#VoiceModel-125"><span class="linenos">125</span></a>            <span class="k">return</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">combined_audio</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span><span id="VoiceModel-126"><a href="#VoiceModel-126"><span class="linenos">126</span></a>        <span class="k">elif</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;bytes&quot;</span><span class="p">:</span>
</span><span id="VoiceModel-127"><a href="#VoiceModel-127"><span class="linenos">127</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_bytes_chunks</span><span class="p">(</span><span class="n">audio_chunks</span><span class="p">)</span>
</span><span id="VoiceModel-128"><a href="#VoiceModel-128"><span class="linenos">128</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="VoiceModel-129"><a href="#VoiceModel-129"><span class="linenos">129</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid return type: </span><span class="si">{</span><span class="n">return_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="VoiceModel-130"><a href="#VoiceModel-130"><span class="linenos">130</span></a>    
</span><span id="VoiceModel-131"><a href="#VoiceModel-131"><span class="linenos">131</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_combine_bytes_chunks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_chunks</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
</span><span id="VoiceModel-132"><a href="#VoiceModel-132"><span class="linenos">132</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel-133"><a href="#VoiceModel-133"><span class="linenos">133</span></a><span class="sd">        Combine audio chunks into a single bytes object.</span>
</span><span id="VoiceModel-134"><a href="#VoiceModel-134"><span class="linenos">134</span></a><span class="sd">        </span>
</span><span id="VoiceModel-135"><a href="#VoiceModel-135"><span class="linenos">135</span></a><span class="sd">        Parameters</span>
</span><span id="VoiceModel-136"><a href="#VoiceModel-136"><span class="linenos">136</span></a><span class="sd">        ----------</span>
</span><span id="VoiceModel-137"><a href="#VoiceModel-137"><span class="linenos">137</span></a><span class="sd">        audio_chunks : list</span>
</span><span id="VoiceModel-138"><a href="#VoiceModel-138"><span class="linenos">138</span></a><span class="sd">            List of audio byte chunks to combine</span>
</span><span id="VoiceModel-139"><a href="#VoiceModel-139"><span class="linenos">139</span></a><span class="sd">            </span>
</span><span id="VoiceModel-140"><a href="#VoiceModel-140"><span class="linenos">140</span></a><span class="sd">        Returns</span>
</span><span id="VoiceModel-141"><a href="#VoiceModel-141"><span class="linenos">141</span></a><span class="sd">        -------</span>
</span><span id="VoiceModel-142"><a href="#VoiceModel-142"><span class="linenos">142</span></a><span class="sd">        bytes</span>
</span><span id="VoiceModel-143"><a href="#VoiceModel-143"><span class="linenos">143</span></a><span class="sd">            Combined audio data as bytes</span>
</span><span id="VoiceModel-144"><a href="#VoiceModel-144"><span class="linenos">144</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="VoiceModel-145"><a href="#VoiceModel-145"><span class="linenos">145</span></a>        <span class="n">combined</span> <span class="o">=</span> <span class="sa">b</span><span class="s2">&quot;&quot;</span>
</span><span id="VoiceModel-146"><a href="#VoiceModel-146"><span class="linenos">146</span></a>        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_chunks</span><span class="p">:</span>
</span><span id="VoiceModel-147"><a href="#VoiceModel-147"><span class="linenos">147</span></a>            <span class="n">combined</span> <span class="o">+=</span> <span class="n">chunk</span>
</span><span id="VoiceModel-148"><a href="#VoiceModel-148"><span class="linenos">148</span></a>        <span class="k">return</span> <span class="n">combined</span>
</span><span id="VoiceModel-149"><a href="#VoiceModel-149"><span class="linenos">149</span></a>    
</span><span id="VoiceModel-150"><a href="#VoiceModel-150"><span class="linenos">150</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_audio_groups</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">min_chars_per_sentence</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="VoiceModel-151"><a href="#VoiceModel-151"><span class="linenos">151</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel-152"><a href="#VoiceModel-152"><span class="linenos">152</span></a><span class="sd">        Generate optimized sentence groups for audio generation.</span>
</span><span id="VoiceModel-153"><a href="#VoiceModel-153"><span class="linenos">153</span></a><span class="sd">        </span>
</span><span id="VoiceModel-154"><a href="#VoiceModel-154"><span class="linenos">154</span></a><span class="sd">        Splits text into sentence groups that meet the minimum character requirement</span>
</span><span id="VoiceModel-155"><a href="#VoiceModel-155"><span class="linenos">155</span></a><span class="sd">        for optimal audio quality while respecting sentence boundaries.</span>
</span><span id="VoiceModel-156"><a href="#VoiceModel-156"><span class="linenos">156</span></a><span class="sd">        </span>
</span><span id="VoiceModel-157"><a href="#VoiceModel-157"><span class="linenos">157</span></a><span class="sd">        Parameters</span>
</span><span id="VoiceModel-158"><a href="#VoiceModel-158"><span class="linenos">158</span></a><span class="sd">        ----------</span>
</span><span id="VoiceModel-159"><a href="#VoiceModel-159"><span class="linenos">159</span></a><span class="sd">        text : str</span>
</span><span id="VoiceModel-160"><a href="#VoiceModel-160"><span class="linenos">160</span></a><span class="sd">            The text to split into groups</span>
</span><span id="VoiceModel-161"><a href="#VoiceModel-161"><span class="linenos">161</span></a><span class="sd">        min_chars_per_sentence : int</span>
</span><span id="VoiceModel-162"><a href="#VoiceModel-162"><span class="linenos">162</span></a><span class="sd">            Minimum number of characters per sentence group</span>
</span><span id="VoiceModel-163"><a href="#VoiceModel-163"><span class="linenos">163</span></a><span class="sd">            </span>
</span><span id="VoiceModel-164"><a href="#VoiceModel-164"><span class="linenos">164</span></a><span class="sd">        Returns</span>
</span><span id="VoiceModel-165"><a href="#VoiceModel-165"><span class="linenos">165</span></a><span class="sd">        -------</span>
</span><span id="VoiceModel-166"><a href="#VoiceModel-166"><span class="linenos">166</span></a><span class="sd">        list</span>
</span><span id="VoiceModel-167"><a href="#VoiceModel-167"><span class="linenos">167</span></a><span class="sd">            List of sentence groups optimized for audio generation</span>
</span><span id="VoiceModel-168"><a href="#VoiceModel-168"><span class="linenos">168</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="VoiceModel-169"><a href="#VoiceModel-169"><span class="linenos">169</span></a>        <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>
</span><span id="VoiceModel-170"><a href="#VoiceModel-170"><span class="linenos">170</span></a>        <span class="n">audio_groups</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="VoiceModel-171"><a href="#VoiceModel-171"><span class="linenos">171</span></a>        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="VoiceModel-172"><a href="#VoiceModel-172"><span class="linenos">172</span></a>        
</span><span id="VoiceModel-173"><a href="#VoiceModel-173"><span class="linenos">173</span></a>        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
</span><span id="VoiceModel-174"><a href="#VoiceModel-174"><span class="linenos">174</span></a>            <span class="n">current_group</span> <span class="o">=</span> <span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="VoiceModel-175"><a href="#VoiceModel-175"><span class="linenos">175</span></a>            <span class="n">j</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="VoiceModel-176"><a href="#VoiceModel-176"><span class="linenos">176</span></a>            
</span><span id="VoiceModel-177"><a href="#VoiceModel-177"><span class="linenos">177</span></a>            <span class="c1"># Continue adding subsequent sentences until min_chars_per_sentence is exceeded</span>
</span><span id="VoiceModel-178"><a href="#VoiceModel-178"><span class="linenos">178</span></a>            <span class="k">while</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
</span><span id="VoiceModel-179"><a href="#VoiceModel-179"><span class="linenos">179</span></a>                <span class="n">next_sentence</span> <span class="o">=</span> <span class="n">sentences</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
</span><span id="VoiceModel-180"><a href="#VoiceModel-180"><span class="linenos">180</span></a>                <span class="n">combined_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_group</span> <span class="o">+</span> <span class="s2">&quot;. &quot;</span> <span class="o">+</span> <span class="n">next_sentence</span><span class="p">)</span>
</span><span id="VoiceModel-181"><a href="#VoiceModel-181"><span class="linenos">181</span></a>                
</span><span id="VoiceModel-182"><a href="#VoiceModel-182"><span class="linenos">182</span></a>                <span class="c1"># If the combination exceeds the limit, stop</span>
</span><span id="VoiceModel-183"><a href="#VoiceModel-183"><span class="linenos">183</span></a>                <span class="k">if</span> <span class="n">combined_length</span> <span class="o">&gt;</span> <span class="n">min_chars_per_sentence</span><span class="p">:</span>
</span><span id="VoiceModel-184"><a href="#VoiceModel-184"><span class="linenos">184</span></a>                    <span class="k">break</span>
</span><span id="VoiceModel-185"><a href="#VoiceModel-185"><span class="linenos">185</span></a>                
</span><span id="VoiceModel-186"><a href="#VoiceModel-186"><span class="linenos">186</span></a>                <span class="c1"># Otherwise, join the next sentence</span>
</span><span id="VoiceModel-187"><a href="#VoiceModel-187"><span class="linenos">187</span></a>                <span class="n">current_group</span> <span class="o">+=</span> <span class="s2">&quot;. &quot;</span> <span class="o">+</span> <span class="n">next_sentence</span>
</span><span id="VoiceModel-188"><a href="#VoiceModel-188"><span class="linenos">188</span></a>                <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="VoiceModel-189"><a href="#VoiceModel-189"><span class="linenos">189</span></a>            
</span><span id="VoiceModel-190"><a href="#VoiceModel-190"><span class="linenos">190</span></a>            <span class="n">audio_groups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_group</span><span class="p">)</span>
</span><span id="VoiceModel-191"><a href="#VoiceModel-191"><span class="linenos">191</span></a>            <span class="c1"># Move to the next unprocessed sentence</span>
</span><span id="VoiceModel-192"><a href="#VoiceModel-192"><span class="linenos">192</span></a>            <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>
</span><span id="VoiceModel-193"><a href="#VoiceModel-193"><span class="linenos">193</span></a>        
</span><span id="VoiceModel-194"><a href="#VoiceModel-194"><span class="linenos">194</span></a>        <span class="k">return</span> <span class="n">audio_groups</span>
</span><span id="VoiceModel-195"><a href="#VoiceModel-195"><span class="linenos">195</span></a>        
</span><span id="VoiceModel-196"><a href="#VoiceModel-196"><span class="linenos">196</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
</span><span id="VoiceModel-197"><a href="#VoiceModel-197"><span class="linenos">197</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel-198"><a href="#VoiceModel-198"><span class="linenos">198</span></a><span class="sd">        Generate audio from text using the configured provider.</span>
</span><span id="VoiceModel-199"><a href="#VoiceModel-199"><span class="linenos">199</span></a><span class="sd">        </span>
</span><span id="VoiceModel-200"><a href="#VoiceModel-200"><span class="linenos">200</span></a><span class="sd">        Parameters</span>
</span><span id="VoiceModel-201"><a href="#VoiceModel-201"><span class="linenos">201</span></a><span class="sd">        ----------</span>
</span><span id="VoiceModel-202"><a href="#VoiceModel-202"><span class="linenos">202</span></a><span class="sd">        text : str</span>
</span><span id="VoiceModel-203"><a href="#VoiceModel-203"><span class="linenos">203</span></a><span class="sd">            The text to convert to speech</span>
</span><span id="VoiceModel-204"><a href="#VoiceModel-204"><span class="linenos">204</span></a><span class="sd">            </span>
</span><span id="VoiceModel-205"><a href="#VoiceModel-205"><span class="linenos">205</span></a><span class="sd">        Returns</span>
</span><span id="VoiceModel-206"><a href="#VoiceModel-206"><span class="linenos">206</span></a><span class="sd">        -------</span>
</span><span id="VoiceModel-207"><a href="#VoiceModel-207"><span class="linenos">207</span></a><span class="sd">        bytes</span>
</span><span id="VoiceModel-208"><a href="#VoiceModel-208"><span class="linenos">208</span></a><span class="sd">            Generated audio data as bytes</span>
</span><span id="VoiceModel-209"><a href="#VoiceModel-209"><span class="linenos">209</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="VoiceModel-210"><a href="#VoiceModel-210"><span class="linenos">210</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_provider</span> <span class="o">==</span> <span class="s2">&quot;elevenlabs&quot;</span><span class="p">:</span>
</span><span id="VoiceModel-211"><a href="#VoiceModel-211"><span class="linenos">211</span></a>            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">text_to_speech</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span>
</span><span id="VoiceModel-212"><a href="#VoiceModel-212"><span class="linenos">212</span></a>                <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
</span><span id="VoiceModel-213"><a href="#VoiceModel-213"><span class="linenos">213</span></a>                <span class="n">voice_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_voice</span><span class="p">,</span>
</span><span id="VoiceModel-214"><a href="#VoiceModel-214"><span class="linenos">214</span></a>                <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span>
</span><span id="VoiceModel-215"><a href="#VoiceModel-215"><span class="linenos">215</span></a>                <span class="n">output_format</span><span class="o">=</span><span class="s2">&quot;mp3_44100_128&quot;</span><span class="p">,</span>
</span><span id="VoiceModel-216"><a href="#VoiceModel-216"><span class="linenos">216</span></a>            <span class="p">)</span>
</span><span id="VoiceModel-217"><a href="#VoiceModel-217"><span class="linenos">217</span></a>            <span class="n">response_bytes</span> <span class="o">=</span> <span class="sa">b</span><span class="s2">&quot;&quot;</span>
</span><span id="VoiceModel-218"><a href="#VoiceModel-218"><span class="linenos">218</span></a>            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">response</span><span class="p">:</span>
</span><span id="VoiceModel-219"><a href="#VoiceModel-219"><span class="linenos">219</span></a>                <span class="n">response_bytes</span> <span class="o">+=</span> <span class="n">r</span>
</span><span id="VoiceModel-220"><a href="#VoiceModel-220"><span class="linenos">220</span></a>            <span class="k">return</span> <span class="n">response_bytes</span>
</span><span id="VoiceModel-221"><a href="#VoiceModel-221"><span class="linenos">221</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="VoiceModel-222"><a href="#VoiceModel-222"><span class="linenos">222</span></a>            <span class="n">response</span> <span class="o">=</span> <span class="n">speech</span><span class="p">(</span>
</span><span id="VoiceModel-223"><a href="#VoiceModel-223"><span class="linenos">223</span></a>                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_provider</span><span class="o">+</span><span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span>
</span><span id="VoiceModel-224"><a href="#VoiceModel-224"><span class="linenos">224</span></a>                <span class="n">voice</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_voice</span><span class="p">,</span>
</span><span id="VoiceModel-225"><a href="#VoiceModel-225"><span class="linenos">225</span></a>                <span class="nb">input</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
</span><span id="VoiceModel-226"><a href="#VoiceModel-226"><span class="linenos">226</span></a>            <span class="p">)</span>
</span><span id="VoiceModel-227"><a href="#VoiceModel-227"><span class="linenos">227</span></a>            <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">content</span>
</span><span id="VoiceModel-228"><a href="#VoiceModel-228"><span class="linenos">228</span></a>    
</span><span id="VoiceModel-229"><a href="#VoiceModel-229"><span class="linenos">229</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">min_chars_per_sentence</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;audio.mp3&quot;</span><span class="p">):</span>
</span><span id="VoiceModel-230"><a href="#VoiceModel-230"><span class="linenos">230</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel-231"><a href="#VoiceModel-231"><span class="linenos">231</span></a><span class="sd">        Stream audio generation for long texts.</span>
</span><span id="VoiceModel-232"><a href="#VoiceModel-232"><span class="linenos">232</span></a><span class="sd">        </span>
</span><span id="VoiceModel-233"><a href="#VoiceModel-233"><span class="linenos">233</span></a><span class="sd">        Generates audio in chunks for long texts, yielding each chunk as it&#39;s</span>
</span><span id="VoiceModel-234"><a href="#VoiceModel-234"><span class="linenos">234</span></a><span class="sd">        generated. This is useful for real-time audio generation or processing</span>
</span><span id="VoiceModel-235"><a href="#VoiceModel-235"><span class="linenos">235</span></a><span class="sd">        very long texts.</span>
</span><span id="VoiceModel-236"><a href="#VoiceModel-236"><span class="linenos">236</span></a><span class="sd">        </span>
</span><span id="VoiceModel-237"><a href="#VoiceModel-237"><span class="linenos">237</span></a><span class="sd">        Parameters</span>
</span><span id="VoiceModel-238"><a href="#VoiceModel-238"><span class="linenos">238</span></a><span class="sd">        ----------</span>
</span><span id="VoiceModel-239"><a href="#VoiceModel-239"><span class="linenos">239</span></a><span class="sd">        text : str</span>
</span><span id="VoiceModel-240"><a href="#VoiceModel-240"><span class="linenos">240</span></a><span class="sd">            The text to convert to speech</span>
</span><span id="VoiceModel-241"><a href="#VoiceModel-241"><span class="linenos">241</span></a><span class="sd">        min_chars_per_sentence : int, optional</span>
</span><span id="VoiceModel-242"><a href="#VoiceModel-242"><span class="linenos">242</span></a><span class="sd">            Minimum number of characters per sentence group for optimal audio</span>
</span><span id="VoiceModel-243"><a href="#VoiceModel-243"><span class="linenos">243</span></a><span class="sd">            generation (default: 100)</span>
</span><span id="VoiceModel-244"><a href="#VoiceModel-244"><span class="linenos">244</span></a><span class="sd">        return_type : str, optional</span>
</span><span id="VoiceModel-245"><a href="#VoiceModel-245"><span class="linenos">245</span></a><span class="sd">            The format to return each audio chunk in. Options:</span>
</span><span id="VoiceModel-246"><a href="#VoiceModel-246"><span class="linenos">246</span></a><span class="sd">            - File path ending with &#39;.mp3&#39; or &#39;.wav&#39; to save each chunk to file</span>
</span><span id="VoiceModel-247"><a href="#VoiceModel-247"><span class="linenos">247</span></a><span class="sd">            - &#39;base64&#39; to return each chunk as base64 encoded string</span>
</span><span id="VoiceModel-248"><a href="#VoiceModel-248"><span class="linenos">248</span></a><span class="sd">            - &#39;bytes&#39; to return each chunk as raw bytes (default: &quot;audio.mp3&quot;)</span>
</span><span id="VoiceModel-249"><a href="#VoiceModel-249"><span class="linenos">249</span></a><span class="sd">            </span>
</span><span id="VoiceModel-250"><a href="#VoiceModel-250"><span class="linenos">250</span></a><span class="sd">        Yields</span>
</span><span id="VoiceModel-251"><a href="#VoiceModel-251"><span class="linenos">251</span></a><span class="sd">        ------</span>
</span><span id="VoiceModel-252"><a href="#VoiceModel-252"><span class="linenos">252</span></a><span class="sd">        str or bytes</span>
</span><span id="VoiceModel-253"><a href="#VoiceModel-253"><span class="linenos">253</span></a><span class="sd">            Audio chunks in the specified format:</span>
</span><span id="VoiceModel-254"><a href="#VoiceModel-254"><span class="linenos">254</span></a><span class="sd">            - If return_type is a file path: yields the file path for each chunk</span>
</span><span id="VoiceModel-255"><a href="#VoiceModel-255"><span class="linenos">255</span></a><span class="sd">            - If return_type is &#39;base64&#39;: yields base64 encoded strings</span>
</span><span id="VoiceModel-256"><a href="#VoiceModel-256"><span class="linenos">256</span></a><span class="sd">            - If return_type is &#39;bytes&#39;: yields raw audio bytes</span>
</span><span id="VoiceModel-257"><a href="#VoiceModel-257"><span class="linenos">257</span></a><span class="sd">            </span>
</span><span id="VoiceModel-258"><a href="#VoiceModel-258"><span class="linenos">258</span></a><span class="sd">        Raises</span>
</span><span id="VoiceModel-259"><a href="#VoiceModel-259"><span class="linenos">259</span></a><span class="sd">        ------</span>
</span><span id="VoiceModel-260"><a href="#VoiceModel-260"><span class="linenos">260</span></a><span class="sd">        ValueError</span>
</span><span id="VoiceModel-261"><a href="#VoiceModel-261"><span class="linenos">261</span></a><span class="sd">            If return_type is not a valid option</span>
</span><span id="VoiceModel-262"><a href="#VoiceModel-262"><span class="linenos">262</span></a><span class="sd">            </span>
</span><span id="VoiceModel-263"><a href="#VoiceModel-263"><span class="linenos">263</span></a><span class="sd">        Examples</span>
</span><span id="VoiceModel-264"><a href="#VoiceModel-264"><span class="linenos">264</span></a><span class="sd">        --------</span>
</span><span id="VoiceModel-265"><a href="#VoiceModel-265"><span class="linenos">265</span></a><span class="sd">        &gt;&gt;&gt; model = VoiceModel(provider=&quot;elevenlabs&quot;, model=&quot;eleven_multilingual_v2&quot;, voice=&quot;21m00Tcm4TlvDq8ikWAM&quot;)</span>
</span><span id="VoiceModel-266"><a href="#VoiceModel-266"><span class="linenos">266</span></a><span class="sd">        &gt;&gt;&gt; async for audio_chunk in model.stream(&quot;Long text to convert to speech&quot;):</span>
</span><span id="VoiceModel-267"><a href="#VoiceModel-267"><span class="linenos">267</span></a><span class="sd">        ...     print(f&quot;Generated audio chunk: {audio_chunk}&quot;)</span>
</span><span id="VoiceModel-268"><a href="#VoiceModel-268"><span class="linenos">268</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="VoiceModel-269"><a href="#VoiceModel-269"><span class="linenos">269</span></a>        <span class="n">audio_groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_audio_groups</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">min_chars_per_sentence</span><span class="p">)</span>
</span><span id="VoiceModel-270"><a href="#VoiceModel-270"><span class="linenos">270</span></a>        
</span><span id="VoiceModel-271"><a href="#VoiceModel-271"><span class="linenos">271</span></a>        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">audio_groups</span><span class="p">):</span>
</span><span id="VoiceModel-272"><a href="#VoiceModel-272"><span class="linenos">272</span></a>            <span class="c1"># Generate audio for the sentence group</span>
</span><span id="VoiceModel-273"><a href="#VoiceModel-273"><span class="linenos">273</span></a>            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
</span><span id="VoiceModel-274"><a href="#VoiceModel-274"><span class="linenos">274</span></a>
</span><span id="VoiceModel-275"><a href="#VoiceModel-275"><span class="linenos">275</span></a>            <span class="k">if</span> <span class="n">return_type</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.mp3&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">return_type</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.wav&quot;</span><span class="p">):</span>
</span><span id="VoiceModel-276"><a href="#VoiceModel-276"><span class="linenos">276</span></a>                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">return_type</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="VoiceModel-277"><a href="#VoiceModel-277"><span class="linenos">277</span></a>                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span id="VoiceModel-278"><a href="#VoiceModel-278"><span class="linenos">278</span></a>                <span class="k">yield</span> <span class="n">return_type</span>
</span><span id="VoiceModel-279"><a href="#VoiceModel-279"><span class="linenos">279</span></a>            <span class="k">elif</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;base64&quot;</span><span class="p">:</span>
</span><span id="VoiceModel-280"><a href="#VoiceModel-280"><span class="linenos">280</span></a>                <span class="k">yield</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span><span id="VoiceModel-281"><a href="#VoiceModel-281"><span class="linenos">281</span></a>            <span class="k">elif</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;bytes&quot;</span><span class="p">:</span>
</span><span id="VoiceModel-282"><a href="#VoiceModel-282"><span class="linenos">282</span></a>                <span class="k">yield</span> <span class="n">response</span>
</span><span id="VoiceModel-283"><a href="#VoiceModel-283"><span class="linenos">283</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="VoiceModel-284"><a href="#VoiceModel-284"><span class="linenos">284</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid return type: </span><span class="si">{</span><span class="n">return_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A class for text-to-speech using various AI voice models.</p>

<p>VoiceModel provides an interface for converting text to speech using different
AI voice providers. Currently supports ElevenLabs and OpenAI voice models.</p>

<h6 id="examples">Examples</h6>

<p>Basic usage with ElevenLabs:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">VoiceModel</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;elevenlabs&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;eleven_multilingual_v2&quot;</span><span class="p">,</span> <span class="n">voice</span><span class="o">=</span><span class="s2">&quot;21m00Tcm4TlvDq8ikWAM&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">audio_file</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">speak</span><span class="p">(</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">)</span>
</code></pre>
</div>

<p>Using different return types:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Save as MP3 file</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">audio_file</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">speak</span><span class="p">(</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;output.mp3&quot;</span><span class="p">)</span>
</code></pre>
</div>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get as base64 string</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">audio_b64</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">speak</span><span class="p">(</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;base64&quot;</span><span class="p">)</span>
</code></pre>
</div>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get as bytes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">audio_bytes</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">speak</span><span class="p">(</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;bytes&quot;</span><span class="p">)</span>
</code></pre>
</div>

<p>Streaming audio generation:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="k">async</span> <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="s2">&quot;Long text to convert to speech&quot;</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated audio chunk: </span><span class="si">{</span><span class="n">audio_chunk</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre>
</div>
</div>


                            <div id="VoiceModel.__init__" class="classattr">
                                        <input id="VoiceModel.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">VoiceModel</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">provider</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">model</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">voice</span><span class="p">:</span> <span class="nb">str</span></span>)</span>

                <label class="view-source-button" for="VoiceModel.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#VoiceModel.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="VoiceModel.__init__-35"><a href="#VoiceModel.__init__-35"><span class="linenos">35</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">voice</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="VoiceModel.__init__-36"><a href="#VoiceModel.__init__-36"><span class="linenos">36</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel.__init__-37"><a href="#VoiceModel.__init__-37"><span class="linenos">37</span></a><span class="sd">        Initialize a new VoiceModel instance.</span>
</span><span id="VoiceModel.__init__-38"><a href="#VoiceModel.__init__-38"><span class="linenos">38</span></a><span class="sd">        </span>
</span><span id="VoiceModel.__init__-39"><a href="#VoiceModel.__init__-39"><span class="linenos">39</span></a><span class="sd">        Parameters</span>
</span><span id="VoiceModel.__init__-40"><a href="#VoiceModel.__init__-40"><span class="linenos">40</span></a><span class="sd">        ----------</span>
</span><span id="VoiceModel.__init__-41"><a href="#VoiceModel.__init__-41"><span class="linenos">41</span></a><span class="sd">        provider : str</span>
</span><span id="VoiceModel.__init__-42"><a href="#VoiceModel.__init__-42"><span class="linenos">42</span></a><span class="sd">            The voice provider to use (e.g., &#39;elevenlabs&#39;, &#39;openai&#39;)</span>
</span><span id="VoiceModel.__init__-43"><a href="#VoiceModel.__init__-43"><span class="linenos">43</span></a><span class="sd">        model : str</span>
</span><span id="VoiceModel.__init__-44"><a href="#VoiceModel.__init__-44"><span class="linenos">44</span></a><span class="sd">            The specific voice model to use</span>
</span><span id="VoiceModel.__init__-45"><a href="#VoiceModel.__init__-45"><span class="linenos">45</span></a><span class="sd">        voice : str</span>
</span><span id="VoiceModel.__init__-46"><a href="#VoiceModel.__init__-46"><span class="linenos">46</span></a><span class="sd">            The voice ID or voice name to use for speech generation</span>
</span><span id="VoiceModel.__init__-47"><a href="#VoiceModel.__init__-47"><span class="linenos">47</span></a><span class="sd">            </span>
</span><span id="VoiceModel.__init__-48"><a href="#VoiceModel.__init__-48"><span class="linenos">48</span></a><span class="sd">        Raises</span>
</span><span id="VoiceModel.__init__-49"><a href="#VoiceModel.__init__-49"><span class="linenos">49</span></a><span class="sd">        ------</span>
</span><span id="VoiceModel.__init__-50"><a href="#VoiceModel.__init__-50"><span class="linenos">50</span></a><span class="sd">        ImportError</span>
</span><span id="VoiceModel.__init__-51"><a href="#VoiceModel.__init__-51"><span class="linenos">51</span></a><span class="sd">            If the required provider library is not installed</span>
</span><span id="VoiceModel.__init__-52"><a href="#VoiceModel.__init__-52"><span class="linenos">52</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="VoiceModel.__init__-53"><a href="#VoiceModel.__init__-53"><span class="linenos">53</span></a>        <span class="n">load_key</span><span class="p">(</span><span class="n">provider</span><span class="p">)</span>
</span><span id="VoiceModel.__init__-54"><a href="#VoiceModel.__init__-54"><span class="linenos">54</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_provider</span> <span class="o">=</span> <span class="n">provider</span>
</span><span id="VoiceModel.__init__-55"><a href="#VoiceModel.__init__-55"><span class="linenos">55</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="VoiceModel.__init__-56"><a href="#VoiceModel.__init__-56"><span class="linenos">56</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_voice</span> <span class="o">=</span> <span class="n">voice</span>
</span><span id="VoiceModel.__init__-57"><a href="#VoiceModel.__init__-57"><span class="linenos">57</span></a>        
</span><span id="VoiceModel.__init__-58"><a href="#VoiceModel.__init__-58"><span class="linenos">58</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_provider</span> <span class="o">==</span> <span class="s2">&quot;elevenlabs&quot;</span><span class="p">:</span>
</span><span id="VoiceModel.__init__-59"><a href="#VoiceModel.__init__-59"><span class="linenos">59</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="VoiceModel.__init__-60"><a href="#VoiceModel.__init__-60"><span class="linenos">60</span></a>                <span class="kn">from</span><span class="w"> </span><span class="nn">elevenlabs.client</span><span class="w"> </span><span class="kn">import</span> <span class="n">ElevenLabs</span>
</span><span id="VoiceModel.__init__-61"><a href="#VoiceModel.__init__-61"><span class="linenos">61</span></a>            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
</span><span id="VoiceModel.__init__-62"><a href="#VoiceModel.__init__-62"><span class="linenos">62</span></a>                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;elevenlabs is not installed. Please install it with &#39;pip install elevenlabs&#39;&quot;</span><span class="p">)</span>
</span><span id="VoiceModel.__init__-63"><a href="#VoiceModel.__init__-63"><span class="linenos">63</span></a>
</span><span id="VoiceModel.__init__-64"><a href="#VoiceModel.__init__-64"><span class="linenos">64</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_client</span> <span class="o">=</span> <span class="n">ElevenLabs</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;ELEVENLABS_API_KEY&quot;</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Initialize a new VoiceModel instance.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>provider</strong> (str):
The voice provider to use (e.g., 'elevenlabs', 'openai')</li>
<li><strong>model</strong> (str):
The specific voice model to use</li>
<li><strong>voice</strong> (str):
The voice ID or voice name to use for speech generation</li>
</ul>

<h6 id="raises">Raises</h6>

<ul>
<li><strong>ImportError</strong>: If the required provider library is not installed</li>
</ul>
</div>


                            </div>
                            <div id="VoiceModel.speak" class="classattr">
                                        <input id="VoiceModel.speak-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">speak</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">text</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">min_chars_per_sentence</span><span class="o">=</span><span class="mi">100</span>, </span><span class="param"><span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;audio.mp3&#39;</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="VoiceModel.speak-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#VoiceModel.speak"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="VoiceModel.speak-66"><a href="#VoiceModel.speak-66"><span class="linenos"> 66</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">speak</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">min_chars_per_sentence</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;audio.mp3&quot;</span><span class="p">):</span>
</span><span id="VoiceModel.speak-67"><a href="#VoiceModel.speak-67"><span class="linenos"> 67</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel.speak-68"><a href="#VoiceModel.speak-68"><span class="linenos"> 68</span></a><span class="sd">        Convert text to speech and return the audio in the specified format.</span>
</span><span id="VoiceModel.speak-69"><a href="#VoiceModel.speak-69"><span class="linenos"> 69</span></a><span class="sd">        </span>
</span><span id="VoiceModel.speak-70"><a href="#VoiceModel.speak-70"><span class="linenos"> 70</span></a><span class="sd">        The method automatically splits long text into optimal chunks based on</span>
</span><span id="VoiceModel.speak-71"><a href="#VoiceModel.speak-71"><span class="linenos"> 71</span></a><span class="sd">        sentence boundaries to ensure high-quality audio generation.</span>
</span><span id="VoiceModel.speak-72"><a href="#VoiceModel.speak-72"><span class="linenos"> 72</span></a><span class="sd">        </span>
</span><span id="VoiceModel.speak-73"><a href="#VoiceModel.speak-73"><span class="linenos"> 73</span></a><span class="sd">        Parameters</span>
</span><span id="VoiceModel.speak-74"><a href="#VoiceModel.speak-74"><span class="linenos"> 74</span></a><span class="sd">        ----------</span>
</span><span id="VoiceModel.speak-75"><a href="#VoiceModel.speak-75"><span class="linenos"> 75</span></a><span class="sd">        text : str</span>
</span><span id="VoiceModel.speak-76"><a href="#VoiceModel.speak-76"><span class="linenos"> 76</span></a><span class="sd">            The text to convert to speech</span>
</span><span id="VoiceModel.speak-77"><a href="#VoiceModel.speak-77"><span class="linenos"> 77</span></a><span class="sd">        min_chars_per_sentence : int, optional</span>
</span><span id="VoiceModel.speak-78"><a href="#VoiceModel.speak-78"><span class="linenos"> 78</span></a><span class="sd">            Minimum number of characters per sentence group for optimal audio</span>
</span><span id="VoiceModel.speak-79"><a href="#VoiceModel.speak-79"><span class="linenos"> 79</span></a><span class="sd">            generation (default: 100)</span>
</span><span id="VoiceModel.speak-80"><a href="#VoiceModel.speak-80"><span class="linenos"> 80</span></a><span class="sd">        return_type : str, optional</span>
</span><span id="VoiceModel.speak-81"><a href="#VoiceModel.speak-81"><span class="linenos"> 81</span></a><span class="sd">            The format to return the audio in. Options:</span>
</span><span id="VoiceModel.speak-82"><a href="#VoiceModel.speak-82"><span class="linenos"> 82</span></a><span class="sd">            - File path ending with &#39;.mp3&#39; or &#39;.wav&#39; to save to file</span>
</span><span id="VoiceModel.speak-83"><a href="#VoiceModel.speak-83"><span class="linenos"> 83</span></a><span class="sd">            - &#39;base64&#39; to return as base64 encoded string</span>
</span><span id="VoiceModel.speak-84"><a href="#VoiceModel.speak-84"><span class="linenos"> 84</span></a><span class="sd">            - &#39;bytes&#39; to return as raw bytes (default: &quot;audio.mp3&quot;)</span>
</span><span id="VoiceModel.speak-85"><a href="#VoiceModel.speak-85"><span class="linenos"> 85</span></a><span class="sd">            </span>
</span><span id="VoiceModel.speak-86"><a href="#VoiceModel.speak-86"><span class="linenos"> 86</span></a><span class="sd">        Returns</span>
</span><span id="VoiceModel.speak-87"><a href="#VoiceModel.speak-87"><span class="linenos"> 87</span></a><span class="sd">        -------</span>
</span><span id="VoiceModel.speak-88"><a href="#VoiceModel.speak-88"><span class="linenos"> 88</span></a><span class="sd">        str or bytes</span>
</span><span id="VoiceModel.speak-89"><a href="#VoiceModel.speak-89"><span class="linenos"> 89</span></a><span class="sd">            The generated audio in the specified format:</span>
</span><span id="VoiceModel.speak-90"><a href="#VoiceModel.speak-90"><span class="linenos"> 90</span></a><span class="sd">            - If return_type is a file path: returns the file path</span>
</span><span id="VoiceModel.speak-91"><a href="#VoiceModel.speak-91"><span class="linenos"> 91</span></a><span class="sd">            - If return_type is &#39;base64&#39;: returns base64 encoded string</span>
</span><span id="VoiceModel.speak-92"><a href="#VoiceModel.speak-92"><span class="linenos"> 92</span></a><span class="sd">            - If return_type is &#39;bytes&#39;: returns raw audio bytes</span>
</span><span id="VoiceModel.speak-93"><a href="#VoiceModel.speak-93"><span class="linenos"> 93</span></a><span class="sd">            </span>
</span><span id="VoiceModel.speak-94"><a href="#VoiceModel.speak-94"><span class="linenos"> 94</span></a><span class="sd">        Raises</span>
</span><span id="VoiceModel.speak-95"><a href="#VoiceModel.speak-95"><span class="linenos"> 95</span></a><span class="sd">        ------</span>
</span><span id="VoiceModel.speak-96"><a href="#VoiceModel.speak-96"><span class="linenos"> 96</span></a><span class="sd">        ValueError</span>
</span><span id="VoiceModel.speak-97"><a href="#VoiceModel.speak-97"><span class="linenos"> 97</span></a><span class="sd">            If return_type is not a valid option</span>
</span><span id="VoiceModel.speak-98"><a href="#VoiceModel.speak-98"><span class="linenos"> 98</span></a><span class="sd">            </span>
</span><span id="VoiceModel.speak-99"><a href="#VoiceModel.speak-99"><span class="linenos"> 99</span></a><span class="sd">        Examples</span>
</span><span id="VoiceModel.speak-100"><a href="#VoiceModel.speak-100"><span class="linenos">100</span></a><span class="sd">        --------</span>
</span><span id="VoiceModel.speak-101"><a href="#VoiceModel.speak-101"><span class="linenos">101</span></a><span class="sd">        &gt;&gt;&gt; model = VoiceModel(provider=&quot;elevenlabs&quot;, model=&quot;eleven_multilingual_v2&quot;, voice=&quot;21m00Tcm4TlvDq8ikWAM&quot;)</span>
</span><span id="VoiceModel.speak-102"><a href="#VoiceModel.speak-102"><span class="linenos">102</span></a><span class="sd">        &gt;&gt;&gt; # Save to file</span>
</span><span id="VoiceModel.speak-103"><a href="#VoiceModel.speak-103"><span class="linenos">103</span></a><span class="sd">        &gt;&gt;&gt; audio_file = model.speak(&quot;Hello, world!&quot;, return_type=&quot;output.mp3&quot;)</span>
</span><span id="VoiceModel.speak-104"><a href="#VoiceModel.speak-104"><span class="linenos">104</span></a><span class="sd">        &gt;&gt;&gt; # Get as base64</span>
</span><span id="VoiceModel.speak-105"><a href="#VoiceModel.speak-105"><span class="linenos">105</span></a><span class="sd">        &gt;&gt;&gt; audio_b64 = model.speak(&quot;Hello, world!&quot;, return_type=&quot;base64&quot;)</span>
</span><span id="VoiceModel.speak-106"><a href="#VoiceModel.speak-106"><span class="linenos">106</span></a><span class="sd">        &gt;&gt;&gt; # Get as bytes</span>
</span><span id="VoiceModel.speak-107"><a href="#VoiceModel.speak-107"><span class="linenos">107</span></a><span class="sd">        &gt;&gt;&gt; audio_bytes = model.speak(&quot;Hello, world!&quot;, return_type=&quot;bytes&quot;)</span>
</span><span id="VoiceModel.speak-108"><a href="#VoiceModel.speak-108"><span class="linenos">108</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="VoiceModel.speak-109"><a href="#VoiceModel.speak-109"><span class="linenos">109</span></a>        <span class="n">audio_groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_audio_groups</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">min_chars_per_sentence</span><span class="p">)</span>
</span><span id="VoiceModel.speak-110"><a href="#VoiceModel.speak-110"><span class="linenos">110</span></a>        <span class="n">audio_chunks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="VoiceModel.speak-111"><a href="#VoiceModel.speak-111"><span class="linenos">111</span></a>        
</span><span id="VoiceModel.speak-112"><a href="#VoiceModel.speak-112"><span class="linenos">112</span></a>        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">audio_groups</span><span class="p">:</span>
</span><span id="VoiceModel.speak-113"><a href="#VoiceModel.speak-113"><span class="linenos">113</span></a>            
</span><span id="VoiceModel.speak-114"><a href="#VoiceModel.speak-114"><span class="linenos">114</span></a>            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
</span><span id="VoiceModel.speak-115"><a href="#VoiceModel.speak-115"><span class="linenos">115</span></a>            
</span><span id="VoiceModel.speak-116"><a href="#VoiceModel.speak-116"><span class="linenos">116</span></a>            <span class="n">audio_chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span id="VoiceModel.speak-117"><a href="#VoiceModel.speak-117"><span class="linenos">117</span></a>        
</span><span id="VoiceModel.speak-118"><a href="#VoiceModel.speak-118"><span class="linenos">118</span></a>        <span class="k">if</span> <span class="n">return_type</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.mp3&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">return_type</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.wav&quot;</span><span class="p">):</span>
</span><span id="VoiceModel.speak-119"><a href="#VoiceModel.speak-119"><span class="linenos">119</span></a>            <span class="n">combined_audio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_bytes_chunks</span><span class="p">(</span><span class="n">audio_chunks</span><span class="p">)</span>
</span><span id="VoiceModel.speak-120"><a href="#VoiceModel.speak-120"><span class="linenos">120</span></a>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">return_type</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="VoiceModel.speak-121"><a href="#VoiceModel.speak-121"><span class="linenos">121</span></a>                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">combined_audio</span><span class="p">)</span>
</span><span id="VoiceModel.speak-122"><a href="#VoiceModel.speak-122"><span class="linenos">122</span></a>            <span class="k">return</span> <span class="n">return_type</span>
</span><span id="VoiceModel.speak-123"><a href="#VoiceModel.speak-123"><span class="linenos">123</span></a>        <span class="k">elif</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;base64&quot;</span><span class="p">:</span>
</span><span id="VoiceModel.speak-124"><a href="#VoiceModel.speak-124"><span class="linenos">124</span></a>            <span class="n">combined_audio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_bytes_chunks</span><span class="p">(</span><span class="n">audio_chunks</span><span class="p">)</span>
</span><span id="VoiceModel.speak-125"><a href="#VoiceModel.speak-125"><span class="linenos">125</span></a>            <span class="k">return</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">combined_audio</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span><span id="VoiceModel.speak-126"><a href="#VoiceModel.speak-126"><span class="linenos">126</span></a>        <span class="k">elif</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;bytes&quot;</span><span class="p">:</span>
</span><span id="VoiceModel.speak-127"><a href="#VoiceModel.speak-127"><span class="linenos">127</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_bytes_chunks</span><span class="p">(</span><span class="n">audio_chunks</span><span class="p">)</span>
</span><span id="VoiceModel.speak-128"><a href="#VoiceModel.speak-128"><span class="linenos">128</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="VoiceModel.speak-129"><a href="#VoiceModel.speak-129"><span class="linenos">129</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid return type: </span><span class="si">{</span><span class="n">return_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Convert text to speech and return the audio in the specified format.</p>

<p>The method automatically splits long text into optimal chunks based on
sentence boundaries to ensure high-quality audio generation.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>text</strong> (str):
The text to convert to speech</li>
<li><strong>min_chars_per_sentence</strong> (int, optional):
Minimum number of characters per sentence group for optimal audio
generation (default: 100)</li>
<li><strong>return_type</strong> (str, optional):
The format to return the audio in. Options:
<ul>
<li>File path ending with '.mp3' or '.wav' to save to file</li>
<li>'base64' to return as base64 encoded string</li>
<li>'bytes' to return as raw bytes (default: "audio.mp3")</li>
</ul></li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>str or bytes</strong>: The generated audio in the specified format:
<ul>
<li>If return_type is a file path: returns the file path</li>
<li>If return_type is 'base64': returns base64 encoded string</li>
<li>If return_type is 'bytes': returns raw audio bytes</li>
</ul></li>
</ul>

<h6 id="raises">Raises</h6>

<ul>
<li><strong>ValueError</strong>: If return_type is not a valid option</li>
</ul>

<h6 id="examples">Examples</h6>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">VoiceModel</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;elevenlabs&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;eleven_multilingual_v2&quot;</span><span class="p">,</span> <span class="n">voice</span><span class="o">=</span><span class="s2">&quot;21m00Tcm4TlvDq8ikWAM&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Save to file</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">audio_file</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">speak</span><span class="p">(</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;output.mp3&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get as base64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">audio_b64</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">speak</span><span class="p">(</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;base64&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get as bytes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">audio_bytes</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">speak</span><span class="p">(</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;bytes&quot;</span><span class="p">)</span>
</code></pre>
</div>
</div>


                            </div>
                            <div id="VoiceModel.stream" class="classattr">
                                        <input id="VoiceModel.stream-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">stream</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">text</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">min_chars_per_sentence</span><span class="o">=</span><span class="mi">100</span>, </span><span class="param"><span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;audio.mp3&#39;</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="VoiceModel.stream-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#VoiceModel.stream"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="VoiceModel.stream-229"><a href="#VoiceModel.stream-229"><span class="linenos">229</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">min_chars_per_sentence</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;audio.mp3&quot;</span><span class="p">):</span>
</span><span id="VoiceModel.stream-230"><a href="#VoiceModel.stream-230"><span class="linenos">230</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="VoiceModel.stream-231"><a href="#VoiceModel.stream-231"><span class="linenos">231</span></a><span class="sd">        Stream audio generation for long texts.</span>
</span><span id="VoiceModel.stream-232"><a href="#VoiceModel.stream-232"><span class="linenos">232</span></a><span class="sd">        </span>
</span><span id="VoiceModel.stream-233"><a href="#VoiceModel.stream-233"><span class="linenos">233</span></a><span class="sd">        Generates audio in chunks for long texts, yielding each chunk as it&#39;s</span>
</span><span id="VoiceModel.stream-234"><a href="#VoiceModel.stream-234"><span class="linenos">234</span></a><span class="sd">        generated. This is useful for real-time audio generation or processing</span>
</span><span id="VoiceModel.stream-235"><a href="#VoiceModel.stream-235"><span class="linenos">235</span></a><span class="sd">        very long texts.</span>
</span><span id="VoiceModel.stream-236"><a href="#VoiceModel.stream-236"><span class="linenos">236</span></a><span class="sd">        </span>
</span><span id="VoiceModel.stream-237"><a href="#VoiceModel.stream-237"><span class="linenos">237</span></a><span class="sd">        Parameters</span>
</span><span id="VoiceModel.stream-238"><a href="#VoiceModel.stream-238"><span class="linenos">238</span></a><span class="sd">        ----------</span>
</span><span id="VoiceModel.stream-239"><a href="#VoiceModel.stream-239"><span class="linenos">239</span></a><span class="sd">        text : str</span>
</span><span id="VoiceModel.stream-240"><a href="#VoiceModel.stream-240"><span class="linenos">240</span></a><span class="sd">            The text to convert to speech</span>
</span><span id="VoiceModel.stream-241"><a href="#VoiceModel.stream-241"><span class="linenos">241</span></a><span class="sd">        min_chars_per_sentence : int, optional</span>
</span><span id="VoiceModel.stream-242"><a href="#VoiceModel.stream-242"><span class="linenos">242</span></a><span class="sd">            Minimum number of characters per sentence group for optimal audio</span>
</span><span id="VoiceModel.stream-243"><a href="#VoiceModel.stream-243"><span class="linenos">243</span></a><span class="sd">            generation (default: 100)</span>
</span><span id="VoiceModel.stream-244"><a href="#VoiceModel.stream-244"><span class="linenos">244</span></a><span class="sd">        return_type : str, optional</span>
</span><span id="VoiceModel.stream-245"><a href="#VoiceModel.stream-245"><span class="linenos">245</span></a><span class="sd">            The format to return each audio chunk in. Options:</span>
</span><span id="VoiceModel.stream-246"><a href="#VoiceModel.stream-246"><span class="linenos">246</span></a><span class="sd">            - File path ending with &#39;.mp3&#39; or &#39;.wav&#39; to save each chunk to file</span>
</span><span id="VoiceModel.stream-247"><a href="#VoiceModel.stream-247"><span class="linenos">247</span></a><span class="sd">            - &#39;base64&#39; to return each chunk as base64 encoded string</span>
</span><span id="VoiceModel.stream-248"><a href="#VoiceModel.stream-248"><span class="linenos">248</span></a><span class="sd">            - &#39;bytes&#39; to return each chunk as raw bytes (default: &quot;audio.mp3&quot;)</span>
</span><span id="VoiceModel.stream-249"><a href="#VoiceModel.stream-249"><span class="linenos">249</span></a><span class="sd">            </span>
</span><span id="VoiceModel.stream-250"><a href="#VoiceModel.stream-250"><span class="linenos">250</span></a><span class="sd">        Yields</span>
</span><span id="VoiceModel.stream-251"><a href="#VoiceModel.stream-251"><span class="linenos">251</span></a><span class="sd">        ------</span>
</span><span id="VoiceModel.stream-252"><a href="#VoiceModel.stream-252"><span class="linenos">252</span></a><span class="sd">        str or bytes</span>
</span><span id="VoiceModel.stream-253"><a href="#VoiceModel.stream-253"><span class="linenos">253</span></a><span class="sd">            Audio chunks in the specified format:</span>
</span><span id="VoiceModel.stream-254"><a href="#VoiceModel.stream-254"><span class="linenos">254</span></a><span class="sd">            - If return_type is a file path: yields the file path for each chunk</span>
</span><span id="VoiceModel.stream-255"><a href="#VoiceModel.stream-255"><span class="linenos">255</span></a><span class="sd">            - If return_type is &#39;base64&#39;: yields base64 encoded strings</span>
</span><span id="VoiceModel.stream-256"><a href="#VoiceModel.stream-256"><span class="linenos">256</span></a><span class="sd">            - If return_type is &#39;bytes&#39;: yields raw audio bytes</span>
</span><span id="VoiceModel.stream-257"><a href="#VoiceModel.stream-257"><span class="linenos">257</span></a><span class="sd">            </span>
</span><span id="VoiceModel.stream-258"><a href="#VoiceModel.stream-258"><span class="linenos">258</span></a><span class="sd">        Raises</span>
</span><span id="VoiceModel.stream-259"><a href="#VoiceModel.stream-259"><span class="linenos">259</span></a><span class="sd">        ------</span>
</span><span id="VoiceModel.stream-260"><a href="#VoiceModel.stream-260"><span class="linenos">260</span></a><span class="sd">        ValueError</span>
</span><span id="VoiceModel.stream-261"><a href="#VoiceModel.stream-261"><span class="linenos">261</span></a><span class="sd">            If return_type is not a valid option</span>
</span><span id="VoiceModel.stream-262"><a href="#VoiceModel.stream-262"><span class="linenos">262</span></a><span class="sd">            </span>
</span><span id="VoiceModel.stream-263"><a href="#VoiceModel.stream-263"><span class="linenos">263</span></a><span class="sd">        Examples</span>
</span><span id="VoiceModel.stream-264"><a href="#VoiceModel.stream-264"><span class="linenos">264</span></a><span class="sd">        --------</span>
</span><span id="VoiceModel.stream-265"><a href="#VoiceModel.stream-265"><span class="linenos">265</span></a><span class="sd">        &gt;&gt;&gt; model = VoiceModel(provider=&quot;elevenlabs&quot;, model=&quot;eleven_multilingual_v2&quot;, voice=&quot;21m00Tcm4TlvDq8ikWAM&quot;)</span>
</span><span id="VoiceModel.stream-266"><a href="#VoiceModel.stream-266"><span class="linenos">266</span></a><span class="sd">        &gt;&gt;&gt; async for audio_chunk in model.stream(&quot;Long text to convert to speech&quot;):</span>
</span><span id="VoiceModel.stream-267"><a href="#VoiceModel.stream-267"><span class="linenos">267</span></a><span class="sd">        ...     print(f&quot;Generated audio chunk: {audio_chunk}&quot;)</span>
</span><span id="VoiceModel.stream-268"><a href="#VoiceModel.stream-268"><span class="linenos">268</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="VoiceModel.stream-269"><a href="#VoiceModel.stream-269"><span class="linenos">269</span></a>        <span class="n">audio_groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_audio_groups</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">min_chars_per_sentence</span><span class="p">)</span>
</span><span id="VoiceModel.stream-270"><a href="#VoiceModel.stream-270"><span class="linenos">270</span></a>        
</span><span id="VoiceModel.stream-271"><a href="#VoiceModel.stream-271"><span class="linenos">271</span></a>        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">audio_groups</span><span class="p">):</span>
</span><span id="VoiceModel.stream-272"><a href="#VoiceModel.stream-272"><span class="linenos">272</span></a>            <span class="c1"># Generate audio for the sentence group</span>
</span><span id="VoiceModel.stream-273"><a href="#VoiceModel.stream-273"><span class="linenos">273</span></a>            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
</span><span id="VoiceModel.stream-274"><a href="#VoiceModel.stream-274"><span class="linenos">274</span></a>
</span><span id="VoiceModel.stream-275"><a href="#VoiceModel.stream-275"><span class="linenos">275</span></a>            <span class="k">if</span> <span class="n">return_type</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.mp3&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">return_type</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.wav&quot;</span><span class="p">):</span>
</span><span id="VoiceModel.stream-276"><a href="#VoiceModel.stream-276"><span class="linenos">276</span></a>                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">return_type</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="VoiceModel.stream-277"><a href="#VoiceModel.stream-277"><span class="linenos">277</span></a>                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span id="VoiceModel.stream-278"><a href="#VoiceModel.stream-278"><span class="linenos">278</span></a>                <span class="k">yield</span> <span class="n">return_type</span>
</span><span id="VoiceModel.stream-279"><a href="#VoiceModel.stream-279"><span class="linenos">279</span></a>            <span class="k">elif</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;base64&quot;</span><span class="p">:</span>
</span><span id="VoiceModel.stream-280"><a href="#VoiceModel.stream-280"><span class="linenos">280</span></a>                <span class="k">yield</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span><span id="VoiceModel.stream-281"><a href="#VoiceModel.stream-281"><span class="linenos">281</span></a>            <span class="k">elif</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;bytes&quot;</span><span class="p">:</span>
</span><span id="VoiceModel.stream-282"><a href="#VoiceModel.stream-282"><span class="linenos">282</span></a>                <span class="k">yield</span> <span class="n">response</span>
</span><span id="VoiceModel.stream-283"><a href="#VoiceModel.stream-283"><span class="linenos">283</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="VoiceModel.stream-284"><a href="#VoiceModel.stream-284"><span class="linenos">284</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid return type: </span><span class="si">{</span><span class="n">return_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Stream audio generation for long texts.</p>

<p>Generates audio in chunks for long texts, yielding each chunk as it's
generated. This is useful for real-time audio generation or processing
very long texts.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>text</strong> (str):
The text to convert to speech</li>
<li><strong>min_chars_per_sentence</strong> (int, optional):
Minimum number of characters per sentence group for optimal audio
generation (default: 100)</li>
<li><strong>return_type</strong> (str, optional):
The format to return each audio chunk in. Options:
<ul>
<li>File path ending with '.mp3' or '.wav' to save each chunk to file</li>
<li>'base64' to return each chunk as base64 encoded string</li>
<li>'bytes' to return each chunk as raw bytes (default: "audio.mp3")</li>
</ul></li>
</ul>

<h6 id="yields">Yields</h6>

<ul>
<li><strong>str or bytes</strong>: Audio chunks in the specified format:
<ul>
<li>If return_type is a file path: yields the file path for each chunk</li>
<li>If return_type is 'base64': yields base64 encoded strings</li>
<li>If return_type is 'bytes': yields raw audio bytes</li>
</ul></li>
</ul>

<h6 id="raises">Raises</h6>

<ul>
<li><strong>ValueError</strong>: If return_type is not a valid option</li>
</ul>

<h6 id="examples">Examples</h6>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">VoiceModel</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;elevenlabs&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;eleven_multilingual_v2&quot;</span><span class="p">,</span> <span class="n">voice</span><span class="o">=</span><span class="s2">&quot;21m00Tcm4TlvDq8ikWAM&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">async</span> <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="s2">&quot;Long text to convert to speech&quot;</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated audio chunk: </span><span class="si">{</span><span class="n">audio_chunk</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre>
</div>
</div>


                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>